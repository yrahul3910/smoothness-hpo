running: {'--uuid': '71aa122b4f695b25a107b206256c58dd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_224500', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d wine -o hyperopt -u 71aa122b4f695b25a107b206256c58dd -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_224500
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study hyperopt MLP-adam wine acc 15 1
with data root: None
suggestion time taken 0.002332 iter 0 next_points [{'alpha': 0.09176412818018741, 'batch_size': 168, 'beta_1': 0.8798622223064156, 'beta_2': 0.9890531165849494, 'epsilon': 8.867196814047557e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.04773233360274255, 'tol': 1.0835521986809588e-05, 'validation_fraction': 0.27205022789275957}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.091999 value -0.671429 suggestion {'alpha': 0.09176412818018741, 'batch_size': 168, 'beta_1': 0.8798622223064156, 'beta_2': 0.9890531165849494, 'epsilon': 8.867196814047557e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.04773233360274255, 'tol': 1.0835521986809588e-05, 'validation_fraction': 0.27205022789275957}
observation time 0.000066, current best -0.671429 at iter 0
suggestion time taken 0.002398 iter 1 next_points [{'alpha': 0.5810124159536622, 'batch_size': 36, 'beta_1': 0.8322571364314211, 'beta_2': 0.9431416478065969, 'epsilon': 1.5633238489972752e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0013798481165746834, 'tol': 0.0038724483818405996, 'validation_fraction': 0.2267429270813678}]
function_evaluation time 0.137212 value -0.802709 suggestion {'alpha': 0.5810124159536622, 'batch_size': 36, 'beta_1': 0.8322571364314211, 'beta_2': 0.9431416478065969, 'epsilon': 1.5633238489972752e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0013798481165746834, 'tol': 0.0038724483818405996, 'validation_fraction': 0.2267429270813678}
observation time 0.000071, current best -0.802709 at iter 1
suggestion time taken 0.002156 iter 2 next_points [{'alpha': 3.505336864020512, 'batch_size': 31, 'beta_1': 0.6752540221774198, 'beta_2': 0.9411771202271305, 'epsilon': 1.5329735168136898e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0011867590383252953, 'tol': 0.008634483340875323, 'validation_fraction': 0.8477744960397331}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.090888 value -0.464039 suggestion {'alpha': 3.505336864020512, 'batch_size': 31, 'beta_1': 0.6752540221774198, 'beta_2': 0.9411771202271305, 'epsilon': 1.5329735168136898e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0011867590383252953, 'tol': 0.008634483340875323, 'validation_fraction': 0.8477744960397331}
observation time 0.000076, current best -0.802709 at iter 2
suggestion time taken 0.002228 iter 3 next_points [{'alpha': 0.0033150749772922305, 'batch_size': 246, 'beta_1': 0.7196231448772941, 'beta_2': 0.953542686588257, 'epsilon': 4.421181573290709e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0018413779544077255, 'tol': 0.00185713763985303, 'validation_fraction': 0.20969941903301198}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.103471 value -0.600246 suggestion {'alpha': 0.0033150749772922305, 'batch_size': 246, 'beta_1': 0.7196231448772941, 'beta_2': 0.953542686588257, 'epsilon': 4.421181573290709e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0018413779544077255, 'tol': 0.00185713763985303, 'validation_fraction': 0.20969941903301198}
observation time 0.000072, current best -0.802709 at iter 3
suggestion time taken 0.002178 iter 4 next_points [{'alpha': 0.00015572407689415417, 'batch_size': 191, 'beta_1': 0.7107787250733445, 'beta_2': 0.9770801920108354, 'epsilon': 1.0835252394678383e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0004966686977847623, 'tol': 0.00022611978835138032, 'validation_fraction': 0.14532235647443903}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.071962 value -0.336946 suggestion {'alpha': 0.00015572407689415417, 'batch_size': 191, 'beta_1': 0.7107787250733445, 'beta_2': 0.9770801920108354, 'epsilon': 1.0835252394678383e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0004966686977847623, 'tol': 0.00022611978835138032, 'validation_fraction': 0.14532235647443903}
observation time 0.000078, current best -0.802709 at iter 4
suggestion time taken 0.002251 iter 5 next_points [{'alpha': 0.10722028128173046, 'batch_size': 225, 'beta_1': 0.5012701920521575, 'beta_2': 0.9459623905952931, 'epsilon': 1.8117444716588674e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.01970777251615673, 'tol': 0.0006644779699063622, 'validation_fraction': 0.3589993224750601}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.118503 value -0.655665 suggestion {'alpha': 0.10722028128173046, 'batch_size': 225, 'beta_1': 0.5012701920521575, 'beta_2': 0.9459623905952931, 'epsilon': 1.8117444716588674e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.01970777251615673, 'tol': 0.0006644779699063622, 'validation_fraction': 0.3589993224750601}
observation time 0.000077, current best -0.802709 at iter 5
suggestion time taken 0.002159 iter 6 next_points [{'alpha': 0.00022183732562094206, 'batch_size': 16, 'beta_1': 0.7050429164521999, 'beta_2': 0.9840548926206962, 'epsilon': 3.2597106873024977e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.005493619536780867, 'tol': 1.5938504923581708e-05, 'validation_fraction': 0.8944495808228378}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.082790 value -0.626108 suggestion {'alpha': 0.00022183732562094206, 'batch_size': 16, 'beta_1': 0.7050429164521999, 'beta_2': 0.9840548926206962, 'epsilon': 3.2597106873024977e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.005493619536780867, 'tol': 1.5938504923581708e-05, 'validation_fraction': 0.8944495808228378}
observation time 0.000091, current best -0.802709 at iter 6
suggestion time taken 0.002206 iter 7 next_points [{'alpha': 1.1371145553239038e-05, 'batch_size': 53, 'beta_1': 0.7803067333916682, 'beta_2': 0.9626345914219593, 'epsilon': 1.400801043235227e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.03285515978804764, 'tol': 0.00013099471246554994, 'validation_fraction': 0.10594686996776256}]
function_evaluation time 0.129344 value -0.797783 suggestion {'alpha': 1.1371145553239038e-05, 'batch_size': 53, 'beta_1': 0.7803067333916682, 'beta_2': 0.9626345914219593, 'epsilon': 1.400801043235227e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.03285515978804764, 'tol': 0.00013099471246554994, 'validation_fraction': 0.10594686996776256}
observation time 0.000074, current best -0.802709 at iter 7
suggestion time taken 0.002202 iter 8 next_points [{'alpha': 0.0023090361540778915, 'batch_size': 80, 'beta_1': 0.7422605470464271, 'beta_2': 0.9465761407294229, 'epsilon': 4.6654076201844807e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0011489335292145578, 'tol': 0.0013838410276456015, 'validation_fraction': 0.2566746356375716}]
function_evaluation time 0.132134 value -0.656897 suggestion {'alpha': 0.0023090361540778915, 'batch_size': 80, 'beta_1': 0.7422605470464271, 'beta_2': 0.9465761407294229, 'epsilon': 4.6654076201844807e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0011489335292145578, 'tol': 0.0013838410276456015, 'validation_fraction': 0.2566746356375716}
observation time 0.000071, current best -0.802709 at iter 8
suggestion time taken 0.002135 iter 9 next_points [{'alpha': 0.0004886482246644663, 'batch_size': 52, 'beta_1': 0.5633403274861991, 'beta_2': 0.9171129307633467, 'epsilon': 3.970792818877116e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 7.548255674390339e-05, 'tol': 1.773835821399905e-05, 'validation_fraction': 0.30549395307942306}]
function_evaluation time 0.058604 value -0.233251 suggestion {'alpha': 0.0004886482246644663, 'batch_size': 52, 'beta_1': 0.5633403274861991, 'beta_2': 0.9171129307633467, 'epsilon': 3.970792818877116e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 7.548255674390339e-05, 'tol': 1.773835821399905e-05, 'validation_fraction': 0.30549395307942306}
observation time 0.000077, current best -0.802709 at iter 9
suggestion time taken 0.002148 iter 10 next_points [{'alpha': 0.0021473233592487428, 'batch_size': 87, 'beta_1': 0.5540878361823948, 'beta_2': 0.914207547393835, 'epsilon': 6.347360705867141e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 6.794999820158486e-05, 'tol': 0.022269613139855867, 'validation_fraction': 0.3666053218813009}]
function_evaluation time 0.079283 value -0.445074 suggestion {'alpha': 0.0021473233592487428, 'batch_size': 87, 'beta_1': 0.5540878361823948, 'beta_2': 0.914207547393835, 'epsilon': 6.347360705867141e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 6.794999820158486e-05, 'tol': 0.022269613139855867, 'validation_fraction': 0.3666053218813009}
observation time 0.000077, current best -0.802709 at iter 10
suggestion time taken 0.002156 iter 11 next_points [{'alpha': 0.043737268163004744, 'batch_size': 17, 'beta_1': 0.8680580800140257, 'beta_2': 0.9344942122775536, 'epsilon': 4.976951581130596e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 1.173736466593905e-05, 'tol': 0.00025267915835985123, 'validation_fraction': 0.1382894036504193}]
function_evaluation time 0.105330 value -0.338424 suggestion {'alpha': 0.043737268163004744, 'batch_size': 17, 'beta_1': 0.8680580800140257, 'beta_2': 0.9344942122775536, 'epsilon': 4.976951581130596e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 1.173736466593905e-05, 'tol': 0.00025267915835985123, 'validation_fraction': 0.1382894036504193}
observation time 0.000076, current best -0.802709 at iter 11
suggestion time taken 0.002222 iter 12 next_points [{'alpha': 9.696723678896907e-05, 'batch_size': 126, 'beta_1': 0.708204961488001, 'beta_2': 0.936805013511275, 'epsilon': 3.425070015242853e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.037058247512375554, 'tol': 1.3563103716800084e-05, 'validation_fraction': 0.10095041099552764}]
function_evaluation time 0.071417 value -0.541626 suggestion {'alpha': 9.696723678896907e-05, 'batch_size': 126, 'beta_1': 0.708204961488001, 'beta_2': 0.936805013511275, 'epsilon': 3.425070015242853e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.037058247512375554, 'tol': 1.3563103716800084e-05, 'validation_fraction': 0.10095041099552764}
observation time 0.000073, current best -0.802709 at iter 12
suggestion time taken 0.002188 iter 13 next_points [{'alpha': 0.10955653791675438, 'batch_size': 165, 'beta_1': 0.6478683907240517, 'beta_2': 0.9262635688356665, 'epsilon': 2.8403396229067512e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0271959119199266, 'tol': 0.013970547583088359, 'validation_fraction': 0.29169223057828175}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.114465 value -0.663793 suggestion {'alpha': 0.10955653791675438, 'batch_size': 165, 'beta_1': 0.6478683907240517, 'beta_2': 0.9262635688356665, 'epsilon': 2.8403396229067512e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0271959119199266, 'tol': 0.013970547583088359, 'validation_fraction': 0.29169223057828175}
observation time 0.000072, current best -0.802709 at iter 13
suggestion time taken 0.002124 iter 14 next_points [{'alpha': 0.04011359915545219, 'batch_size': 112, 'beta_1': 0.6481894842860532, 'beta_2': 0.938468896085496, 'epsilon': 4.4731274646291115e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.011795441652337592, 'tol': 0.09770765939471825, 'validation_fraction': 0.13594601519036556}]
function_evaluation time 0.075906 value -0.584975 suggestion {'alpha': 0.04011359915545219, 'batch_size': 112, 'beta_1': 0.6481894842860532, 'beta_2': 0.938468896085496, 'epsilon': 4.4731274646291115e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.011795441652337592, 'tol': 0.09770765939471825, 'validation_fraction': 0.13594601519036556}
observation time 0.000076, current best -0.802709 at iter 14
saving meta data: {'args': {'--uuid': '71aa122b4f695b25a107b206256c58dd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_224500', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done
