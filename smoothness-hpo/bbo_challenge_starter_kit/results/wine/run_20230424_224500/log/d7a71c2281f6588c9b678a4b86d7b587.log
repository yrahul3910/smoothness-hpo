running: {'--uuid': 'd7a71c2281f6588c9b678a4b86d7b587', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_224500', '--opt': 'smoothness', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d wine -o smoothness -u d7a71c2281f6588c9b678a4b86d7b587 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_224500
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study smoothness MLP-adam wine acc 15 1
with data root: None
suggestion time taken 10.925071 iter 0 next_points [{'alpha': 0.0003018190787329794, 'batch_size': 16, 'beta_1': 0.7743430434725157, 'beta_2': 0.9915538193140289, 'epsilon': 4.072363674089456e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0005886074556075635, 'tol': 2.409515464267946e-05, 'validation_fraction': 0.8960461134538783}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.093108 value -0.521921 suggestion {'alpha': 0.0003018190787329794, 'batch_size': 16, 'beta_1': 0.7743430434725157, 'beta_2': 0.9915538193140289, 'epsilon': 4.072363674089456e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0005886074556075635, 'tol': 2.409515464267946e-05, 'validation_fraction': 0.8960461134538783}
observation time 0.000006, current best -0.521921 at iter 0
suggestion time taken 11.131656 iter 1 next_points [{'alpha': 1.2458876639899787, 'batch_size': 10, 'beta_1': 0.6840386458719216, 'beta_2': 0.9600777354064525, 'epsilon': 5.983787979591406e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006192276037807878, 'tol': 0.005556868174418201, 'validation_fraction': 0.7040750348351466}]
function_evaluation time 0.189789 value -0.718719 suggestion {'alpha': 1.2458876639899787, 'batch_size': 10, 'beta_1': 0.6840386458719216, 'beta_2': 0.9600777354064525, 'epsilon': 5.983787979591406e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006192276037807878, 'tol': 0.005556868174418201, 'validation_fraction': 0.7040750348351466}
observation time 0.000006, current best -0.718719 at iter 1
suggestion time taken 10.962116 iter 2 next_points [{'alpha': 0.9586027433503177, 'batch_size': 11, 'beta_1': 0.8728735667846135, 'beta_2': 0.9996681276789725, 'epsilon': 6.0705839036035e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 8.660639176701379e-05, 'tol': 0.0063714056480660575, 'validation_fraction': 0.17529653986196983}]
function_evaluation time 0.221570 value -0.423153 suggestion {'alpha': 0.9586027433503177, 'batch_size': 11, 'beta_1': 0.8728735667846135, 'beta_2': 0.9996681276789725, 'epsilon': 6.0705839036035e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 8.660639176701379e-05, 'tol': 0.0063714056480660575, 'validation_fraction': 0.17529653986196983}
observation time 0.000006, current best -0.718719 at iter 2
suggestion time taken 11.253553 iter 3 next_points [{'alpha': 7.073281859774376e-05, 'batch_size': 27, 'beta_1': 0.5332141829061726, 'beta_2': 0.9999978783142125, 'epsilon': 3.933522389860768e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.016881455038480556, 'tol': 0.0010776570533458454, 'validation_fraction': 0.7274249861496256}]
function_evaluation time 0.122481 value -0.648522 suggestion {'alpha': 7.073281859774376e-05, 'batch_size': 27, 'beta_1': 0.5332141829061726, 'beta_2': 0.9999978783142125, 'epsilon': 3.933522389860768e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.016881455038480556, 'tol': 0.0010776570533458454, 'validation_fraction': 0.7274249861496256}
observation time 0.000006, current best -0.718719 at iter 3
suggestion time taken 10.981270 iter 4 next_points [{'alpha': 0.023664410923368073, 'batch_size': 17, 'beta_1': 0.9726234165097526, 'beta_2': 0.9185366812158999, 'epsilon': 1.4107502160290795e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.013990100430038706, 'tol': 7.635318757628117e-05, 'validation_fraction': 0.5852779336627754}]
function_evaluation time 0.154802 value -0.837438 suggestion {'alpha': 0.023664410923368073, 'batch_size': 17, 'beta_1': 0.9726234165097526, 'beta_2': 0.9185366812158999, 'epsilon': 1.4107502160290795e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.013990100430038706, 'tol': 7.635318757628117e-05, 'validation_fraction': 0.5852779336627754}
observation time 0.000006, current best -0.837438 at iter 4
suggestion time taken 11.094300 iter 5 next_points [{'alpha': 0.0035383142463950175, 'batch_size': 17, 'beta_1': 0.9125550161021299, 'beta_2': 0.999237083545919, 'epsilon': 2.9187238134707056e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0626550700142043, 'tol': 0.0011428373075848316, 'validation_fraction': 0.7390013225233721}]
function_evaluation time 0.116776 value -0.663054 suggestion {'alpha': 0.0035383142463950175, 'batch_size': 17, 'beta_1': 0.9125550161021299, 'beta_2': 0.999237083545919, 'epsilon': 2.9187238134707056e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0626550700142043, 'tol': 0.0011428373075848316, 'validation_fraction': 0.7390013225233721}
observation time 0.000006, current best -0.837438 at iter 5
suggestion time taken 11.470210 iter 6 next_points [{'alpha': 0.0025813212576953587, 'batch_size': 12, 'beta_1': 0.988132349229985, 'beta_2': 0.9977114931937237, 'epsilon': 1.6911822076920694e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.4333679022819441e-05, 'tol': 0.06894696428051279, 'validation_fraction': 0.10728332284950655}]
function_evaluation time 0.153357 value -0.423645 suggestion {'alpha': 0.0025813212576953587, 'batch_size': 12, 'beta_1': 0.988132349229985, 'beta_2': 0.9977114931937237, 'epsilon': 1.6911822076920694e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.4333679022819441e-05, 'tol': 0.06894696428051279, 'validation_fraction': 0.10728332284950655}
observation time 0.000005, current best -0.837438 at iter 6
suggestion time taken 11.149860 iter 7 next_points [{'alpha': 0.8017449272801206, 'batch_size': 15, 'beta_1': 0.9214906418924993, 'beta_2': 0.9982406014309207, 'epsilon': 8.737390080786465e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.006399313958856373, 'tol': 0.004542595119698897, 'validation_fraction': 0.8276400805271432}]
function_evaluation time 0.150091 value -0.761576 suggestion {'alpha': 0.8017449272801206, 'batch_size': 15, 'beta_1': 0.9214906418924993, 'beta_2': 0.9982406014309207, 'epsilon': 8.737390080786465e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.006399313958856373, 'tol': 0.004542595119698897, 'validation_fraction': 0.8276400805271432}
observation time 0.000006, current best -0.837438 at iter 7
suggestion time taken 11.006626 iter 8 next_points [{'alpha': 0.009156313637078875, 'batch_size': 18, 'beta_1': 0.9339298170935004, 'beta_2': 0.9933219995226857, 'epsilon': 9.645930591420612e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0006566137802571371, 'tol': 4.759385561643789e-05, 'validation_fraction': 0.14576884247965954}]
function_evaluation time 0.239190 value -0.746552 suggestion {'alpha': 0.009156313637078875, 'batch_size': 18, 'beta_1': 0.9339298170935004, 'beta_2': 0.9933219995226857, 'epsilon': 9.645930591420612e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0006566137802571371, 'tol': 4.759385561643789e-05, 'validation_fraction': 0.14576884247965954}
observation time 0.000006, current best -0.837438 at iter 8
suggestion time taken 11.245125 iter 9 next_points [{'alpha': 0.46337125450181815, 'batch_size': 26, 'beta_1': 0.7835447961752026, 'beta_2': 0.937143481478993, 'epsilon': 4.468089406469831e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.001695690581949444, 'tol': 0.000812678750997504, 'validation_fraction': 0.7316551280901809}]
function_evaluation time 0.070416 value -0.494581 suggestion {'alpha': 0.46337125450181815, 'batch_size': 26, 'beta_1': 0.7835447961752026, 'beta_2': 0.937143481478993, 'epsilon': 4.468089406469831e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.001695690581949444, 'tol': 0.000812678750997504, 'validation_fraction': 0.7316551280901809}
observation time 0.000006, current best -0.837438 at iter 9
suggestion time taken 11.015917 iter 10 next_points [{'alpha': 0.41526088734010025, 'batch_size': 14, 'beta_1': 0.9407672522762867, 'beta_2': 0.9999926434035723, 'epsilon': 5.649701298480523e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.009560619930186674, 'tol': 0.09792541804824037, 'validation_fraction': 0.13208410868283552}]
function_evaluation time 0.181835 value -0.753202 suggestion {'alpha': 0.41526088734010025, 'batch_size': 14, 'beta_1': 0.9407672522762867, 'beta_2': 0.9999926434035723, 'epsilon': 5.649701298480523e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.009560619930186674, 'tol': 0.09792541804824037, 'validation_fraction': 0.13208410868283552}
observation time 0.000005, current best -0.837438 at iter 10
suggestion time taken 10.949900 iter 11 next_points [{'alpha': 0.1586060734681228, 'batch_size': 15, 'beta_1': 0.9857672685851102, 'beta_2': 0.9980228944729147, 'epsilon': 8.965519351422003e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 6.990952049762946e-05, 'tol': 0.00017785646753090773, 'validation_fraction': 0.15205277311428625}]
function_evaluation time 0.181130 value -0.324138 suggestion {'alpha': 0.1586060734681228, 'batch_size': 15, 'beta_1': 0.9857672685851102, 'beta_2': 0.9980228944729147, 'epsilon': 8.965519351422003e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 6.990952049762946e-05, 'tol': 0.00017785646753090773, 'validation_fraction': 0.15205277311428625}
observation time 0.000006, current best -0.837438 at iter 11
suggestion time taken 11.017183 iter 12 next_points [{'alpha': 0.0025257804141819175, 'batch_size': 11, 'beta_1': 0.8859724847846517, 'beta_2': 0.9996199157648927, 'epsilon': 2.1589146937539615e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.05338177179256667, 'tol': 0.003291950155865705, 'validation_fraction': 0.3605165610411106}]
function_evaluation time 0.214135 value -0.810837 suggestion {'alpha': 0.0025257804141819175, 'batch_size': 11, 'beta_1': 0.8859724847846517, 'beta_2': 0.9996199157648927, 'epsilon': 2.1589146937539615e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.05338177179256667, 'tol': 0.003291950155865705, 'validation_fraction': 0.3605165610411106}
observation time 0.000006, current best -0.837438 at iter 12
suggestion time taken 11.338247 iter 13 next_points [{'alpha': 7.67239698652386e-05, 'batch_size': 25, 'beta_1': 0.9794071208513475, 'beta_2': 0.9911008783389625, 'epsilon': 3.1309418562161818e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0025029013807149297, 'tol': 1.6496459920347713e-05, 'validation_fraction': 0.732482407344514}]
function_evaluation time 0.132755 value -0.649754 suggestion {'alpha': 7.67239698652386e-05, 'batch_size': 25, 'beta_1': 0.9794071208513475, 'beta_2': 0.9911008783389625, 'epsilon': 3.1309418562161818e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0025029013807149297, 'tol': 1.6496459920347713e-05, 'validation_fraction': 0.732482407344514}
observation time 0.000005, current best -0.837438 at iter 13
suggestion time taken 10.989736 iter 14 next_points [{'alpha': 0.7248505809208992, 'batch_size': 19, 'beta_1': 0.9245797319527722, 'beta_2': 0.996438947165035, 'epsilon': 6.380769373862439e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.002052194388796965, 'tol': 0.010549838048418324, 'validation_fraction': 0.8939147944851591}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070687 value -0.549261 suggestion {'alpha': 0.7248505809208992, 'batch_size': 19, 'beta_1': 0.9245797319527722, 'beta_2': 0.996438947165035, 'epsilon': 6.380769373862439e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.002052194388796965, 'tol': 0.010549838048418324, 'validation_fraction': 0.8939147944851591}
observation time 0.000006, current best -0.837438 at iter 14
saving meta data: {'args': {'--uuid': 'd7a71c2281f6588c9b678a4b86d7b587', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_224500', '--opt': 'smoothness', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done
