running: {'--uuid': '776895a2d0335442be8226919a8cf173', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 776895a2d0335442be8226919a8cf173 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study random-search MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002533 iter 0 next_points [{'alpha': 0.00015129488256827213, 'batch_size': 111, 'beta_1': 0.7127953426778876, 'beta_2': 0.9999889685291181, 'epsilon': 6.674781667498398e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00559206653309018, 'tol': 0.00023569997164391246, 'validation_fraction': 0.7592445647844513}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.821979 value 4021.341168 suggestion {'alpha': 0.00015129488256827213, 'batch_size': 111, 'beta_1': 0.7127953426778876, 'beta_2': 0.9999889685291181, 'epsilon': 6.674781667498398e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00559206653309018, 'tol': 0.00023569997164391246, 'validation_fraction': 0.7592445647844513}
observation time 0.000005, current best 4021.341168 at iter 0
suggestion time taken 0.002480 iter 1 next_points [{'alpha': 0.6692746204672188, 'batch_size': 190, 'beta_1': 0.9823145784467786, 'beta_2': 0.9999917737352512, 'epsilon': 1.7986332379883036e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0017750647094544687, 'tol': 1.3468325924670066e-05, 'validation_fraction': 0.45449742432998214}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.776375 value 26719.288212 suggestion {'alpha': 0.6692746204672188, 'batch_size': 190, 'beta_1': 0.9823145784467786, 'beta_2': 0.9999917737352512, 'epsilon': 1.7986332379883036e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0017750647094544687, 'tol': 1.3468325924670066e-05, 'validation_fraction': 0.45449742432998214}
observation time 0.000005, current best 4021.341168 at iter 1
suggestion time taken 0.002494 iter 2 next_points [{'alpha': 0.037915700671252606, 'batch_size': 209, 'beta_1': 0.9678899413853723, 'beta_2': 0.994633987806982, 'epsilon': 1.9143734754578347e-07, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.09802292496115944, 'tol': 0.0013790063748634555, 'validation_fraction': 0.4425850200038534}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.143299 value 4251.111720 suggestion {'alpha': 0.037915700671252606, 'batch_size': 209, 'beta_1': 0.9678899413853723, 'beta_2': 0.994633987806982, 'epsilon': 1.9143734754578347e-07, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.09802292496115944, 'tol': 0.0013790063748634555, 'validation_fraction': 0.4425850200038534}
observation time 0.000005, current best 4021.341168 at iter 2
suggestion time taken 0.002538 iter 3 next_points [{'alpha': 2.9960944181055975, 'batch_size': 228, 'beta_1': 0.5694989601065346, 'beta_2': 0.9956912252109876, 'epsilon': 8.513575585948241e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.008403008412384139, 'tol': 0.043407310795874655, 'validation_fraction': 0.7707783430389012}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046288 value 28731.448686 suggestion {'alpha': 2.9960944181055975, 'batch_size': 228, 'beta_1': 0.5694989601065346, 'beta_2': 0.9956912252109876, 'epsilon': 8.513575585948241e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.008403008412384139, 'tol': 0.043407310795874655, 'validation_fraction': 0.7707783430389012}
observation time 0.000004, current best 4021.341168 at iter 3
suggestion time taken 0.002812 iter 4 next_points [{'alpha': 0.054899981353956906, 'batch_size': 152, 'beta_1': 0.9654401023692561, 'beta_2': 0.9999680109521589, 'epsilon': 2.9760438578852645e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 1.2447075629476978e-05, 'tol': 2.7988250724406897e-05, 'validation_fraction': 0.23144841328638652}]
function_evaluation time 0.074737 value 29135.599176 suggestion {'alpha': 0.054899981353956906, 'batch_size': 152, 'beta_1': 0.9654401023692561, 'beta_2': 0.9999680109521589, 'epsilon': 2.9760438578852645e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 1.2447075629476978e-05, 'tol': 2.7988250724406897e-05, 'validation_fraction': 0.23144841328638652}
observation time 0.000005, current best 4021.341168 at iter 4
suggestion time taken 0.002477 iter 5 next_points [{'alpha': 0.02275584771028423, 'batch_size': 26, 'beta_1': 0.9822348051654519, 'beta_2': 0.9999974921888414, 'epsilon': 3.5185853907410175e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.07609723563469653, 'tol': 0.0001276167063137965, 'validation_fraction': 0.672644163332675}]
function_evaluation time 0.276065 value 3362.714988 suggestion {'alpha': 0.02275584771028423, 'batch_size': 26, 'beta_1': 0.9822348051654519, 'beta_2': 0.9999974921888414, 'epsilon': 3.5185853907410175e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.07609723563469653, 'tol': 0.0001276167063137965, 'validation_fraction': 0.672644163332675}
observation time 0.000005, current best 3362.714988 at iter 5
suggestion time taken 0.002789 iter 6 next_points [{'alpha': 0.013780791575526068, 'batch_size': 203, 'beta_1': 0.947494219253068, 'beta_2': 0.9387276132454573, 'epsilon': 5.487431690110592e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.010129895181701551, 'tol': 1.391585201438915e-05, 'validation_fraction': 0.2354736144314835}]
function_evaluation time 0.657663 value 4113.695296 suggestion {'alpha': 0.013780791575526068, 'batch_size': 203, 'beta_1': 0.947494219253068, 'beta_2': 0.9387276132454573, 'epsilon': 5.487431690110592e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.010129895181701551, 'tol': 1.391585201438915e-05, 'validation_fraction': 0.2354736144314835}
observation time 0.000005, current best 3362.714988 at iter 6
suggestion time taken 0.002872 iter 7 next_points [{'alpha': 1.3948997516430017, 'batch_size': 44, 'beta_1': 0.9670106991425133, 'beta_2': 0.9983877196144416, 'epsilon': 4.4953836296474575e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 1.2063416095319422e-05, 'tol': 0.05331884713114552, 'validation_fraction': 0.44307121791172016}]
function_evaluation time 0.089675 value 29107.250293 suggestion {'alpha': 1.3948997516430017, 'batch_size': 44, 'beta_1': 0.9670106991425133, 'beta_2': 0.9983877196144416, 'epsilon': 4.4953836296474575e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 1.2063416095319422e-05, 'tol': 0.05331884713114552, 'validation_fraction': 0.44307121791172016}
observation time 0.000004, current best 3362.714988 at iter 7
suggestion time taken 0.002485 iter 8 next_points [{'alpha': 0.0009829363765455324, 'batch_size': 12, 'beta_1': 0.9892778299307423, 'beta_2': 0.9999969197715687, 'epsilon': 2.999512295421714e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0007171825087063708, 'tol': 0.0018375306200935583, 'validation_fraction': 0.1540522045997309}]
function_evaluation time 2.389766 value 3879.341456 suggestion {'alpha': 0.0009829363765455324, 'batch_size': 12, 'beta_1': 0.9892778299307423, 'beta_2': 0.9999969197715687, 'epsilon': 2.999512295421714e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0007171825087063708, 'tol': 0.0018375306200935583, 'validation_fraction': 0.1540522045997309}
observation time 0.000005, current best 3362.714988 at iter 8
suggestion time taken 0.002481 iter 9 next_points [{'alpha': 0.01072890454026027, 'batch_size': 193, 'beta_1': 0.8949554153712067, 'beta_2': 0.9969394962837802, 'epsilon': 3.060901697824803e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 3.738412336919279e-05, 'tol': 0.0004894882370306861, 'validation_fraction': 0.16454127868996696}]
function_evaluation time 0.060786 value 29085.837885 suggestion {'alpha': 0.01072890454026027, 'batch_size': 193, 'beta_1': 0.8949554153712067, 'beta_2': 0.9969394962837802, 'epsilon': 3.060901697824803e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 3.738412336919279e-05, 'tol': 0.0004894882370306861, 'validation_fraction': 0.16454127868996696}
observation time 0.000005, current best 3362.714988 at iter 9
suggestion time taken 0.002422 iter 10 next_points [{'alpha': 0.3048574342590302, 'batch_size': 182, 'beta_1': 0.5210030139127341, 'beta_2': 0.9997082262476181, 'epsilon': 9.442572116377908e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.01965992293838533, 'tol': 0.011862371389294088, 'validation_fraction': 0.5335387850194472}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.312713 value 3808.457255 suggestion {'alpha': 0.3048574342590302, 'batch_size': 182, 'beta_1': 0.5210030139127341, 'beta_2': 0.9997082262476181, 'epsilon': 9.442572116377908e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.01965992293838533, 'tol': 0.011862371389294088, 'validation_fraction': 0.5335387850194472}
observation time 0.000005, current best 3362.714988 at iter 10
suggestion time taken 0.002643 iter 11 next_points [{'alpha': 0.0018212544692301547, 'batch_size': 129, 'beta_1': 0.627517051016415, 'beta_2': 0.9853023270793522, 'epsilon': 3.7211186273758456e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.021604155713264062, 'tol': 5.95406140240044e-05, 'validation_fraction': 0.3051726480041447}]
function_evaluation time 0.507287 value 2974.917007 suggestion {'alpha': 0.0018212544692301547, 'batch_size': 129, 'beta_1': 0.627517051016415, 'beta_2': 0.9853023270793522, 'epsilon': 3.7211186273758456e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.021604155713264062, 'tol': 5.95406140240044e-05, 'validation_fraction': 0.3051726480041447}
observation time 0.000004, current best 2974.917007 at iter 11
suggestion time taken 0.002436 iter 12 next_points [{'alpha': 6.169246031864512e-05, 'batch_size': 88, 'beta_1': 0.6210974045664973, 'beta_2': 0.9975956431722995, 'epsilon': 4.240659676298403e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 8.093018443877686e-05, 'tol': 0.0008766519517369513, 'validation_fraction': 0.3478791336428913}]
function_evaluation time 0.097850 value 29049.847466 suggestion {'alpha': 6.169246031864512e-05, 'batch_size': 88, 'beta_1': 0.6210974045664973, 'beta_2': 0.9975956431722995, 'epsilon': 4.240659676298403e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 8.093018443877686e-05, 'tol': 0.0008766519517369513, 'validation_fraction': 0.3478791336428913}
observation time 0.000005, current best 2974.917007 at iter 12
suggestion time taken 0.002720 iter 13 next_points [{'alpha': 0.006812504135710509, 'batch_size': 177, 'beta_1': 0.879687525422684, 'beta_2': 0.9999976869306703, 'epsilon': 7.534834621307045e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.00770476418789892, 'tol': 0.0015976617090568562, 'validation_fraction': 0.42440755935260427}]
function_evaluation time 0.821870 value 3646.020567 suggestion {'alpha': 0.006812504135710509, 'batch_size': 177, 'beta_1': 0.879687525422684, 'beta_2': 0.9999976869306703, 'epsilon': 7.534834621307045e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.00770476418789892, 'tol': 0.0015976617090568562, 'validation_fraction': 0.42440755935260427}
observation time 0.000004, current best 2974.917007 at iter 13
suggestion time taken 0.002722 iter 14 next_points [{'alpha': 0.5690897718269534, 'batch_size': 210, 'beta_1': 0.7806760613899523, 'beta_2': 0.9998662805965619, 'epsilon': 8.699424055479095e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.02123855788772788, 'tol': 0.06555554457842842, 'validation_fraction': 0.7186742701274501}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.044083 value 28081.425057 suggestion {'alpha': 0.5690897718269534, 'batch_size': 210, 'beta_1': 0.7806760613899523, 'beta_2': 0.9998662805965619, 'epsilon': 8.699424055479095e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.02123855788772788, 'tol': 0.06555554457842842, 'validation_fraction': 0.7186742701274501}
observation time 0.000004, current best 2974.917007 at iter 14
saving meta data: {'args': {'--uuid': '776895a2d0335442be8226919a8cf173', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done
