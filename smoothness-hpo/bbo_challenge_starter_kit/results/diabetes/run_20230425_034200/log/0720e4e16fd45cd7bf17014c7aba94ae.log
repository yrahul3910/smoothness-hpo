running: {'--uuid': '0720e4e16fd45cd7bf17014c7aba94ae', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u 0720e4e16fd45cd7bf17014c7aba94ae -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study opentuner MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.031573 iter 0 next_points [{'hidden_layer_sizes': 98, 'alpha': 5.0625646171567995, 'batch_size': 169, 'learning_rate_init': 0.049892834508552024, 'tol': 0.09661128510674281, 'validation_fraction': 0.7998254969017303, 'beta_1': 0.680721884336372, 'beta_2': 0.9530201117394124, 'epsilon': 7.922295722270666e-08}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.140661 value 4066.970381 suggestion {'hidden_layer_sizes': 98, 'alpha': 5.0625646171567995, 'batch_size': 169, 'learning_rate_init': 0.049892834508552024, 'tol': 0.09661128510674281, 'validation_fraction': 0.7998254969017303, 'beta_1': 0.680721884336372, 'beta_2': 0.9530201117394124, 'epsilon': 7.922295722270666e-08}
observation time 0.004168, current best 4066.970381 at iter 0
suggestion time taken 0.007877 iter 1 next_points [{'hidden_layer_sizes': 98, 'alpha': 5.0625646171567995, 'batch_size': 150, 'learning_rate_init': 0.08012825745905598, 'tol': 0.08679906319163881, 'validation_fraction': 0.7998254969017303, 'beta_1': 0.5931826845739346, 'beta_2': 0.9583073222190398, 'epsilon': 1.4259306482852684e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.109321 value 3749.150692 suggestion {'hidden_layer_sizes': 98, 'alpha': 5.0625646171567995, 'batch_size': 150, 'learning_rate_init': 0.08012825745905598, 'tol': 0.08679906319163881, 'validation_fraction': 0.7998254969017303, 'beta_1': 0.5931826845739346, 'beta_2': 0.9583073222190398, 'epsilon': 1.4259306482852684e-07}
observation time 0.001996, current best 3749.150692 at iter 1
suggestion time taken 0.045352 iter 2 next_points [{'epsilon': 5.921976626027382e-07, 'learning_rate_init': 0.06369838881913618, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9306840295294122, 'alpha': 5.350706418274311, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}]
function_evaluation time 0.138679 value 3732.942154 suggestion {'epsilon': 5.921976626027382e-07, 'learning_rate_init': 0.06369838881913618, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9306840295294122, 'alpha': 5.350706418274311, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}
observation time 0.001832, current best 3732.942154 at iter 2
suggestion time taken 0.006763 iter 3 next_points [{'epsilon': 5.921976626027382e-07, 'learning_rate_init': 0.06369838881913618, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9337601175363482, 'alpha': 5.350706418274311, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}]
function_evaluation time 0.135762 value 3654.370005 suggestion {'epsilon': 5.921976626027382e-07, 'learning_rate_init': 0.06369838881913618, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9337601175363482, 'alpha': 5.350706418274311, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}
observation time 0.002057, current best 3654.370005 at iter 3
suggestion time taken 0.007196 iter 4 next_points [{'epsilon': 4.309696645393425e-07, 'learning_rate_init': 0.05708096659171285, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9337601175363482, 'alpha': 4.220357743911411, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}]
function_evaluation time 0.148709 value 3733.744361 suggestion {'epsilon': 4.309696645393425e-07, 'learning_rate_init': 0.05708096659171285, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9337601175363482, 'alpha': 4.220357743911411, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}
observation time 0.001746, current best 3654.370005 at iter 4
suggestion time taken 0.006448 iter 5 next_points [{'epsilon': 5.921976626027382e-07, 'learning_rate_init': 0.06369838881913618, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9055254808936256, 'alpha': 5.350706418274311, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}]
function_evaluation time 0.141787 value 3818.210996 suggestion {'epsilon': 5.921976626027382e-07, 'learning_rate_init': 0.06369838881913618, 'validation_fraction': 0.3418189821672806, 'beta_2': 0.9055254808936256, 'alpha': 5.350706418274311, 'tol': 0.09868188733541731, 'batch_size': 215, 'hidden_layer_sizes': 86, 'beta_1': 0.6585808323581601}
observation time 0.001963, current best 3654.370005 at iter 5
suggestion time taken 0.004996 iter 6 next_points [{'epsilon': 6.546888788044592e-07, 'learning_rate_init': 0.07370516699970946, 'validation_fraction': 0.26282879315139807, 'beta_2': 0.9454625476206677, 'alpha': 0.13829266815178615, 'tol': 0.009614715343092484, 'batch_size': 148, 'hidden_layer_sizes': 161, 'beta_1': 0.7474474973420648}]
function_evaluation time 0.237092 value 2993.334939 suggestion {'epsilon': 6.546888788044592e-07, 'learning_rate_init': 0.07370516699970946, 'validation_fraction': 0.26282879315139807, 'beta_2': 0.9454625476206677, 'alpha': 0.13829266815178615, 'tol': 0.009614715343092484, 'batch_size': 148, 'hidden_layer_sizes': 161, 'beta_1': 0.7474474973420648}
observation time 0.001796, current best 2993.334939 at iter 6
suggestion time taken 0.006253 iter 7 next_points [{'hidden_layer_sizes': 51, 'alpha': 2.760050884274123, 'batch_size': 13, 'learning_rate_init': 0.03696982758728667, 'tol': 0.08222272959194925, 'validation_fraction': 0.7562749843774808, 'beta_1': 0.7477496063794925, 'beta_2': 0.9191373769357056, 'epsilon': 1.5989459525908478e-07}]
function_evaluation time 0.186373 value 3797.737208 suggestion {'hidden_layer_sizes': 51, 'alpha': 2.760050884274123, 'batch_size': 13, 'learning_rate_init': 0.03696982758728667, 'tol': 0.08222272959194925, 'validation_fraction': 0.7562749843774808, 'beta_1': 0.7477496063794925, 'beta_2': 0.9191373769357056, 'epsilon': 1.5989459525908478e-07}
observation time 0.001796, current best 2993.334939 at iter 7
suggestion time taken 0.005394 iter 8 next_points [{'epsilon': 1.4792894856338512e-07, 'learning_rate_init': 0.07987831825291562, 'validation_fraction': 0.4722058836101879, 'beta_2': 0.9978454163326483, 'alpha': 0.7507743746344385, 'tol': 0.031086221359609856, 'batch_size': 140, 'hidden_layer_sizes': 144, 'beta_1': 0.6472786832367622}]
function_evaluation time 0.136142 value 3257.791882 suggestion {'epsilon': 1.4792894856338512e-07, 'learning_rate_init': 0.07987831825291562, 'validation_fraction': 0.4722058836101879, 'beta_2': 0.9978454163326483, 'alpha': 0.7507743746344385, 'tol': 0.031086221359609856, 'batch_size': 140, 'hidden_layer_sizes': 144, 'beta_1': 0.6472786832367622}
observation time 0.001842, current best 2993.334939 at iter 8
suggestion time taken 0.005161 iter 9 next_points [{'epsilon': 7.815055657339466e-07, 'learning_rate_init': 0.01498217714651411, 'validation_fraction': 0.7695534148929438, 'beta_2': 0.9500028797706763, 'alpha': 1.4323308331440514, 'tol': 0.0848506936330579, 'batch_size': 34, 'hidden_layer_sizes': 100, 'beta_1': 0.5039044376996158}]
function_evaluation time 0.163286 value 13532.693767 suggestion {'epsilon': 7.815055657339466e-07, 'learning_rate_init': 0.01498217714651411, 'validation_fraction': 0.7695534148929438, 'beta_2': 0.9500028797706763, 'alpha': 1.4323308331440514, 'tol': 0.0848506936330579, 'batch_size': 34, 'hidden_layer_sizes': 100, 'beta_1': 0.5039044376996158}
observation time 0.001831, current best 2993.334939 at iter 9
suggestion time taken 0.005786 iter 10 next_points [{'hidden_layer_sizes': 73, 'alpha': 4.4511200589101625, 'batch_size': 201, 'learning_rate_init': 0.02746601534569686, 'tol': 0.008352716819866424, 'validation_fraction': 0.22712084183346778, 'beta_1': 0.5296758804090875, 'beta_2': 0.9983653751159176, 'epsilon': 8.935094805434241e-07}]
function_evaluation time 0.243853 value 3628.014514 suggestion {'hidden_layer_sizes': 73, 'alpha': 4.4511200589101625, 'batch_size': 201, 'learning_rate_init': 0.02746601534569686, 'tol': 0.008352716819866424, 'validation_fraction': 0.22712084183346778, 'beta_1': 0.5296758804090875, 'beta_2': 0.9983653751159176, 'epsilon': 8.935094805434241e-07}
observation time 0.002633, current best 2993.334939 at iter 10
suggestion time taken 0.006855 iter 11 next_points [{'epsilon': 5.366997498928706e-07, 'learning_rate_init': 0.07284695027216818, 'validation_fraction': 0.26282879315139807, 'beta_2': 0.9454625476206677, 'alpha': 0.13829266815178615, 'tol': 0.0004701503708001609, 'batch_size': 148, 'hidden_layer_sizes': 161, 'beta_1': 0.6992087743421403}]
function_evaluation time 0.378355 value 3039.520570 suggestion {'epsilon': 5.366997498928706e-07, 'learning_rate_init': 0.07284695027216818, 'validation_fraction': 0.26282879315139807, 'beta_2': 0.9454625476206677, 'alpha': 0.13829266815178615, 'tol': 0.0004701503708001609, 'batch_size': 148, 'hidden_layer_sizes': 161, 'beta_1': 0.6992087743421403}
observation time 0.002027, current best 2993.334939 at iter 11
suggestion time taken 0.006976 iter 12 next_points [{'epsilon': 6.546888788044592e-07, 'learning_rate_init': 0.07370516699970946, 'validation_fraction': 0.5907605914182514, 'beta_2': 0.9877644671404038, 'alpha': 0.521901969219641, 'tol': 0.009614715343092484, 'batch_size': 148, 'hidden_layer_sizes': 199, 'beta_1': 0.7474474973420648}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.200979 value 3153.824022 suggestion {'epsilon': 6.546888788044592e-07, 'learning_rate_init': 0.07370516699970946, 'validation_fraction': 0.5907605914182514, 'beta_2': 0.9877644671404038, 'alpha': 0.521901969219641, 'tol': 0.009614715343092484, 'batch_size': 148, 'hidden_layer_sizes': 199, 'beta_1': 0.7474474973420648}
observation time 0.001848, current best 2993.334939 at iter 12
suggestion time taken 0.005149 iter 13 next_points [{'epsilon': 3.606985613807391e-07, 'learning_rate_init': 0.05125699777339603, 'validation_fraction': 0.5845616913280184, 'beta_2': 0.9134475321466629, 'alpha': 2.626518206725732, 'tol': 0.06209170756138709, 'batch_size': 94, 'hidden_layer_sizes': 115, 'beta_1': 0.6219056504997401}]
function_evaluation time 0.135331 value 3476.755954 suggestion {'epsilon': 3.606985613807391e-07, 'learning_rate_init': 0.05125699777339603, 'validation_fraction': 0.5845616913280184, 'beta_2': 0.9134475321466629, 'alpha': 2.626518206725732, 'tol': 0.06209170756138709, 'batch_size': 94, 'hidden_layer_sizes': 115, 'beta_1': 0.6219056504997401}
observation time 0.001814, current best 2993.334939 at iter 13
suggestion time taken 0.005057 iter 14 next_points [{'epsilon': 6.649358129945094e-07, 'learning_rate_init': 0.07490172377558084, 'validation_fraction': 0.21004884077655897, 'beta_2': 0.9457931214060593, 'alpha': 0.27006650641669755, 'tol': 0.04095335193032106, 'batch_size': 73, 'hidden_layer_sizes': 90, 'beta_1': 0.503158743387959}]
function_evaluation time 0.093044 value 3178.086704 suggestion {'epsilon': 6.649358129945094e-07, 'learning_rate_init': 0.07490172377558084, 'validation_fraction': 0.21004884077655897, 'beta_2': 0.9457931214060593, 'alpha': 0.27006650641669755, 'tol': 0.04095335193032106, 'batch_size': 73, 'hidden_layer_sizes': 90, 'beta_1': 0.503158743387959}
observation time 0.001760, current best 2993.334939 at iter 14
saving meta data: {'args': {'--uuid': '0720e4e16fd45cd7bf17014c7aba94ae', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done
