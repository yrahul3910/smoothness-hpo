running: {'--uuid': 'cc260de283235d4698c44c879198298c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u cc260de283235d4698c44c879198298c -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study turbo MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002170 iter 0 next_points [{'alpha': 0.009465096585273523, 'batch_size': 119, 'beta_1': 0.966907343409367, 'beta_2': 0.9999987497395135, 'epsilon': 1.186500821485956e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 1.9300347378297448e-05, 'tol': 0.0002571691613706836, 'validation_fraction': 0.8702197437265311}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051172 value 29120.207949 suggestion {'alpha': 0.009465096585273523, 'batch_size': 119, 'beta_1': 0.966907343409367, 'beta_2': 0.9999987497395135, 'epsilon': 1.186500821485956e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 1.9300347378297448e-05, 'tol': 0.0002571691613706836, 'validation_fraction': 0.8702197437265311}
observation time 0.001429, current best 29120.207949 at iter 0
suggestion time taken 0.001758 iter 1 next_points [{'alpha': 0.0005133442005900186, 'batch_size': 83, 'beta_1': 0.8338288841053533, 'beta_2': 0.9967416906669743, 'epsilon': 4.1984531344170554e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.010790057725140035, 'tol': 5.1654743447909575e-05, 'validation_fraction': 0.11255923779001174}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.663194 value 3710.716351 suggestion {'alpha': 0.0005133442005900186, 'batch_size': 83, 'beta_1': 0.8338288841053533, 'beta_2': 0.9967416906669743, 'epsilon': 4.1984531344170554e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.010790057725140035, 'tol': 5.1654743447909575e-05, 'validation_fraction': 0.11255923779001174}
observation time 0.001420, current best 3710.716351 at iter 1
suggestion time taken 0.001779 iter 2 next_points [{'alpha': 7.063975234035065e-05, 'batch_size': 12, 'beta_1': 0.9464060337623976, 'beta_2': 0.9873669212193882, 'epsilon': 4.9638151597510404e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.00047620461024270856, 'tol': 0.0010803135645277707, 'validation_fraction': 0.20876140593313958}]
function_evaluation time 2.936232 value 4307.064708 suggestion {'alpha': 7.063975234035065e-05, 'batch_size': 12, 'beta_1': 0.9464060337623976, 'beta_2': 0.9873669212193882, 'epsilon': 4.9638151597510404e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.00047620461024270856, 'tol': 0.0010803135645277707, 'validation_fraction': 0.20876140593313958}
observation time 0.001430, current best 3710.716351 at iter 2
suggestion time taken 0.001725 iter 3 next_points [{'alpha': 0.04612760855136254, 'batch_size': 35, 'beta_1': 0.7721333231252654, 'beta_2': 0.9998625802141671, 'epsilon': 8.284617620179704e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00016559247649759087, 'tol': 0.0016074660700597417, 'validation_fraction': 0.7947297099331386}]
function_evaluation time 0.073454 value 29120.281555 suggestion {'alpha': 0.04612760855136254, 'batch_size': 35, 'beta_1': 0.7721333231252654, 'beta_2': 0.9998625802141671, 'epsilon': 8.284617620179704e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00016559247649759087, 'tol': 0.0016074660700597417, 'validation_fraction': 0.7947297099331386}
observation time 0.001393, current best 3710.716351 at iter 3
suggestion time taken 0.001801 iter 4 next_points [{'alpha': 0.005847809582182254, 'batch_size': 47, 'beta_1': 0.7525267670426726, 'beta_2': 0.9999878224308537, 'epsilon': 6.653657456041559e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 4.0296847069983846e-05, 'tol': 0.0023476530611887276, 'validation_fraction': 0.2840735877226011}]
function_evaluation time 0.124493 value 29084.838104 suggestion {'alpha': 0.005847809582182254, 'batch_size': 47, 'beta_1': 0.7525267670426726, 'beta_2': 0.9999878224308537, 'epsilon': 6.653657456041559e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 4.0296847069983846e-05, 'tol': 0.0023476530611887276, 'validation_fraction': 0.2840735877226011}
observation time 0.001379, current best 3710.716351 at iter 4
suggestion time taken 0.001768 iter 5 next_points [{'alpha': 0.49572810092054986, 'batch_size': 215, 'beta_1': 0.6153801038089728, 'beta_2': 0.9741318571867745, 'epsilon': 1.8391547340162042e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0012203126893936354, 'tol': 0.00015340821498376316, 'validation_fraction': 0.3892245875244054}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.006927 value 26181.667157 suggestion {'alpha': 0.49572810092054986, 'batch_size': 215, 'beta_1': 0.6153801038089728, 'beta_2': 0.9741318571867745, 'epsilon': 1.8391547340162042e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0012203126893936354, 'tol': 0.00015340821498376316, 'validation_fraction': 0.3892245875244054}
observation time 0.001420, current best 3710.716351 at iter 5
suggestion time taken 0.001960 iter 6 next_points [{'alpha': 2.3963896669850575, 'batch_size': 209, 'beta_1': 0.9859144698417507, 'beta_2': 0.9986922566028124, 'epsilon': 2.0660370964607585e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.000250406273731967, 'tol': 0.004201848645070252, 'validation_fraction': 0.23583992970029885}]
function_evaluation time 0.081447 value 29076.277065 suggestion {'alpha': 2.3963896669850575, 'batch_size': 209, 'beta_1': 0.9859144698417507, 'beta_2': 0.9986922566028124, 'epsilon': 2.0660370964607585e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.000250406273731967, 'tol': 0.004201848645070252, 'validation_fraction': 0.23583992970029885}
observation time 0.001400, current best 3710.716351 at iter 6
suggestion time taken 0.001814 iter 7 next_points [{'alpha': 0.0028129583591379745, 'batch_size': 143, 'beta_1': 0.8977622637338128, 'beta_2': 0.948498231275355, 'epsilon': 1.8789934840107942e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0006484171502567226, 'tol': 0.0006748775538426417, 'validation_fraction': 0.31265436160520543}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.134273 value 27015.479059 suggestion {'alpha': 0.0028129583591379745, 'batch_size': 143, 'beta_1': 0.8977622637338128, 'beta_2': 0.948498231275355, 'epsilon': 1.8789934840107942e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0006484171502567226, 'tol': 0.0006748775538426417, 'validation_fraction': 0.31265436160520543}
observation time 0.001356, current best 3710.716351 at iter 7
suggestion time taken 0.001756 iter 8 next_points [{'alpha': 1.2249307298875339e-05, 'batch_size': 176, 'beta_1': 0.9801095921464944, 'beta_2': 0.9978586741607415, 'epsilon': 2.8240689051434047e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.07607969351577311, 'tol': 0.02624327348295346, 'validation_fraction': 0.677213650882794}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.141141 value 4228.095769 suggestion {'alpha': 1.2249307298875339e-05, 'batch_size': 176, 'beta_1': 0.9801095921464944, 'beta_2': 0.9978586741607415, 'epsilon': 2.8240689051434047e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.07607969351577311, 'tol': 0.02624327348295346, 'validation_fraction': 0.677213650882794}
observation time 0.001429, current best 3710.716351 at iter 8
suggestion time taken 0.001786 iter 9 next_points [{'alpha': 0.000221795926734407, 'batch_size': 248, 'beta_1': 0.7118465840166118, 'beta_2': 0.9999786555503652, 'epsilon': 7.561952595021136e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 1.020066274546217e-05, 'tol': 3.7378553959692456e-05, 'validation_fraction': 0.15694180954780906}]
function_evaluation time 0.057389 value 29074.098676 suggestion {'alpha': 0.000221795926734407, 'batch_size': 248, 'beta_1': 0.7118465840166118, 'beta_2': 0.9999786555503652, 'epsilon': 7.561952595021136e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 1.020066274546217e-05, 'tol': 3.7378553959692456e-05, 'validation_fraction': 0.15694180954780906}
observation time 0.001423, current best 3710.716351 at iter 9
suggestion time taken 0.001770 iter 10 next_points [{'alpha': 0.15772385784846094, 'batch_size': 158, 'beta_1': 0.9708957255689673, 'beta_2': 0.9999287356617749, 'epsilon': 1.63470778176006e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.00269167287464413, 'tol': 7.120545932175283e-05, 'validation_fraction': 0.8897413461765553}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.602284 value 24857.302682 suggestion {'alpha': 0.15772385784846094, 'batch_size': 158, 'beta_1': 0.9708957255689673, 'beta_2': 0.9999287356617749, 'epsilon': 1.63470778176006e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.00269167287464413, 'tol': 7.120545932175283e-05, 'validation_fraction': 0.8897413461765553}
observation time 0.001350, current best 3710.716351 at iter 10
suggestion time taken 0.001694 iter 11 next_points [{'alpha': 2.5970210553416472e-05, 'batch_size': 69, 'beta_1': 0.957855118419482, 'beta_2': 0.9333577394444856, 'epsilon': 5.443105903115009e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0036025168665069726, 'tol': 0.012797452874121566, 'validation_fraction': 0.8197226629001972}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051836 value 28903.087210 suggestion {'alpha': 2.5970210553416472e-05, 'batch_size': 69, 'beta_1': 0.957855118419482, 'beta_2': 0.9333577394444856, 'epsilon': 5.443105903115009e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0036025168665069726, 'tol': 0.012797452874121566, 'validation_fraction': 0.8197226629001972}
observation time 0.001453, current best 3710.716351 at iter 11
suggestion time taken 0.001707 iter 12 next_points [{'alpha': 1.1193953869729998, 'batch_size': 232, 'beta_1': 0.912411898710282, 'beta_2': 0.9932134590534611, 'epsilon': 1.385151934349876e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 9.176857364808894e-05, 'tol': 0.08947953313726913, 'validation_fraction': 0.7286798473811646}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.045759 value 29098.990838 suggestion {'alpha': 1.1193953869729998, 'batch_size': 232, 'beta_1': 0.912411898710282, 'beta_2': 0.9932134590534611, 'epsilon': 1.385151934349876e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 9.176857364808894e-05, 'tol': 0.08947953313726913, 'validation_fraction': 0.7286798473811646}
observation time 0.001374, current best 3710.716351 at iter 12
suggestion time taken 0.001732 iter 13 next_points [{'alpha': 0.10411294665977075, 'batch_size': 126, 'beta_1': 0.8594184479379453, 'beta_2': 0.9998749962046592, 'epsilon': 1.2658997935636304e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.024437775140970855, 'tol': 0.04348996902941658, 'validation_fraction': 0.6054981657680666}]
function_evaluation time 0.246582 value 3953.380060 suggestion {'alpha': 0.10411294665977075, 'batch_size': 126, 'beta_1': 0.8594184479379453, 'beta_2': 0.9998749962046592, 'epsilon': 1.2658997935636304e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.024437775140970855, 'tol': 0.04348996902941658, 'validation_fraction': 0.6054981657680666}
observation time 0.001369, current best 3710.716351 at iter 13
suggestion time taken 0.001760 iter 14 next_points [{'alpha': 1.4810628624576625, 'batch_size': 111, 'beta_1': 0.975832499382532, 'beta_2': 0.9999953217714713, 'epsilon': 3.2074250728412194e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 5.8323561199897836e-05, 'tol': 0.01697296133875264, 'validation_fraction': 0.46698154687406424}]
function_evaluation time 0.044926 value 29083.411672 suggestion {'alpha': 1.4810628624576625, 'batch_size': 111, 'beta_1': 0.975832499382532, 'beta_2': 0.9999953217714713, 'epsilon': 3.2074250728412194e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 5.8323561199897836e-05, 'tol': 0.01697296133875264, 'validation_fraction': 0.46698154687406424}
observation time 0.001443, current best 3710.716351 at iter 14
saving meta data: {'args': {'--uuid': 'cc260de283235d4698c44c879198298c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done
