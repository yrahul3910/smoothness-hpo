running: {'--uuid': 'b729c8b1234959a4a44676d9369ecc81', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u b729c8b1234959a4a44676d9369ecc81 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study random-search MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002490 iter 0 next_points [{'alpha': 0.0015518309148139034, 'batch_size': 111, 'beta_1': 0.8015945595958082, 'beta_2': 0.9998453718350953, 'epsilon': 2.9135506184570884e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 2.0984640209373993e-05, 'tol': 0.02690733883534694, 'validation_fraction': 0.37900478181940556}]
function_evaluation time 0.049179 value 151.605955 suggestion {'alpha': 0.0015518309148139034, 'batch_size': 111, 'beta_1': 0.8015945595958082, 'beta_2': 0.9998453718350953, 'epsilon': 2.9135506184570884e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 2.0984640209373993e-05, 'tol': 0.02690733883534694, 'validation_fraction': 0.37900478181940556}
observation time 0.000006, current best 151.605955 at iter 0
suggestion time taken 0.002518 iter 1 next_points [{'alpha': 0.002013507600257936, 'batch_size': 189, 'beta_1': 0.924755702525637, 'beta_2': 0.9982265009735569, 'epsilon': 7.457486867269347e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 2.2691491890529133e-05, 'tol': 0.0002492649644925215, 'validation_fraction': 0.4749248244338954}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.059854 value 151.662467 suggestion {'alpha': 0.002013507600257936, 'batch_size': 189, 'beta_1': 0.924755702525637, 'beta_2': 0.9982265009735569, 'epsilon': 7.457486867269347e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 2.2691491890529133e-05, 'tol': 0.0002492649644925215, 'validation_fraction': 0.4749248244338954}
observation time 0.000004, current best 151.605955 at iter 1
suggestion time taken 0.002712 iter 2 next_points [{'alpha': 0.0014802709525438137, 'batch_size': 23, 'beta_1': 0.948031561451884, 'beta_2': 0.9998204439772889, 'epsilon': 7.506638925780622e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0012725246004999617, 'tol': 0.0006344310901358799, 'validation_fraction': 0.4833342310940232}]
function_evaluation time 1.934376 value 54.002431 suggestion {'alpha': 0.0014802709525438137, 'batch_size': 23, 'beta_1': 0.948031561451884, 'beta_2': 0.9998204439772889, 'epsilon': 7.506638925780622e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0012725246004999617, 'tol': 0.0006344310901358799, 'validation_fraction': 0.4833342310940232}
observation time 0.000004, current best 54.002431 at iter 2
suggestion time taken 0.002482 iter 3 next_points [{'alpha': 1.1670533038301781e-05, 'batch_size': 96, 'beta_1': 0.9692556984207827, 'beta_2': 0.9999888672370141, 'epsilon': 4.878392464689973e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0016772838066375902, 'tol': 0.0023724128287222045, 'validation_fraction': 0.6527935264750855}]
function_evaluation time 0.060051 value 151.063148 suggestion {'alpha': 1.1670533038301781e-05, 'batch_size': 96, 'beta_1': 0.9692556984207827, 'beta_2': 0.9999888672370141, 'epsilon': 4.878392464689973e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0016772838066375902, 'tol': 0.0023724128287222045, 'validation_fraction': 0.6527935264750855}
observation time 0.000004, current best 54.002431 at iter 3
suggestion time taken 0.002503 iter 4 next_points [{'alpha': 0.00010256450816088269, 'batch_size': 74, 'beta_1': 0.582168334650286, 'beta_2': 0.999990642869173, 'epsilon': 1.7120285872163202e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.004533911488830295, 'tol': 0.01508527777224405, 'validation_fraction': 0.6793401452694157}]
function_evaluation time 0.630745 value 55.091954 suggestion {'alpha': 0.00010256450816088269, 'batch_size': 74, 'beta_1': 0.582168334650286, 'beta_2': 0.999990642869173, 'epsilon': 1.7120285872163202e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.004533911488830295, 'tol': 0.01508527777224405, 'validation_fraction': 0.6793401452694157}
observation time 0.000004, current best 54.002431 at iter 4
suggestion time taken 0.002498 iter 5 next_points [{'alpha': 0.01983055597590239, 'batch_size': 120, 'beta_1': 0.984529597690704, 'beta_2': 0.9233858839091768, 'epsilon': 2.4162129004108645e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 5.829280536635185e-05, 'tol': 0.02354712667088927, 'validation_fraction': 0.4879386837658824}]
function_evaluation time 0.061450 value 151.569073 suggestion {'alpha': 0.01983055597590239, 'batch_size': 120, 'beta_1': 0.984529597690704, 'beta_2': 0.9233858839091768, 'epsilon': 2.4162129004108645e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 5.829280536635185e-05, 'tol': 0.02354712667088927, 'validation_fraction': 0.4879386837658824}
observation time 0.000004, current best 54.002431 at iter 5
suggestion time taken 0.002767 iter 6 next_points [{'alpha': 1.6604559828941898, 'batch_size': 247, 'beta_1': 0.8664807030301339, 'beta_2': 0.9933711163412862, 'epsilon': 7.289029966495933e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 3.600444316967061e-05, 'tol': 0.009259194266130812, 'validation_fraction': 0.13406637967480384}]
function_evaluation time 0.059371 value 151.737113 suggestion {'alpha': 1.6604559828941898, 'batch_size': 247, 'beta_1': 0.8664807030301339, 'beta_2': 0.9933711163412862, 'epsilon': 7.289029966495933e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 3.600444316967061e-05, 'tol': 0.009259194266130812, 'validation_fraction': 0.13406637967480384}
observation time 0.000005, current best 54.002431 at iter 6
suggestion time taken 0.002488 iter 7 next_points [{'alpha': 0.0022270491909840403, 'batch_size': 53, 'beta_1': 0.7415165934382968, 'beta_2': 0.9788127912784544, 'epsilon': 2.387899047848835e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0019536772791889398, 'tol': 0.00021215081376757015, 'validation_fraction': 0.29734124427016}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.066834 value 57.347498 suggestion {'alpha': 0.0022270491909840403, 'batch_size': 53, 'beta_1': 0.7415165934382968, 'beta_2': 0.9788127912784544, 'epsilon': 2.387899047848835e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0019536772791889398, 'tol': 0.00021215081376757015, 'validation_fraction': 0.29734124427016}
observation time 0.000004, current best 54.002431 at iter 7
suggestion time taken 0.002774 iter 8 next_points [{'alpha': 0.006516997219645492, 'batch_size': 218, 'beta_1': 0.5331080792234648, 'beta_2': 0.9999951569079659, 'epsilon': 7.451477424192767e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00011656237297786741, 'tol': 0.015474711883092147, 'validation_fraction': 0.7817659159714878}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.044087 value 151.612518 suggestion {'alpha': 0.006516997219645492, 'batch_size': 218, 'beta_1': 0.5331080792234648, 'beta_2': 0.9999951569079659, 'epsilon': 7.451477424192767e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00011656237297786741, 'tol': 0.015474711883092147, 'validation_fraction': 0.7817659159714878}
observation time 0.000004, current best 54.002431 at iter 8
suggestion time taken 0.002482 iter 9 next_points [{'alpha': 0.011895150363177273, 'batch_size': 73, 'beta_1': 0.8495963319855184, 'beta_2': 0.9665872404387946, 'epsilon': 3.896974252580247e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0019127581460632167, 'tol': 7.094831899150945e-05, 'validation_fraction': 0.6817377045619977}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.875682 value 124.135860 suggestion {'alpha': 0.011895150363177273, 'batch_size': 73, 'beta_1': 0.8495963319855184, 'beta_2': 0.9665872404387946, 'epsilon': 3.896974252580247e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0019127581460632167, 'tol': 7.094831899150945e-05, 'validation_fraction': 0.6817377045619977}
observation time 0.000003, current best 54.002431 at iter 9
suggestion time taken 0.002441 iter 10 next_points [{'alpha': 4.1779938951008, 'batch_size': 199, 'beta_1': 0.9829705314450526, 'beta_2': 0.9988499344997908, 'epsilon': 1.954987049760514e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0008709045822668867, 'tol': 0.001459662161867588, 'validation_fraction': 0.44675836612529585}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.036345 value 151.579783 suggestion {'alpha': 4.1779938951008, 'batch_size': 199, 'beta_1': 0.9829705314450526, 'beta_2': 0.9988499344997908, 'epsilon': 1.954987049760514e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0008709045822668867, 'tol': 0.001459662161867588, 'validation_fraction': 0.44675836612529585}
observation time 0.000004, current best 54.002431 at iter 10
suggestion time taken 0.002472 iter 11 next_points [{'alpha': 0.0006120417617122516, 'batch_size': 157, 'beta_1': 0.5454506619080949, 'beta_2': 0.9978175561837168, 'epsilon': 4.387561362327539e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 9.102543444465938e-05, 'tol': 0.03236782686172523, 'validation_fraction': 0.21485737204969546}]
function_evaluation time 0.093014 value 151.581487 suggestion {'alpha': 0.0006120417617122516, 'batch_size': 157, 'beta_1': 0.5454506619080949, 'beta_2': 0.9978175561837168, 'epsilon': 4.387561362327539e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 9.102543444465938e-05, 'tol': 0.03236782686172523, 'validation_fraction': 0.21485737204969546}
observation time 0.000005, current best 54.002431 at iter 11
suggestion time taken 0.002462 iter 12 next_points [{'alpha': 1.2700394354268616e-05, 'batch_size': 119, 'beta_1': 0.7779513356472746, 'beta_2': 0.9999124684945877, 'epsilon': 2.2132220918880377e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.069722602298234, 'tol': 0.0006968647505910734, 'validation_fraction': 0.8817392315368342}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.225228 value 48.450708 suggestion {'alpha': 1.2700394354268616e-05, 'batch_size': 119, 'beta_1': 0.7779513356472746, 'beta_2': 0.9999124684945877, 'epsilon': 2.2132220918880377e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.069722602298234, 'tol': 0.0006968647505910734, 'validation_fraction': 0.8817392315368342}
observation time 0.000004, current best 48.450708 at iter 12
suggestion time taken 0.002422 iter 13 next_points [{'alpha': 0.021978738675778004, 'batch_size': 62, 'beta_1': 0.9787932898172208, 'beta_2': 0.9961391283862855, 'epsilon': 1.3818214349929615e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00010491589888541535, 'tol': 0.0011615912040359993, 'validation_fraction': 0.2103463850755838}]
function_evaluation time 0.060288 value 151.619756 suggestion {'alpha': 0.021978738675778004, 'batch_size': 62, 'beta_1': 0.9787932898172208, 'beta_2': 0.9961391283862855, 'epsilon': 1.3818214349929615e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00010491589888541535, 'tol': 0.0011615912040359993, 'validation_fraction': 0.2103463850755838}
observation time 0.000004, current best 48.450708 at iter 13
suggestion time taken 0.002564 iter 14 next_points [{'alpha': 1.614925829838176, 'batch_size': 126, 'beta_1': 0.987018161915534, 'beta_2': 0.9943879231656784, 'epsilon': 1.3989364181000024e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0006711311372444458, 'tol': 0.00010014306314000934, 'validation_fraction': 0.14123836813733384}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.107586 value 145.794752 suggestion {'alpha': 1.614925829838176, 'batch_size': 126, 'beta_1': 0.987018161915534, 'beta_2': 0.9943879231656784, 'epsilon': 1.3989364181000024e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0006711311372444458, 'tol': 0.00010014306314000934, 'validation_fraction': 0.14123836813733384}
observation time 0.000004, current best 48.450708 at iter 14
saving meta data: {'args': {'--uuid': 'b729c8b1234959a4a44676d9369ecc81', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done
