running: {'--uuid': '8c30098d03c9538cbec56925ea1997b5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 8c30098d03c9538cbec56925ea1997b5 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study turbo MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002120 iter 0 next_points [{'alpha': 0.004298650219978776, 'batch_size': 62, 'beta_1': 0.974314875783367, 'beta_2': 0.9999986883400218, 'epsilon': 8.683073049244772e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.007771295937500707, 'tol': 0.0624460882248882, 'validation_fraction': 0.8589528752358564}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052892 value 149.882642 suggestion {'alpha': 0.004298650219978776, 'batch_size': 62, 'beta_1': 0.974314875783367, 'beta_2': 0.9999986883400218, 'epsilon': 8.683073049244772e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.007771295937500707, 'tol': 0.0624460882248882, 'validation_fraction': 0.8589528752358564}
observation time 0.001408, current best 149.882642 at iter 0
suggestion time taken 0.001786 iter 1 next_points [{'alpha': 2.5200181409892468e-05, 'batch_size': 239, 'beta_1': 0.9132650200240561, 'beta_2': 0.9850080203814802, 'epsilon': 1.6867374756232023e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0240123671724311, 'tol': 0.0006511486869568013, 'validation_fraction': 0.699392162489123}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.420123 value 51.568034 suggestion {'alpha': 2.5200181409892468e-05, 'batch_size': 239, 'beta_1': 0.9132650200240561, 'beta_2': 0.9850080203814802, 'epsilon': 1.6867374756232023e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0240123671724311, 'tol': 0.0006511486869568013, 'validation_fraction': 0.699392162489123}
observation time 0.001414, current best 51.568034 at iter 1
suggestion time taken 0.001755 iter 2 next_points [{'alpha': 0.33776234046754655, 'batch_size': 49, 'beta_1': 0.6825661177444723, 'beta_2': 0.9999976507596053, 'epsilon': 2.4056900924459466e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0013848272490014186, 'tol': 0.014352334198864019, 'validation_fraction': 0.5635918586757646}]
function_evaluation time 0.093097 value 150.570800 suggestion {'alpha': 0.33776234046754655, 'batch_size': 49, 'beta_1': 0.6825661177444723, 'beta_2': 0.9999976507596053, 'epsilon': 2.4056900924459466e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0013848272490014186, 'tol': 0.014352334198864019, 'validation_fraction': 0.5635918586757646}
observation time 0.001389, current best 51.568034 at iter 2
suggestion time taken 0.001970 iter 3 next_points [{'alpha': 0.00026379634121740807, 'batch_size': 230, 'beta_1': 0.7519920830245032, 'beta_2': 0.9714557783730889, 'epsilon': 3.402264000767044e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 4.950095502372162e-05, 'tol': 1.4658173602145264e-05, 'validation_fraction': 0.84777539038461}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.569708 value 151.369214 suggestion {'alpha': 0.00026379634121740807, 'batch_size': 230, 'beta_1': 0.7519920830245032, 'beta_2': 0.9714557783730889, 'epsilon': 3.402264000767044e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 4.950095502372162e-05, 'tol': 1.4658173602145264e-05, 'validation_fraction': 0.84777539038461}
observation time 0.001369, current best 51.568034 at iter 3
suggestion time taken 0.001963 iter 4 next_points [{'alpha': 0.0010074271989303591, 'batch_size': 138, 'beta_1': 0.9641719071774487, 'beta_2': 0.9978327158153761, 'epsilon': 2.0554293591673765e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.041156038311387075, 'tol': 7.990975505344756e-05, 'validation_fraction': 0.6175120145625852}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.214373 value 54.966293 suggestion {'alpha': 0.0010074271989303591, 'batch_size': 138, 'beta_1': 0.9641719071774487, 'beta_2': 0.9978327158153761, 'epsilon': 2.0554293591673765e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.041156038311387075, 'tol': 7.990975505344756e-05, 'validation_fraction': 0.6175120145625852}
observation time 0.001408, current best 51.568034 at iter 4
suggestion time taken 0.001688 iter 5 next_points [{'alpha': 4.940731266863965e-05, 'batch_size': 184, 'beta_1': 0.7760911392452844, 'beta_2': 0.9996928663713024, 'epsilon': 7.4106677694798695e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.009065416519251518, 'tol': 0.028255978464999408, 'validation_fraction': 0.8099290759347981}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.059143 value 149.101529 suggestion {'alpha': 4.940731266863965e-05, 'batch_size': 184, 'beta_1': 0.7760911392452844, 'beta_2': 0.9996928663713024, 'epsilon': 7.4106677694798695e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.009065416519251518, 'tol': 0.028255978464999408, 'validation_fraction': 0.8099290759347981}
observation time 0.001410, current best 51.568034 at iter 5
suggestion time taken 0.001747 iter 6 next_points [{'alpha': 0.941684909057029, 'batch_size': 84, 'beta_1': 0.8863732616667935, 'beta_2': 0.9998298286267001, 'epsilon': 4.7897781823146846e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.00023132007109044508, 'tol': 0.0025164011652522166, 'validation_fraction': 0.404480953726991}]
function_evaluation time 0.075490 value 151.519911 suggestion {'alpha': 0.941684909057029, 'batch_size': 84, 'beta_1': 0.8863732616667935, 'beta_2': 0.9998298286267001, 'epsilon': 4.7897781823146846e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.00023132007109044508, 'tol': 0.0025164011652522166, 'validation_fraction': 0.404480953726991}
observation time 0.001432, current best 51.568034 at iter 6
suggestion time taken 0.001728 iter 7 next_points [{'alpha': 0.12824378997913555, 'batch_size': 195, 'beta_1': 0.969626501258392, 'beta_2': 0.9999869848096319, 'epsilon': 1.3987108702722849e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0011058990304424604, 'tol': 0.006226993774008837, 'validation_fraction': 0.4543424632274517}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.056049 value 151.462488 suggestion {'alpha': 0.12824378997913555, 'batch_size': 195, 'beta_1': 0.969626501258392, 'beta_2': 0.9999869848096319, 'epsilon': 1.3987108702722849e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0011058990304424604, 'tol': 0.006226993774008837, 'validation_fraction': 0.4543424632274517}
observation time 0.001409, current best 51.568034 at iter 7
suggestion time taken 0.001760 iter 8 next_points [{'alpha': 0.09653837511830163, 'batch_size': 33, 'beta_1': 0.9886733610635022, 'beta_2': 0.9999914447673958, 'epsilon': 1.923975328455159e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 8.563501691800195e-05, 'tol': 0.01568559244981866, 'validation_fraction': 0.17906563661833663}]
function_evaluation time 0.088431 value 151.559314 suggestion {'alpha': 0.09653837511830163, 'batch_size': 33, 'beta_1': 0.9886733610635022, 'beta_2': 0.9999914447673958, 'epsilon': 1.923975328455159e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 8.563501691800195e-05, 'tol': 0.01568559244981866, 'validation_fraction': 0.17906563661833663}
observation time 0.001466, current best 51.568034 at iter 8
suggestion time taken 0.001897 iter 9 next_points [{'alpha': 0.00013069083239249034, 'batch_size': 149, 'beta_1': 0.5484706613107729, 'beta_2': 0.9674952398254432, 'epsilon': 4.922241062296684e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.00015096569565141636, 'tol': 0.00018238039684785064, 'validation_fraction': 0.7748005036485004}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.049906 value 151.414101 suggestion {'alpha': 0.00013069083239249034, 'batch_size': 149, 'beta_1': 0.5484706613107729, 'beta_2': 0.9674952398254432, 'epsilon': 4.922241062296684e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.00015096569565141636, 'tol': 0.00018238039684785064, 'validation_fraction': 0.7748005036485004}
observation time 0.001368, current best 51.568034 at iter 9
suggestion time taken 0.001738 iter 10 next_points [{'alpha': 0.0019059587089818098, 'batch_size': 118, 'beta_1': 0.9243747855787762, 'beta_2': 0.9999162552158751, 'epsilon': 3.9531481512360684e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 1.9319868512893076e-05, 'tol': 0.00032395404159112594, 'validation_fraction': 0.221888161430245}]
function_evaluation time 0.091091 value 151.461949 suggestion {'alpha': 0.0019059587089818098, 'batch_size': 118, 'beta_1': 0.9243747855787762, 'beta_2': 0.9999162552158751, 'epsilon': 3.9531481512360684e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 1.9319868512893076e-05, 'tol': 0.00032395404159112594, 'validation_fraction': 0.221888161430245}
observation time 0.001365, current best 51.568034 at iter 10
suggestion time taken 0.001696 iter 11 next_points [{'alpha': 1.3128421541367783e-05, 'batch_size': 105, 'beta_1': 0.9817258000429507, 'beta_2': 0.9971187547467886, 'epsilon': 8.90574693451442e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.4509676157437064e-05, 'tol': 1.8420046192997916e-05, 'validation_fraction': 0.893002212701883}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.042044 value 151.716968 suggestion {'alpha': 1.3128421541367783e-05, 'batch_size': 105, 'beta_1': 0.9817258000429507, 'beta_2': 0.9971187547467886, 'epsilon': 8.90574693451442e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.4509676157437064e-05, 'tol': 1.8420046192997916e-05, 'validation_fraction': 0.893002212701883}
observation time 0.001370, current best 51.568034 at iter 11
suggestion time taken 0.001722 iter 12 next_points [{'alpha': 2.0505983293921615, 'batch_size': 86, 'beta_1': 0.9370032980245174, 'beta_2': 0.9999567622112274, 'epsilon': 2.633380449879607e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0033262450958060344, 'tol': 5.418515219257354e-05, 'validation_fraction': 0.12641919858167688}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.350474 value 50.578918 suggestion {'alpha': 2.0505983293921615, 'batch_size': 86, 'beta_1': 0.9370032980245174, 'beta_2': 0.9999567622112274, 'epsilon': 2.633380449879607e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0033262450958060344, 'tol': 5.418515219257354e-05, 'validation_fraction': 0.12641919858167688}
observation time 0.001423, current best 50.578918 at iter 12
suggestion time taken 0.001717 iter 13 next_points [{'alpha': 0.023799692767950426, 'batch_size': 205, 'beta_1': 0.9568546295981705, 'beta_2': 0.9988559576278014, 'epsilon': 6.0750198429052466e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.019604540809280226, 'tol': 0.04905039153656827, 'validation_fraction': 0.28799039800975107}]
function_evaluation time 0.091695 value 148.186950 suggestion {'alpha': 0.023799692767950426, 'batch_size': 205, 'beta_1': 0.9568546295981705, 'beta_2': 0.9988559576278014, 'epsilon': 6.0750198429052466e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.019604540809280226, 'tol': 0.04905039153656827, 'validation_fraction': 0.28799039800975107}
observation time 0.001583, current best 50.578918 at iter 13
suggestion time taken 0.001795 iter 14 next_points [{'alpha': 3.216044199427865, 'batch_size': 131, 'beta_1': 0.9850372956038589, 'beta_2': 0.9994935702598774, 'epsilon': 1.578568214661702e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.07107759843491558, 'tol': 0.001072736407089494, 'validation_fraction': 0.19551641331452804}]
function_evaluation time 0.165966 value 53.892311 suggestion {'alpha': 3.216044199427865, 'batch_size': 131, 'beta_1': 0.9850372956038589, 'beta_2': 0.9994935702598774, 'epsilon': 1.578568214661702e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.07107759843491558, 'tol': 0.001072736407089494, 'validation_fraction': 0.19551641331452804}
observation time 0.001318, current best 50.578918 at iter 14
saving meta data: {'args': {'--uuid': '8c30098d03c9538cbec56925ea1997b5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done
