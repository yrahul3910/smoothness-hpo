running: {'--uuid': '9afa1e37866f52c8a5809201e783696b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 9afa1e37866f52c8a5809201e783696b -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study random-search MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002490 iter 0 next_points [{'alpha': 2.0506345973744313e-05, 'batch_size': 228, 'beta_1': 0.9665568758170774, 'beta_2': 0.9996531938874968, 'epsilon': 1.1807115776411744e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.00019911437400515637, 'tol': 0.00010135646310846713, 'validation_fraction': 0.5549720114884185}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.716314 value 151.108214 suggestion {'alpha': 2.0506345973744313e-05, 'batch_size': 228, 'beta_1': 0.9665568758170774, 'beta_2': 0.9996531938874968, 'epsilon': 1.1807115776411744e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.00019911437400515637, 'tol': 0.00010135646310846713, 'validation_fraction': 0.5549720114884185}
observation time 0.000006, current best 151.108214 at iter 0
suggestion time taken 0.002774 iter 1 next_points [{'alpha': 1.7736201796643094, 'batch_size': 161, 'beta_1': 0.9864835962795097, 'beta_2': 0.9998315134009294, 'epsilon': 2.822896793208289e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0001251567573845417, 'tol': 0.00032841115005359316, 'validation_fraction': 0.12258737069914989}]
function_evaluation time 0.065605 value 151.448778 suggestion {'alpha': 1.7736201796643094, 'batch_size': 161, 'beta_1': 0.9864835962795097, 'beta_2': 0.9998315134009294, 'epsilon': 2.822896793208289e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0001251567573845417, 'tol': 0.00032841115005359316, 'validation_fraction': 0.12258737069914989}
observation time 0.000004, current best 151.108214 at iter 1
suggestion time taken 0.002479 iter 2 next_points [{'alpha': 0.3101518260841854, 'batch_size': 78, 'beta_1': 0.9842327473244802, 'beta_2': 0.9995417010100037, 'epsilon': 3.4833896301672524e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 7.396364018299469e-05, 'tol': 0.0921653505636555, 'validation_fraction': 0.7573725238829834}]
function_evaluation time 0.045801 value 151.708824 suggestion {'alpha': 0.3101518260841854, 'batch_size': 78, 'beta_1': 0.9842327473244802, 'beta_2': 0.9995417010100037, 'epsilon': 3.4833896301672524e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 7.396364018299469e-05, 'tol': 0.0921653505636555, 'validation_fraction': 0.7573725238829834}
observation time 0.000004, current best 151.108214 at iter 2
suggestion time taken 0.002456 iter 3 next_points [{'alpha': 0.007254130211416943, 'batch_size': 96, 'beta_1': 0.9511713373870477, 'beta_2': 0.99996995193953, 'epsilon': 3.0816336251958004e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.00026711026419339224, 'tol': 0.003958746559677356, 'validation_fraction': 0.12156954174239763}]
function_evaluation time 0.101944 value 151.611845 suggestion {'alpha': 0.007254130211416943, 'batch_size': 96, 'beta_1': 0.9511713373870477, 'beta_2': 0.99996995193953, 'epsilon': 3.0816336251958004e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.00026711026419339224, 'tol': 0.003958746559677356, 'validation_fraction': 0.12156954174239763}
observation time 0.000005, current best 151.108214 at iter 3
suggestion time taken 0.002465 iter 4 next_points [{'alpha': 0.0857559041569908, 'batch_size': 141, 'beta_1': 0.9544903464393301, 'beta_2': 0.9997182094447906, 'epsilon': 3.2520757109699647e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 5.4969531894282215e-05, 'tol': 0.015350930208645853, 'validation_fraction': 0.7927198822833142}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053130 value 151.679914 suggestion {'alpha': 0.0857559041569908, 'batch_size': 141, 'beta_1': 0.9544903464393301, 'beta_2': 0.9997182094447906, 'epsilon': 3.2520757109699647e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 5.4969531894282215e-05, 'tol': 0.015350930208645853, 'validation_fraction': 0.7927198822833142}
observation time 0.000004, current best 151.108214 at iter 4
suggestion time taken 0.002447 iter 5 next_points [{'alpha': 0.06805103501792394, 'batch_size': 191, 'beta_1': 0.9731928362826213, 'beta_2': 0.9999604165948963, 'epsilon': 3.530798523737762e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0009880765808999083, 'tol': 0.07751545876782676, 'validation_fraction': 0.8228610180275818}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053849 value 151.436931 suggestion {'alpha': 0.06805103501792394, 'batch_size': 191, 'beta_1': 0.9731928362826213, 'beta_2': 0.9999604165948963, 'epsilon': 3.530798523737762e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0009880765808999083, 'tol': 0.07751545876782676, 'validation_fraction': 0.8228610180275818}
observation time 0.000004, current best 151.108214 at iter 5
suggestion time taken 0.002471 iter 6 next_points [{'alpha': 0.00028253984369997224, 'batch_size': 198, 'beta_1': 0.9801492891925632, 'beta_2': 0.9997360792371826, 'epsilon': 1.5603359350632177e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.041319971899632636, 'tol': 0.0002368579787952851, 'validation_fraction': 0.21762564912712054}]
function_evaluation time 0.194697 value 55.552799 suggestion {'alpha': 0.00028253984369997224, 'batch_size': 198, 'beta_1': 0.9801492891925632, 'beta_2': 0.9997360792371826, 'epsilon': 1.5603359350632177e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.041319971899632636, 'tol': 0.0002368579787952851, 'validation_fraction': 0.21762564912712054}
observation time 0.000005, current best 55.552799 at iter 6
suggestion time taken 0.002500 iter 7 next_points [{'alpha': 0.005192209180318833, 'batch_size': 41, 'beta_1': 0.8852621929548727, 'beta_2': 0.9999904481699455, 'epsilon': 9.074361362426672e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 9.379323062880697e-05, 'tol': 0.0001476450498302648, 'validation_fraction': 0.14837705041109753}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.172548 value 149.995768 suggestion {'alpha': 0.005192209180318833, 'batch_size': 41, 'beta_1': 0.8852621929548727, 'beta_2': 0.9999904481699455, 'epsilon': 9.074361362426672e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 9.379323062880697e-05, 'tol': 0.0001476450498302648, 'validation_fraction': 0.14837705041109753}
observation time 0.000004, current best 55.552799 at iter 7
suggestion time taken 0.002470 iter 8 next_points [{'alpha': 0.003819642013150395, 'batch_size': 57, 'beta_1': 0.978064569456517, 'beta_2': 0.9999983930489239, 'epsilon': 9.078486577024155e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.010597024740126575, 'tol': 0.00123813803852687, 'validation_fraction': 0.11552637850244621}]
function_evaluation time 0.463134 value 53.657280 suggestion {'alpha': 0.003819642013150395, 'batch_size': 57, 'beta_1': 0.978064569456517, 'beta_2': 0.9999983930489239, 'epsilon': 9.078486577024155e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.010597024740126575, 'tol': 0.00123813803852687, 'validation_fraction': 0.11552637850244621}
observation time 0.000005, current best 53.657280 at iter 8
suggestion time taken 0.002452 iter 9 next_points [{'alpha': 0.08503084935078825, 'batch_size': 31, 'beta_1': 0.9881796047912837, 'beta_2': 0.9999934441060205, 'epsilon': 4.9425369643320725e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00018293434375863754, 'tol': 0.006996598870373407, 'validation_fraction': 0.6482572787888184}]
function_evaluation time 0.098744 value 151.619913 suggestion {'alpha': 0.08503084935078825, 'batch_size': 31, 'beta_1': 0.9881796047912837, 'beta_2': 0.9999934441060205, 'epsilon': 4.9425369643320725e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00018293434375863754, 'tol': 0.006996598870373407, 'validation_fraction': 0.6482572787888184}
observation time 0.000004, current best 53.657280 at iter 9
suggestion time taken 0.002411 iter 10 next_points [{'alpha': 0.0061870896945729606, 'batch_size': 122, 'beta_1': 0.9732547823852239, 'beta_2': 0.9998556494011608, 'epsilon': 2.847990769826731e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.082767952703595e-05, 'tol': 0.006314486510324989, 'validation_fraction': 0.6322319009583808}]
function_evaluation time 0.053913 value 151.504426 suggestion {'alpha': 0.0061870896945729606, 'batch_size': 122, 'beta_1': 0.9732547823852239, 'beta_2': 0.9998556494011608, 'epsilon': 2.847990769826731e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.082767952703595e-05, 'tol': 0.006314486510324989, 'validation_fraction': 0.6322319009583808}
observation time 0.000005, current best 53.657280 at iter 10
suggestion time taken 0.002469 iter 11 next_points [{'alpha': 4.892136031570681e-05, 'batch_size': 69, 'beta_1': 0.9897726925832887, 'beta_2': 0.9978006093989052, 'epsilon': 3.3299099919516215e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.005967407608822955, 'tol': 0.0021470474103112308, 'validation_fraction': 0.711881216553146}]
function_evaluation time 0.826225 value 59.028009 suggestion {'alpha': 4.892136031570681e-05, 'batch_size': 69, 'beta_1': 0.9897726925832887, 'beta_2': 0.9978006093989052, 'epsilon': 3.3299099919516215e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.005967407608822955, 'tol': 0.0021470474103112308, 'validation_fraction': 0.711881216553146}
observation time 0.000004, current best 53.657280 at iter 11
suggestion time taken 0.002446 iter 12 next_points [{'alpha': 0.8603111103507335, 'batch_size': 115, 'beta_1': 0.9067860615756996, 'beta_2': 0.999980545324446, 'epsilon': 1.675174533657335e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00012105539043683065, 'tol': 0.0055927553639709745, 'validation_fraction': 0.24975976831506103}]
function_evaluation time 0.043232 value 151.572690 suggestion {'alpha': 0.8603111103507335, 'batch_size': 115, 'beta_1': 0.9067860615756996, 'beta_2': 0.999980545324446, 'epsilon': 1.675174533657335e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00012105539043683065, 'tol': 0.0055927553639709745, 'validation_fraction': 0.24975976831506103}
observation time 0.000004, current best 53.657280 at iter 12
suggestion time taken 0.002724 iter 13 next_points [{'alpha': 0.0010131847311074195, 'batch_size': 99, 'beta_1': 0.9743284060128848, 'beta_2': 0.9473163099469597, 'epsilon': 3.498611597648584e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0021439882981310146, 'tol': 0.00011068588700897357, 'validation_fraction': 0.3514870378343414}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.201172 value 104.770758 suggestion {'alpha': 0.0010131847311074195, 'batch_size': 99, 'beta_1': 0.9743284060128848, 'beta_2': 0.9473163099469597, 'epsilon': 3.498611597648584e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0021439882981310146, 'tol': 0.00011068588700897357, 'validation_fraction': 0.3514870378343414}
observation time 0.000004, current best 53.657280 at iter 13
suggestion time taken 0.002433 iter 14 next_points [{'alpha': 3.213992471961414e-05, 'batch_size': 125, 'beta_1': 0.98481273404714, 'beta_2': 0.9993388928644004, 'epsilon': 1.3769848446086611e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0007953127193681823, 'tol': 5.291315880097029e-05, 'validation_fraction': 0.14426381293622717}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.663718 value 145.152447 suggestion {'alpha': 3.213992471961414e-05, 'batch_size': 125, 'beta_1': 0.98481273404714, 'beta_2': 0.9993388928644004, 'epsilon': 1.3769848446086611e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0007953127193681823, 'tol': 5.291315880097029e-05, 'validation_fraction': 0.14426381293622717}
observation time 0.000005, current best 53.657280 at iter 14
saving meta data: {'args': {'--uuid': '9afa1e37866f52c8a5809201e783696b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done
