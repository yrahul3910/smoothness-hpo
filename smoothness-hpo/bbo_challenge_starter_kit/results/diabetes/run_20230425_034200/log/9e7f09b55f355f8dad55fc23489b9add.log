running: {'--uuid': '9e7f09b55f355f8dad55fc23489b9add', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 9e7f09b55f355f8dad55fc23489b9add -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study turbo MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002373 iter 0 next_points [{'alpha': 1.7688259607206443e-05, 'batch_size': 72, 'beta_1': 0.9895904618189902, 'beta_2': 0.999085769215671, 'epsilon': 6.437242270656244e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.04219886644007451, 'tol': 1.2217806733531034e-05, 'validation_fraction': 0.21850364725404015}]
function_evaluation time 0.284786 value 3532.907976 suggestion {'alpha': 1.7688259607206443e-05, 'batch_size': 72, 'beta_1': 0.9895904618189902, 'beta_2': 0.999085769215671, 'epsilon': 6.437242270656244e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.04219886644007451, 'tol': 1.2217806733531034e-05, 'validation_fraction': 0.21850364725404015}
observation time 0.001364, current best 3532.907976 at iter 0
suggestion time taken 0.001733 iter 1 next_points [{'alpha': 6.097066375228429e-05, 'batch_size': 161, 'beta_1': 0.9095088546939806, 'beta_2': 0.9999325317385961, 'epsilon': 6.680805730056814e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 4.477380090959101e-05, 'tol': 8.807976216555806e-05, 'validation_fraction': 0.5664513290672586}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.049384 value 29117.511067 suggestion {'alpha': 6.097066375228429e-05, 'batch_size': 161, 'beta_1': 0.9095088546939806, 'beta_2': 0.9999325317385961, 'epsilon': 6.680805730056814e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 4.477380090959101e-05, 'tol': 8.807976216555806e-05, 'validation_fraction': 0.5664513290672586}
observation time 0.001412, current best 3532.907976 at iter 1
suggestion time taken 0.001694 iter 2 next_points [{'alpha': 2.0779983016251948e-05, 'batch_size': 60, 'beta_1': 0.8828562764404709, 'beta_2': 0.9939932667169628, 'epsilon': 3.0477617477511655e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 2.947654436378897e-05, 'tol': 0.06327256546220654, 'validation_fraction': 0.8017388851204749}]
function_evaluation time 0.049422 value 29122.855330 suggestion {'alpha': 2.0779983016251948e-05, 'batch_size': 60, 'beta_1': 0.8828562764404709, 'beta_2': 0.9939932667169628, 'epsilon': 3.0477617477511655e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 2.947654436378897e-05, 'tol': 0.06327256546220654, 'validation_fraction': 0.8017388851204749}
observation time 0.001426, current best 3532.907976 at iter 2
suggestion time taken 0.001784 iter 3 next_points [{'alpha': 0.00023401186581519843, 'batch_size': 101, 'beta_1': 0.9670998087554464, 'beta_2': 0.9746990100476567, 'epsilon': 1.0040896157975788e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.01807818579384408, 'tol': 0.0016845762528873115, 'validation_fraction': 0.6627519200963836}]
function_evaluation time 0.387630 value 4141.032637 suggestion {'alpha': 0.00023401186581519843, 'batch_size': 101, 'beta_1': 0.9670998087554464, 'beta_2': 0.9746990100476567, 'epsilon': 1.0040896157975788e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.01807818579384408, 'tol': 0.0016845762528873115, 'validation_fraction': 0.6627519200963836}
observation time 0.001364, current best 3532.907976 at iter 3
suggestion time taken 0.001713 iter 4 next_points [{'alpha': 0.0005678219049943098, 'batch_size': 146, 'beta_1': 0.9750586027605502, 'beta_2': 0.9439768869000063, 'epsilon': 7.837779830214563e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.07334734716147874, 'tol': 0.0006306375513693736, 'validation_fraction': 0.352737267784896}]
function_evaluation time 0.155149 value 4303.454799 suggestion {'alpha': 0.0005678219049943098, 'batch_size': 146, 'beta_1': 0.9750586027605502, 'beta_2': 0.9439768869000063, 'epsilon': 7.837779830214563e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.07334734716147874, 'tol': 0.0006306375513693736, 'validation_fraction': 0.352737267784896}
observation time 0.001375, current best 3532.907976 at iter 4
suggestion time taken 0.001685 iter 5 next_points [{'alpha': 1.112501520208807, 'batch_size': 242, 'beta_1': 0.9410726268365884, 'beta_2': 0.9999985762537262, 'epsilon': 1.0968971992024305e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0034342349410649603, 'tol': 0.052308702943888404, 'validation_fraction': 0.14455805820648765}]
function_evaluation time 0.061395 value 28955.168165 suggestion {'alpha': 1.112501520208807, 'batch_size': 242, 'beta_1': 0.9410726268365884, 'beta_2': 0.9999985762537262, 'epsilon': 1.0968971992024305e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0034342349410649603, 'tol': 0.052308702943888404, 'validation_fraction': 0.14455805820648765}
observation time 0.001385, current best 3532.907976 at iter 5
suggestion time taken 0.001719 iter 6 next_points [{'alpha': 0.010599890984646568, 'batch_size': 191, 'beta_1': 0.9243714207119654, 'beta_2': 0.984599200159421, 'epsilon': 1.6844267348583e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.001072682458954306, 'tol': 0.0002942470194297591, 'validation_fraction': 0.47590122571678667}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.834279 value 27357.841473 suggestion {'alpha': 0.010599890984646568, 'batch_size': 191, 'beta_1': 0.9243714207119654, 'beta_2': 0.984599200159421, 'epsilon': 1.6844267348583e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.001072682458954306, 'tol': 0.0002942470194297591, 'validation_fraction': 0.47590122571678667}
observation time 0.001419, current best 3532.907976 at iter 6
suggestion time taken 0.001712 iter 7 next_points [{'alpha': 0.002772494214430663, 'batch_size': 24, 'beta_1': 0.7866593010357712, 'beta_2': 0.9981705077707737, 'epsilon': 3.055865097216313e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0013308141755321516, 'tol': 1.839350233033556e-05, 'validation_fraction': 0.8879236548435616}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.937181 value 17314.042042 suggestion {'alpha': 0.002772494214430663, 'batch_size': 24, 'beta_1': 0.7866593010357712, 'beta_2': 0.9981705077707737, 'epsilon': 3.055865097216313e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0013308141755321516, 'tol': 1.839350233033556e-05, 'validation_fraction': 0.8879236548435616}
observation time 0.001420, current best 3532.907976 at iter 7
suggestion time taken 0.001717 iter 8 next_points [{'alpha': 0.18889918756568372, 'batch_size': 81, 'beta_1': 0.5960806810696773, 'beta_2': 0.9160750395004515, 'epsilon': 4.525614863681746e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 2.23485061475167e-05, 'tol': 0.01934968577859333, 'validation_fraction': 0.11251204828367566}]
function_evaluation time 0.059403 value 29132.627934 suggestion {'alpha': 0.18889918756568372, 'batch_size': 81, 'beta_1': 0.5960806810696773, 'beta_2': 0.9160750395004515, 'epsilon': 4.525614863681746e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 2.23485061475167e-05, 'tol': 0.01934968577859333, 'validation_fraction': 0.11251204828367566}
observation time 0.001349, current best 3532.907976 at iter 8
suggestion time taken 0.001702 iter 9 next_points [{'alpha': 0.06848593932964935, 'batch_size': 233, 'beta_1': 0.7539362400168229, 'beta_2': 0.9997351701954186, 'epsilon': 4.4063406953472126e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.4171547633605827e-05, 'tol': 4.374302176601319e-05, 'validation_fraction': 0.7190486799567383}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054273 value 29133.167534 suggestion {'alpha': 0.06848593932964935, 'batch_size': 233, 'beta_1': 0.7539362400168229, 'beta_2': 0.9997351701954186, 'epsilon': 4.4063406953472126e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.4171547633605827e-05, 'tol': 4.374302176601319e-05, 'validation_fraction': 0.7190486799567383}
observation time 0.001333, current best 3532.907976 at iter 9
suggestion time taken 0.002051 iter 10 next_points [{'alpha': 0.5394908090881808, 'batch_size': 163, 'beta_1': 0.5147422826639908, 'beta_2': 0.999516438256883, 'epsilon': 8.804665449832314e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00016318081360668871, 'tol': 0.007631544683719266, 'validation_fraction': 0.2769161182144636}]
function_evaluation time 0.065418 value 29108.694965 suggestion {'alpha': 0.5394908090881808, 'batch_size': 163, 'beta_1': 0.5147422826639908, 'beta_2': 0.999516438256883, 'epsilon': 8.804665449832314e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00016318081360668871, 'tol': 0.007631544683719266, 'validation_fraction': 0.2769161182144636}
observation time 0.001392, current best 3532.907976 at iter 10
suggestion time taken 0.001712 iter 11 next_points [{'alpha': 0.02210457318419152, 'batch_size': 118, 'beta_1': 0.9502755384468226, 'beta_2': 0.9998763006448416, 'epsilon': 1.1629867307254369e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00021687692956831806, 'tol': 0.0012331070078230111, 'validation_fraction': 0.6219550921266327}]
function_evaluation time 0.048458 value 29102.682336 suggestion {'alpha': 0.02210457318419152, 'batch_size': 118, 'beta_1': 0.9502755384468226, 'beta_2': 0.9998763006448416, 'epsilon': 1.1629867307254369e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00021687692956831806, 'tol': 0.0012331070078230111, 'validation_fraction': 0.6219550921266327}
observation time 0.001352, current best 3532.907976 at iter 11
suggestion time taken 0.001732 iter 12 next_points [{'alpha': 4.7141192892594175, 'batch_size': 46, 'beta_1': 0.9837327644372829, 'beta_2': 0.9998620441458457, 'epsilon': 1.642000946027832e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.03233333673395699, 'tol': 0.0040684439915931086, 'validation_fraction': 0.45812035127771744}]
function_evaluation time 0.287704 value 3621.633314 suggestion {'alpha': 4.7141192892594175, 'batch_size': 46, 'beta_1': 0.9837327644372829, 'beta_2': 0.9998620441458457, 'epsilon': 1.642000946027832e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.03233333673395699, 'tol': 0.0040684439915931086, 'validation_fraction': 0.45812035127771744}
observation time 0.001318, current best 3532.907976 at iter 12
suggestion time taken 0.001748 iter 13 next_points [{'alpha': 1.1875823156080114, 'batch_size': 177, 'beta_1': 0.6287295533184902, 'beta_2': 0.999988321017852, 'epsilon': 1.4060007870192847e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 7.889282874225213e-05, 'tol': 0.03129294060391772, 'validation_fraction': 0.8415834901386319}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050462 value 29105.278477 suggestion {'alpha': 1.1875823156080114, 'batch_size': 177, 'beta_1': 0.6287295533184902, 'beta_2': 0.999988321017852, 'epsilon': 1.4060007870192847e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 7.889282874225213e-05, 'tol': 0.03129294060391772, 'validation_fraction': 0.8415834901386319}
observation time 0.001378, current best 3532.907976 at iter 13
suggestion time taken 0.001713 iter 14 next_points [{'alpha': 9.476814399960385e-05, 'batch_size': 88, 'beta_1': 0.8590019386680199, 'beta_2': 0.9967946975406987, 'epsilon': 2.1528093966795224e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0007346460347200265, 'tol': 0.00944227394263312, 'validation_fraction': 0.24948920051299636}]
function_evaluation time 0.103864 value 28974.546514 suggestion {'alpha': 9.476814399960385e-05, 'batch_size': 88, 'beta_1': 0.8590019386680199, 'beta_2': 0.9967946975406987, 'epsilon': 2.1528093966795224e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0007346460347200265, 'tol': 0.00944227394263312, 'validation_fraction': 0.24948920051299636}
observation time 0.001382, current best 3532.907976 at iter 14
saving meta data: {'args': {'--uuid': '9e7f09b55f355f8dad55fc23489b9add', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done
