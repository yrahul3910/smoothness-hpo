running: {'--uuid': '6148c8ad6cbf512c9cf685b319fad2e7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 6148c8ad6cbf512c9cf685b319fad2e7 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study turbo MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002427 iter 0 next_points [{'alpha': 5.775260729008857, 'batch_size': 156, 'beta_1': 0.6342793399459835, 'beta_2': 0.9983605376623463, 'epsilon': 9.10026849509889e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.05393801493996129, 'tol': 0.010321028503226758, 'validation_fraction': 0.43375862748601673}]
function_evaluation time 0.250198 value 52.680364 suggestion {'alpha': 5.775260729008857, 'batch_size': 156, 'beta_1': 0.6342793399459835, 'beta_2': 0.9983605376623463, 'epsilon': 9.10026849509889e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.05393801493996129, 'tol': 0.010321028503226758, 'validation_fraction': 0.43375862748601673}
observation time 0.001407, current best 52.680364 at iter 0
suggestion time taken 0.001853 iter 1 next_points [{'alpha': 2.027594158294203, 'batch_size': 168, 'beta_1': 0.9547068429779922, 'beta_2': 0.999523051004533, 'epsilon': 3.327118979403688e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 4.3809912558050325e-05, 'tol': 9.071745752998351e-05, 'validation_fraction': 0.21718178147912606}]
function_evaluation time 0.065632 value 151.444458 suggestion {'alpha': 2.027594158294203, 'batch_size': 168, 'beta_1': 0.9547068429779922, 'beta_2': 0.999523051004533, 'epsilon': 3.327118979403688e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 4.3809912558050325e-05, 'tol': 9.071745752998351e-05, 'validation_fraction': 0.21718178147912606}
observation time 0.001451, current best 52.680364 at iter 1
suggestion time taken 0.001756 iter 2 next_points [{'alpha': 0.0001275405936818813, 'batch_size': 44, 'beta_1': 0.8661481764928871, 'beta_2': 0.977521333862875, 'epsilon': 1.1362660371336744e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.000192067973932635, 'tol': 0.04533651195243456, 'validation_fraction': 0.3160298494088096}]
function_evaluation time 0.121927 value 151.370010 suggestion {'alpha': 0.0001275405936818813, 'batch_size': 44, 'beta_1': 0.8661481764928871, 'beta_2': 0.977521333862875, 'epsilon': 1.1362660371336744e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.000192067973932635, 'tol': 0.04533651195243456, 'validation_fraction': 0.3160298494088096}
observation time 0.001405, current best 52.680364 at iter 2
suggestion time taken 0.001804 iter 3 next_points [{'alpha': 0.0017136655209475163, 'batch_size': 132, 'beta_1': 0.6115567344705117, 'beta_2': 0.9555811622834484, 'epsilon': 5.356807782515173e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0001466932620900577, 'tol': 0.007788759998426364, 'validation_fraction': 0.8568359640559245}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054639 value 151.529178 suggestion {'alpha': 0.0017136655209475163, 'batch_size': 132, 'beta_1': 0.6115567344705117, 'beta_2': 0.9555811622834484, 'epsilon': 5.356807782515173e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0001466932620900577, 'tol': 0.007788759998426364, 'validation_fraction': 0.8568359640559245}
observation time 0.001404, current best 52.680364 at iter 3
suggestion time taken 0.001822 iter 4 next_points [{'alpha': 0.003648682407148841, 'batch_size': 62, 'beta_1': 0.8041360305899904, 'beta_2': 0.9986429206174471, 'epsilon': 6.693772677878396e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 3.327662181552831e-05, 'tol': 0.01562508026153208, 'validation_fraction': 0.5041954161158041}]
function_evaluation time 0.052550 value 151.550845 suggestion {'alpha': 0.003648682407148841, 'batch_size': 62, 'beta_1': 0.8041360305899904, 'beta_2': 0.9986429206174471, 'epsilon': 6.693772677878396e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 3.327662181552831e-05, 'tol': 0.01562508026153208, 'validation_fraction': 0.5041954161158041}
observation time 0.001393, current best 52.680364 at iter 4
suggestion time taken 0.001761 iter 5 next_points [{'alpha': 0.0295587656500429, 'batch_size': 59, 'beta_1': 0.9163911719653268, 'beta_2': 0.9264153008979789, 'epsilon': 4.3784439756485215e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0003091536860722281, 'tol': 0.002162228398786678, 'validation_fraction': 0.7444584427766865}]
function_evaluation time 0.065345 value 151.585395 suggestion {'alpha': 0.0295587656500429, 'batch_size': 59, 'beta_1': 0.9163911719653268, 'beta_2': 0.9264153008979789, 'epsilon': 4.3784439756485215e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0003091536860722281, 'tol': 0.002162228398786678, 'validation_fraction': 0.7444584427766865}
observation time 0.001398, current best 52.680364 at iter 5
suggestion time taken 0.001997 iter 6 next_points [{'alpha': 6.043757201960038e-05, 'batch_size': 88, 'beta_1': 0.8753725622651171, 'beta_2': 0.9999764756610958, 'epsilon': 7.635185652861642e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.9468850561742865e-05, 'tol': 0.0034167538173683304, 'validation_fraction': 0.5427277456395437}]
function_evaluation time 0.046153 value 151.729935 suggestion {'alpha': 6.043757201960038e-05, 'batch_size': 88, 'beta_1': 0.8753725622651171, 'beta_2': 0.9999764756610958, 'epsilon': 7.635185652861642e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.9468850561742865e-05, 'tol': 0.0034167538173683304, 'validation_fraction': 0.5427277456395437}
observation time 0.001409, current best 52.680364 at iter 6
suggestion time taken 0.001791 iter 7 next_points [{'alpha': 0.001228950801714249, 'batch_size': 225, 'beta_1': 0.9613730552961205, 'beta_2': 0.9883749657764569, 'epsilon': 2.2043911152785178e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0060440721751031205, 'tol': 1.4313292359414013e-05, 'validation_fraction': 0.8391799802128223}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.633951 value 84.826242 suggestion {'alpha': 0.001228950801714249, 'batch_size': 225, 'beta_1': 0.9613730552961205, 'beta_2': 0.9883749657764569, 'epsilon': 2.2043911152785178e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0060440721751031205, 'tol': 1.4313292359414013e-05, 'validation_fraction': 0.8391799802128223}
observation time 0.001434, current best 52.680364 at iter 7
suggestion time taken 0.001781 iter 8 next_points [{'alpha': 0.12876444201546214, 'batch_size': 145, 'beta_1': 0.9739485263513922, 'beta_2': 0.9950897658983727, 'epsilon': 1.67117119911853e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.5199128028929102e-05, 'tol': 0.0002996209892096268, 'validation_fraction': 0.36204854082070864}]
function_evaluation time 0.085728 value 151.635544 suggestion {'alpha': 0.12876444201546214, 'batch_size': 145, 'beta_1': 0.9739485263513922, 'beta_2': 0.9950897658983727, 'epsilon': 1.67117119911853e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.5199128028929102e-05, 'tol': 0.0002996209892096268, 'validation_fraction': 0.36204854082070864}
observation time 0.001472, current best 52.680364 at iter 8
suggestion time taken 0.001762 iter 9 next_points [{'alpha': 4.471008645324881, 'batch_size': 241, 'beta_1': 0.9895726614981302, 'beta_2': 0.9999981211431261, 'epsilon': 1.357212136142559e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0005295132714664365, 'tol': 0.09300082089666054, 'validation_fraction': 0.24672700557420055}]
function_evaluation time 0.067230 value 151.544453 suggestion {'alpha': 4.471008645324881, 'batch_size': 241, 'beta_1': 0.9895726614981302, 'beta_2': 0.9999981211431261, 'epsilon': 1.357212136142559e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0005295132714664365, 'tol': 0.09300082089666054, 'validation_fraction': 0.24672700557420055}
observation time 0.001463, current best 52.680364 at iter 9
suggestion time taken 0.001808 iter 10 next_points [{'alpha': 0.6886844295755558, 'batch_size': 198, 'beta_1': 0.9774834795058386, 'beta_2': 0.9999983157425208, 'epsilon': 2.3364895709584443e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.033214903043226336, 'tol': 0.027912589839746947, 'validation_fraction': 0.736600259895007}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.232868 value 55.385111 suggestion {'alpha': 0.6886844295755558, 'batch_size': 198, 'beta_1': 0.9774834795058386, 'beta_2': 0.9999983157425208, 'epsilon': 2.3364895709584443e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.033214903043226336, 'tol': 0.027912589839746947, 'validation_fraction': 0.736600259895007}
observation time 0.001384, current best 52.680364 at iter 10
suggestion time taken 0.002102 iter 11 next_points [{'alpha': 0.03988675610083892, 'batch_size': 26, 'beta_1': 0.9838149266287632, 'beta_2': 0.9999308765795466, 'epsilon': 1.0000028695696761e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.019452577275496874, 'tol': 0.00013322825992478942, 'validation_fraction': 0.10543351844084807}]
function_evaluation time 0.668695 value 45.606980 suggestion {'alpha': 0.03988675610083892, 'batch_size': 26, 'beta_1': 0.9838149266287632, 'beta_2': 0.9999308765795466, 'epsilon': 1.0000028695696761e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.019452577275496874, 'tol': 0.00013322825992478942, 'validation_fraction': 0.10543351844084807}
observation time 0.001354, current best 45.606980 at iter 11
suggestion time taken 0.001722 iter 12 next_points [{'alpha': 0.00020976921879778905, 'batch_size': 109, 'beta_1': 0.8184252899287426, 'beta_2': 0.9998166912460871, 'epsilon': 1.541383845048928e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 9.599271271582439e-05, 'tol': 5.6280125108685534e-05, 'validation_fraction': 0.1501170720612025}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.619910 value 150.250791 suggestion {'alpha': 0.00020976921879778905, 'batch_size': 109, 'beta_1': 0.8184252899287426, 'beta_2': 0.9998166912460871, 'epsilon': 1.541383845048928e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 9.599271271582439e-05, 'tol': 5.6280125108685534e-05, 'validation_fraction': 0.1501170720612025}
observation time 0.001629, current best 45.606980 at iter 12
suggestion time taken 0.001766 iter 13 next_points [{'alpha': 1.4043798623155831e-05, 'batch_size': 208, 'beta_1': 0.9411316616798451, 'beta_2': 0.9996535329987438, 'epsilon': 1.3071432838600365e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0025896654569754624, 'tol': 0.0013769697128391584, 'validation_fraction': 0.13570386620794625}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.395015 value 54.985995 suggestion {'alpha': 1.4043798623155831e-05, 'batch_size': 208, 'beta_1': 0.9411316616798451, 'beta_2': 0.9996535329987438, 'epsilon': 1.3071432838600365e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0025896654569754624, 'tol': 0.0013769697128391584, 'validation_fraction': 0.13570386620794625}
observation time 0.001381, current best 45.606980 at iter 13
suggestion time taken 0.001769 iter 14 next_points [{'alpha': 0.009037892961020755, 'batch_size': 123, 'beta_1': 0.7617851495960456, 'beta_2': 0.9999109164944188, 'epsilon': 2.433677087728222e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.09767863872459334, 'tol': 0.00026657095302843735, 'validation_fraction': 0.2780923436376655}]
function_evaluation time 0.340249 value 44.001914 suggestion {'alpha': 0.009037892961020755, 'batch_size': 123, 'beta_1': 0.7617851495960456, 'beta_2': 0.9999109164944188, 'epsilon': 2.433677087728222e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.09767863872459334, 'tol': 0.00026657095302843735, 'validation_fraction': 0.2780923436376655}
observation time 0.001422, current best 44.001914 at iter 14
saving meta data: {'args': {'--uuid': '6148c8ad6cbf512c9cf685b319fad2e7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done
