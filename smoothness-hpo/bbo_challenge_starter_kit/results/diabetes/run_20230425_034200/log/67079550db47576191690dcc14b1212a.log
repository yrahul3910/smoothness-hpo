running: {'--uuid': '67079550db47576191690dcc14b1212a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 67079550db47576191690dcc14b1212a -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_034200
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study random-search MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002514 iter 0 next_points [{'alpha': 0.14494882136883647, 'batch_size': 187, 'beta_1': 0.9793321918702474, 'beta_2': 0.9999255878778708, 'epsilon': 7.275847104548936e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.1440705618056984e-05, 'tol': 0.010567358001564222, 'validation_fraction': 0.636197309525759}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052545 value 29076.763527 suggestion {'alpha': 0.14494882136883647, 'batch_size': 187, 'beta_1': 0.9793321918702474, 'beta_2': 0.9999255878778708, 'epsilon': 7.275847104548936e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.1440705618056984e-05, 'tol': 0.010567358001564222, 'validation_fraction': 0.636197309525759}
observation time 0.000005, current best 29076.763527 at iter 0
suggestion time taken 0.002535 iter 1 next_points [{'alpha': 0.0457431803377395, 'batch_size': 30, 'beta_1': 0.7390886528874967, 'beta_2': 0.9999959828897865, 'epsilon': 9.398537171097226e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00013131947890005472, 'tol': 4.527340982029357e-05, 'validation_fraction': 0.8814921507239988}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.971564 value 28834.097971 suggestion {'alpha': 0.0457431803377395, 'batch_size': 30, 'beta_1': 0.7390886528874967, 'beta_2': 0.9999959828897865, 'epsilon': 9.398537171097226e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00013131947890005472, 'tol': 4.527340982029357e-05, 'validation_fraction': 0.8814921507239988}
observation time 0.000004, current best 28834.097971 at iter 1
suggestion time taken 0.002531 iter 2 next_points [{'alpha': 0.0010575107001628463, 'batch_size': 193, 'beta_1': 0.6172879907712389, 'beta_2': 0.9973888109775925, 'epsilon': 1.9410570363509397e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 2.0443345277416813e-05, 'tol': 0.01937378155432989, 'validation_fraction': 0.3991816549968998}]
function_evaluation time 0.055806 value 29125.037138 suggestion {'alpha': 0.0010575107001628463, 'batch_size': 193, 'beta_1': 0.6172879907712389, 'beta_2': 0.9973888109775925, 'epsilon': 1.9410570363509397e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 2.0443345277416813e-05, 'tol': 0.01937378155432989, 'validation_fraction': 0.3991816549968998}
observation time 0.000004, current best 28834.097971 at iter 2
suggestion time taken 0.002460 iter 3 next_points [{'alpha': 2.135520534330959, 'batch_size': 195, 'beta_1': 0.861199062774268, 'beta_2': 0.9999963327077906, 'epsilon': 6.346505356072312e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.051761639147679145, 'tol': 2.0367288980803723e-05, 'validation_fraction': 0.5976964123865441}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.373351 value 3665.159844 suggestion {'alpha': 2.135520534330959, 'batch_size': 195, 'beta_1': 0.861199062774268, 'beta_2': 0.9999963327077906, 'epsilon': 6.346505356072312e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.051761639147679145, 'tol': 2.0367288980803723e-05, 'validation_fraction': 0.5976964123865441}
observation time 0.000004, current best 3665.159844 at iter 3
suggestion time taken 0.002425 iter 4 next_points [{'alpha': 0.00030266789622384514, 'batch_size': 28, 'beta_1': 0.7029377837032054, 'beta_2': 0.9948974536520211, 'epsilon': 1.7576075709617395e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0011355646057878608, 'tol': 0.002581878187062065, 'validation_fraction': 0.10430946902680883}]
function_evaluation time 1.586085 value 3942.615746 suggestion {'alpha': 0.00030266789622384514, 'batch_size': 28, 'beta_1': 0.7029377837032054, 'beta_2': 0.9948974536520211, 'epsilon': 1.7576075709617395e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0011355646057878608, 'tol': 0.002581878187062065, 'validation_fraction': 0.10430946902680883}
observation time 0.000005, current best 3665.159844 at iter 4
suggestion time taken 0.002701 iter 5 next_points [{'alpha': 0.007224355708841545, 'batch_size': 104, 'beta_1': 0.9742215399078629, 'beta_2': 0.9999962988975931, 'epsilon': 6.456733271265933e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.010084373178269813, 'tol': 0.005388208874685625, 'validation_fraction': 0.8818655500113615}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.537269 value 4519.307645 suggestion {'alpha': 0.007224355708841545, 'batch_size': 104, 'beta_1': 0.9742215399078629, 'beta_2': 0.9999962988975931, 'epsilon': 6.456733271265933e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.010084373178269813, 'tol': 0.005388208874685625, 'validation_fraction': 0.8818655500113615}
observation time 0.000004, current best 3665.159844 at iter 5
suggestion time taken 0.002513 iter 6 next_points [{'alpha': 0.17373204427685815, 'batch_size': 212, 'beta_1': 0.9789295085569297, 'beta_2': 0.9951280647044046, 'epsilon': 4.799546299299869e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 2.5423030619014137e-05, 'tol': 0.0026799582002317575, 'validation_fraction': 0.22273740938047143}]
function_evaluation time 0.093137 value 29110.758891 suggestion {'alpha': 0.17373204427685815, 'batch_size': 212, 'beta_1': 0.9789295085569297, 'beta_2': 0.9951280647044046, 'epsilon': 4.799546299299869e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 2.5423030619014137e-05, 'tol': 0.0026799582002317575, 'validation_fraction': 0.22273740938047143}
observation time 0.000004, current best 3665.159844 at iter 6
suggestion time taken 0.002479 iter 7 next_points [{'alpha': 2.6441829497823166, 'batch_size': 53, 'beta_1': 0.9048274547016306, 'beta_2': 0.9999967781036431, 'epsilon': 1.460169967691831e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0008393488211041464, 'tol': 0.023188558132338746, 'validation_fraction': 0.12001459801405719}]
function_evaluation time 0.069652 value 28906.298809 suggestion {'alpha': 2.6441829497823166, 'batch_size': 53, 'beta_1': 0.9048274547016306, 'beta_2': 0.9999967781036431, 'epsilon': 1.460169967691831e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0008393488211041464, 'tol': 0.023188558132338746, 'validation_fraction': 0.12001459801405719}
observation time 0.000004, current best 3665.159844 at iter 7
suggestion time taken 0.002476 iter 8 next_points [{'alpha': 1.0163464219270917, 'batch_size': 100, 'beta_1': 0.9696987458653664, 'beta_2': 0.991952887852055, 'epsilon': 3.6611822591288122e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.000897858978356353, 'tol': 0.01755584636670219, 'validation_fraction': 0.2781771448810491}]
function_evaluation time 0.088914 value 28932.898934 suggestion {'alpha': 1.0163464219270917, 'batch_size': 100, 'beta_1': 0.9696987458653664, 'beta_2': 0.991952887852055, 'epsilon': 3.6611822591288122e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.000897858978356353, 'tol': 0.01755584636670219, 'validation_fraction': 0.2781771448810491}
observation time 0.000004, current best 3665.159844 at iter 8
suggestion time taken 0.002460 iter 9 next_points [{'alpha': 9.42237315426689e-05, 'batch_size': 35, 'beta_1': 0.5803358633209217, 'beta_2': 0.9999965930909817, 'epsilon': 1.0664247164592995e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.06171075572990918, 'tol': 0.005661796425236882, 'validation_fraction': 0.43422943165939665}]
function_evaluation time 0.282568 value 2979.032063 suggestion {'alpha': 9.42237315426689e-05, 'batch_size': 35, 'beta_1': 0.5803358633209217, 'beta_2': 0.9999965930909817, 'epsilon': 1.0664247164592995e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.06171075572990918, 'tol': 0.005661796425236882, 'validation_fraction': 0.43422943165939665}
observation time 0.000004, current best 2979.032063 at iter 9
suggestion time taken 0.002752 iter 10 next_points [{'alpha': 0.0013890909933988384, 'batch_size': 181, 'beta_1': 0.6585342994560924, 'beta_2': 0.9967645734242345, 'epsilon': 1.2112608668485805e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.024771103925329236, 'tol': 3.7769844285139234e-05, 'validation_fraction': 0.4797339600090952}]
function_evaluation time 0.689218 value 3001.380277 suggestion {'alpha': 0.0013890909933988384, 'batch_size': 181, 'beta_1': 0.6585342994560924, 'beta_2': 0.9967645734242345, 'epsilon': 1.2112608668485805e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.024771103925329236, 'tol': 3.7769844285139234e-05, 'validation_fraction': 0.4797339600090952}
observation time 0.000004, current best 2979.032063 at iter 10
suggestion time taken 0.002381 iter 11 next_points [{'alpha': 0.004557060738899125, 'batch_size': 87, 'beta_1': 0.5603520563141687, 'beta_2': 0.9780706157245448, 'epsilon': 9.3648661833389e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 5.4907262732781773e-05, 'tol': 0.0007988871560172219, 'validation_fraction': 0.44571134736886775}]
function_evaluation time 0.070988 value 29106.900769 suggestion {'alpha': 0.004557060738899125, 'batch_size': 87, 'beta_1': 0.5603520563141687, 'beta_2': 0.9780706157245448, 'epsilon': 9.3648661833389e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 5.4907262732781773e-05, 'tol': 0.0007988871560172219, 'validation_fraction': 0.44571134736886775}
observation time 0.000004, current best 2979.032063 at iter 11
suggestion time taken 0.002460 iter 12 next_points [{'alpha': 2.662633262151173, 'batch_size': 153, 'beta_1': 0.9357071141086177, 'beta_2': 0.9999989761276813, 'epsilon': 6.210685971658226e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 1.649672140215317e-05, 'tol': 0.005224750147649983, 'validation_fraction': 0.7334543793541682}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048068 value 29072.493754 suggestion {'alpha': 2.662633262151173, 'batch_size': 153, 'beta_1': 0.9357071141086177, 'beta_2': 0.9999989761276813, 'epsilon': 6.210685971658226e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 1.649672140215317e-05, 'tol': 0.005224750147649983, 'validation_fraction': 0.7334543793541682}
observation time 0.000004, current best 2979.032063 at iter 12
suggestion time taken 0.002443 iter 13 next_points [{'alpha': 1.6555633293261463e-05, 'batch_size': 171, 'beta_1': 0.9649609559451126, 'beta_2': 0.99992433001719, 'epsilon': 5.777275042943913e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 4.073091093736949e-05, 'tol': 0.0420695391377582, 'validation_fraction': 0.7354664422107451}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.059341 value 29114.205419 suggestion {'alpha': 1.6555633293261463e-05, 'batch_size': 171, 'beta_1': 0.9649609559451126, 'beta_2': 0.99992433001719, 'epsilon': 5.777275042943913e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 4.073091093736949e-05, 'tol': 0.0420695391377582, 'validation_fraction': 0.7354664422107451}
observation time 0.000004, current best 2979.032063 at iter 13
suggestion time taken 0.002438 iter 14 next_points [{'alpha': 1.0139877336433105, 'batch_size': 36, 'beta_1': 0.9369092574373684, 'beta_2': 0.9601986942585796, 'epsilon': 3.139579541243594e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 7.771949024757838e-05, 'tol': 0.03426878189040174, 'validation_fraction': 0.32920562746411275}]
function_evaluation time 0.127474 value 29097.742922 suggestion {'alpha': 1.0139877336433105, 'batch_size': 36, 'beta_1': 0.9369092574373684, 'beta_2': 0.9601986942585796, 'epsilon': 3.139579541243594e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 7.771949024757838e-05, 'tol': 0.03426878189040174, 'validation_fraction': 0.32920562746411275}
observation time 0.000003, current best 2979.032063 at iter 14
saving meta data: {'args': {'--uuid': '67079550db47576191690dcc14b1212a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_034200', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done
