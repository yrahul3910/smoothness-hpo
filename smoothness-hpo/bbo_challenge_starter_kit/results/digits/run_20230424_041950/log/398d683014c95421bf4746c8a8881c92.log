running: {'--uuid': '398d683014c95421bf4746c8a8881c92', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 398d683014c95421bf4746c8a8881c92 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 12.028309 iter 0 next_points [{'alpha': 0.005758317909797383, 'batch_size': 134, 'beta_1': 0.9791209889149706, 'beta_2': 0.9999866880643764, 'epsilon': 1.7405895358904734e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.045774284651438804, 'tol': 0.03288664540941292, 'validation_fraction': 0.8725069182542545}]
function_evaluation time 0.257596 value 2.871334 suggestion {'alpha': 0.005758317909797383, 'batch_size': 134, 'beta_1': 0.9791209889149706, 'beta_2': 0.9999866880643764, 'epsilon': 1.7405895358904734e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.045774284651438804, 'tol': 0.03288664540941292, 'validation_fraction': 0.8725069182542545}
observation time 0.000006, current best 2.871334 at iter 0
suggestion time taken 11.659159 iter 1 next_points [{'alpha': 0.11121086879014504, 'batch_size': 146, 'beta_1': 0.9390944788559457, 'beta_2': 0.999679660086019, 'epsilon': 3.1273990322131044e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.07682488175684953, 'tol': 0.056483326464901465, 'validation_fraction': 0.7941398462652175}]
function_evaluation time 0.185299 value 2.478655 suggestion {'alpha': 0.11121086879014504, 'batch_size': 146, 'beta_1': 0.9390944788559457, 'beta_2': 0.999679660086019, 'epsilon': 3.1273990322131044e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.07682488175684953, 'tol': 0.056483326464901465, 'validation_fraction': 0.7941398462652175}
observation time 0.000005, current best 2.478655 at iter 1
suggestion time taken 12.156662 iter 2 next_points [{'alpha': 0.02146964465712293, 'batch_size': 69, 'beta_1': 0.9790592655522087, 'beta_2': 0.9730303140982623, 'epsilon': 1.0921967143787805e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 9.32275036770225e-05, 'tol': 0.0006400601494925679, 'validation_fraction': 0.5905172132151902}]
function_evaluation time 2.999395 value 4.490273 suggestion {'alpha': 0.02146964465712293, 'batch_size': 69, 'beta_1': 0.9790592655522087, 'beta_2': 0.9730303140982623, 'epsilon': 1.0921967143787805e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 9.32275036770225e-05, 'tol': 0.0006400601494925679, 'validation_fraction': 0.5905172132151902}
observation time 0.000006, current best 2.478655 at iter 2
suggestion time taken 12.197243 iter 3 next_points [{'alpha': 7.911979055880883e-05, 'batch_size': 83, 'beta_1': 0.6286908810567474, 'beta_2': 0.9999232819757878, 'epsilon': 1.8912390541268155e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0008011946926349303, 'tol': 0.02875281068208192, 'validation_fraction': 0.3863843892282913}]
function_evaluation time 0.569046 value 0.371505 suggestion {'alpha': 7.911979055880883e-05, 'batch_size': 83, 'beta_1': 0.6286908810567474, 'beta_2': 0.9999232819757878, 'epsilon': 1.8912390541268155e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0008011946926349303, 'tol': 0.02875281068208192, 'validation_fraction': 0.3863843892282913}
observation time 0.000005, current best 0.371505 at iter 3
suggestion time taken 11.804169 iter 4 next_points [{'alpha': 2.662522272594744, 'batch_size': 63, 'beta_1': 0.8829568139757757, 'beta_2': 0.9999969600265342, 'epsilon': 1.9123387335193333e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 7.453009120332567e-05, 'tol': 0.0001877937957168987, 'validation_fraction': 0.5695820083754314}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.123974 value 0.379818 suggestion {'alpha': 2.662522272594744, 'batch_size': 63, 'beta_1': 0.8829568139757757, 'beta_2': 0.9999969600265342, 'epsilon': 1.9123387335193333e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 7.453009120332567e-05, 'tol': 0.0001877937957168987, 'validation_fraction': 0.5695820083754314}
observation time 0.000005, current best 0.371505 at iter 4
suggestion time taken 11.392416 iter 5 next_points [{'alpha': 0.0667307237997923, 'batch_size': 171, 'beta_1': 0.6697128220274421, 'beta_2': 0.9999112152999264, 'epsilon': 1.801517238867764e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0003098491319726141, 'tol': 0.0016114759452330878, 'validation_fraction': 0.7770181340399285}]
function_evaluation time 2.086369 value 0.517195 suggestion {'alpha': 0.0667307237997923, 'batch_size': 171, 'beta_1': 0.6697128220274421, 'beta_2': 0.9999112152999264, 'epsilon': 1.801517238867764e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0003098491319726141, 'tol': 0.0016114759452330878, 'validation_fraction': 0.7770181340399285}
observation time 0.000006, current best 0.371505 at iter 5
suggestion time taken 11.974216 iter 6 next_points [{'alpha': 0.19852213412115804, 'batch_size': 70, 'beta_1': 0.7272053878858634, 'beta_2': 0.9994268221909854, 'epsilon': 3.6779944059130677e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.011374817656635006, 'tol': 0.001163002806505692, 'validation_fraction': 0.7588168947789228}]
function_evaluation time 0.532277 value 0.266962 suggestion {'alpha': 0.19852213412115804, 'batch_size': 70, 'beta_1': 0.7272053878858634, 'beta_2': 0.9994268221909854, 'epsilon': 3.6779944059130677e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.011374817656635006, 'tol': 0.001163002806505692, 'validation_fraction': 0.7588168947789228}
observation time 0.000006, current best 0.266962 at iter 6
suggestion time taken 11.669117 iter 7 next_points [{'alpha': 0.023135334030863406, 'batch_size': 62, 'beta_1': 0.989883923675904, 'beta_2': 0.9998752457256237, 'epsilon': 5.784689428831941e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.07484989529236204, 'tol': 7.825043390409412e-05, 'validation_fraction': 0.39815180770650627}]
function_evaluation time 1.096691 value 1.179560 suggestion {'alpha': 0.023135334030863406, 'batch_size': 62, 'beta_1': 0.989883923675904, 'beta_2': 0.9998752457256237, 'epsilon': 5.784689428831941e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.07484989529236204, 'tol': 7.825043390409412e-05, 'validation_fraction': 0.39815180770650627}
observation time 0.000005, current best 0.266962 at iter 7
suggestion time taken 11.938229 iter 8 next_points [{'alpha': 1.7371844644562e-05, 'batch_size': 51, 'beta_1': 0.6351450076580888, 'beta_2': 0.9999958284630933, 'epsilon': 4.433869309182491e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0004161869102956081, 'tol': 0.006269169311138793, 'validation_fraction': 0.25895696116887174}]
function_evaluation time 1.480695 value 0.211389 suggestion {'alpha': 1.7371844644562e-05, 'batch_size': 51, 'beta_1': 0.6351450076580888, 'beta_2': 0.9999958284630933, 'epsilon': 4.433869309182491e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0004161869102956081, 'tol': 0.006269169311138793, 'validation_fraction': 0.25895696116887174}
observation time 0.000006, current best 0.211389 at iter 8
suggestion time taken 12.326169 iter 9 next_points [{'alpha': 3.820777540803823e-05, 'batch_size': 176, 'beta_1': 0.6354444175218207, 'beta_2': 0.9994857757121797, 'epsilon': 6.283120339176361e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.005835963469711855, 'tol': 0.05061429532750632, 'validation_fraction': 0.5842260315359886}]
function_evaluation time 0.262108 value 0.300036 suggestion {'alpha': 3.820777540803823e-05, 'batch_size': 176, 'beta_1': 0.6354444175218207, 'beta_2': 0.9994857757121797, 'epsilon': 6.283120339176361e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.005835963469711855, 'tol': 0.05061429532750632, 'validation_fraction': 0.5842260315359886}
observation time 0.000006, current best 0.211389 at iter 9
suggestion time taken 11.915797 iter 10 next_points [{'alpha': 0.0008763028516403205, 'batch_size': 40, 'beta_1': 0.550148216677229, 'beta_2': 0.9549530433241263, 'epsilon': 7.072049737466917e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 8.821146227355357e-05, 'tol': 0.0051854682700064715, 'validation_fraction': 0.13537190486246042}]
function_evaluation time 2.895592 value 0.221756 suggestion {'alpha': 0.0008763028516403205, 'batch_size': 40, 'beta_1': 0.550148216677229, 'beta_2': 0.9549530433241263, 'epsilon': 7.072049737466917e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 8.821146227355357e-05, 'tol': 0.0051854682700064715, 'validation_fraction': 0.13537190486246042}
observation time 0.000005, current best 0.211389 at iter 10
suggestion time taken 11.906566 iter 11 next_points [{'alpha': 1.3238002617425895e-05, 'batch_size': 93, 'beta_1': 0.8080656998009761, 'beta_2': 0.998940511926573, 'epsilon': 3.1240440918019617e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0783188277178658, 'tol': 5.150731030564911e-05, 'validation_fraction': 0.11607134193987902}]
function_evaluation time 0.909798 value 0.993546 suggestion {'alpha': 1.3238002617425895e-05, 'batch_size': 93, 'beta_1': 0.8080656998009761, 'beta_2': 0.998940511926573, 'epsilon': 3.1240440918019617e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0783188277178658, 'tol': 5.150731030564911e-05, 'validation_fraction': 0.11607134193987902}
observation time 0.000005, current best 0.211389 at iter 11
suggestion time taken 11.527830 iter 12 next_points [{'alpha': 0.02912864152232245, 'batch_size': 69, 'beta_1': 0.5274430270099871, 'beta_2': 0.9999891799970049, 'epsilon': 2.903935279886254e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 3.248368109253498e-05, 'tol': 0.0008767469215246827, 'validation_fraction': 0.14168291035187042}]
function_evaluation time 4.360400 value 2.335630 suggestion {'alpha': 0.02912864152232245, 'batch_size': 69, 'beta_1': 0.5274430270099871, 'beta_2': 0.9999891799970049, 'epsilon': 2.903935279886254e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 3.248368109253498e-05, 'tol': 0.0008767469215246827, 'validation_fraction': 0.14168291035187042}
observation time 0.000005, current best 0.211389 at iter 12
suggestion time taken 12.160875 iter 13 next_points [{'alpha': 3.7746343408755445, 'batch_size': 128, 'beta_1': 0.9891030338327773, 'beta_2': 0.9998972521557947, 'epsilon': 1.0849756057637531e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 4.0921087190405744e-05, 'tol': 0.000376794904240867, 'validation_fraction': 0.14267574868556945}]
function_evaluation time 1.031429 value 7.322939 suggestion {'alpha': 3.7746343408755445, 'batch_size': 128, 'beta_1': 0.9891030338327773, 'beta_2': 0.9998972521557947, 'epsilon': 1.0849756057637531e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 4.0921087190405744e-05, 'tol': 0.000376794904240867, 'validation_fraction': 0.14267574868556945}
observation time 0.000005, current best 0.211389 at iter 13
suggestion time taken 11.953154 iter 14 next_points [{'alpha': 9.422763412070594, 'batch_size': 111, 'beta_1': 0.8038095699444809, 'beta_2': 0.9999963955393888, 'epsilon': 4.220134146590165e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 1.1026139722493443e-05, 'tol': 0.0007363275590923287, 'validation_fraction': 0.8406519638498331}]
function_evaluation time 0.208745 value 12.356489 suggestion {'alpha': 9.422763412070594, 'batch_size': 111, 'beta_1': 0.8038095699444809, 'beta_2': 0.9999963955393888, 'epsilon': 4.220134146590165e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 1.1026139722493443e-05, 'tol': 0.0007363275590923287, 'validation_fraction': 0.8406519638498331}
observation time 0.000006, current best 0.211389 at iter 14
saving meta data: {'args': {'--uuid': '398d683014c95421bf4746c8a8881c92', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
