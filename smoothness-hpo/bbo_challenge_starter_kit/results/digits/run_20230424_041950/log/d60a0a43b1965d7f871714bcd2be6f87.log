running: {'--uuid': 'd60a0a43b1965d7f871714bcd2be6f87', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u d60a0a43b1965d7f871714bcd2be6f87 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002351 iter 0 next_points [{'alpha': 1.4790665608826218e-05, 'batch_size': 158, 'beta_1': 0.6552998443486863, 'beta_2': 0.9677868241774265, 'epsilon': 5.4552195906383305e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.005487763104555918, 'tol': 0.002535597586174002, 'validation_fraction': 0.12245430271387132}]
function_evaluation time 0.772175 value -0.957554 suggestion {'alpha': 1.4790665608826218e-05, 'batch_size': 158, 'beta_1': 0.6552998443486863, 'beta_2': 0.9677868241774265, 'epsilon': 5.4552195906383305e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.005487763104555918, 'tol': 0.002535597586174002, 'validation_fraction': 0.12245430271387132}
observation time 0.000061, current best -0.957554 at iter 0
suggestion time taken 0.002323 iter 1 next_points [{'alpha': 1.204254065122145e-05, 'batch_size': 224, 'beta_1': 0.6358976660223407, 'beta_2': 0.9482451237305617, 'epsilon': 7.849277620937283e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.017494318070339656, 'tol': 0.0025177910556644025, 'validation_fraction': 0.2789792986209701}]
function_evaluation time 0.691106 value -0.965205 suggestion {'alpha': 1.204254065122145e-05, 'batch_size': 224, 'beta_1': 0.6358976660223407, 'beta_2': 0.9482451237305617, 'epsilon': 7.849277620937283e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.017494318070339656, 'tol': 0.0025177910556644025, 'validation_fraction': 0.2789792986209701}
observation time 0.000069, current best -0.965205 at iter 1
suggestion time taken 0.002097 iter 2 next_points [{'alpha': 2.518493042687333e-05, 'batch_size': 160, 'beta_1': 0.648433900282854, 'beta_2': 0.9199587898878996, 'epsilon': 1.5695970198185812e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.010124366886704967, 'tol': 1.725241592713623e-05, 'validation_fraction': 0.20123894710219511}]
function_evaluation time 1.013133 value -0.967985 suggestion {'alpha': 2.518493042687333e-05, 'batch_size': 160, 'beta_1': 0.648433900282854, 'beta_2': 0.9199587898878996, 'epsilon': 1.5695970198185812e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.010124366886704967, 'tol': 1.725241592713623e-05, 'validation_fraction': 0.20123894710219511}
observation time 0.000065, current best -0.967985 at iter 2
suggestion time taken 0.002142 iter 3 next_points [{'alpha': 0.0017031330475586516, 'batch_size': 185, 'beta_1': 0.7834643624612975, 'beta_2': 0.9228705309365826, 'epsilon': 1.1365239910821379e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 6.232591209257914e-05, 'tol': 1.998342148498967e-05, 'validation_fraction': 0.2615948645895761}]
function_evaluation time 4.177418 value -0.930410 suggestion {'alpha': 0.0017031330475586516, 'batch_size': 185, 'beta_1': 0.7834643624612975, 'beta_2': 0.9228705309365826, 'epsilon': 1.1365239910821379e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 6.232591209257914e-05, 'tol': 1.998342148498967e-05, 'validation_fraction': 0.2615948645895761}
observation time 0.000064, current best -0.967985 at iter 3
suggestion time taken 0.002148 iter 4 next_points [{'alpha': 7.7802331499806785, 'batch_size': 65, 'beta_1': 0.7813851745730171, 'beta_2': 0.9042701216466645, 'epsilon': 4.011475081530998e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02547393316774746, 'tol': 0.024776419138318295, 'validation_fraction': 0.26094053344280316}]
function_evaluation time 0.696914 value -0.917903 suggestion {'alpha': 7.7802331499806785, 'batch_size': 65, 'beta_1': 0.7813851745730171, 'beta_2': 0.9042701216466645, 'epsilon': 4.011475081530998e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02547393316774746, 'tol': 0.024776419138318295, 'validation_fraction': 0.26094053344280316}
observation time 0.000065, current best -0.967985 at iter 4
suggestion time taken 0.002317 iter 5 next_points [{'alpha': 2.1615376353245392, 'batch_size': 209, 'beta_1': 0.6005852987939003, 'beta_2': 0.9245320766505899, 'epsilon': 2.217362016571928e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 5.5935272956468916e-05, 'tol': 0.00019653619440163713, 'validation_fraction': 0.3143519778296907}]
function_evaluation time 2.493860 value -0.692702 suggestion {'alpha': 2.1615376353245392, 'batch_size': 209, 'beta_1': 0.6005852987939003, 'beta_2': 0.9245320766505899, 'epsilon': 2.217362016571928e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 5.5935272956468916e-05, 'tol': 0.00019653619440163713, 'validation_fraction': 0.3143519778296907}
observation time 0.000066, current best -0.967985 at iter 5
suggestion time taken 0.002130 iter 6 next_points [{'alpha': 0.0004556024912600946, 'batch_size': 34, 'beta_1': 0.761822754846412, 'beta_2': 0.9133691086937337, 'epsilon': 8.3883436666219e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.026287725231773768, 'tol': 0.03750716339827539, 'validation_fraction': 0.10560964141742282}]
function_evaluation time 0.789067 value -0.938778 suggestion {'alpha': 0.0004556024912600946, 'batch_size': 34, 'beta_1': 0.761822754846412, 'beta_2': 0.9133691086937337, 'epsilon': 8.3883436666219e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.026287725231773768, 'tol': 0.03750716339827539, 'validation_fraction': 0.10560964141742282}
observation time 0.000070, current best -0.967985 at iter 6
suggestion time taken 0.002182 iter 7 next_points [{'alpha': 2.029914577291008e-05, 'batch_size': 170, 'beta_1': 0.6930360374683293, 'beta_2': 0.9410524794109326, 'epsilon': 2.324992003382814e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.028396164395995183, 'tol': 0.0005429703797071911, 'validation_fraction': 0.3988865033708958}]
function_evaluation time 0.831440 value -0.955449 suggestion {'alpha': 2.029914577291008e-05, 'batch_size': 170, 'beta_1': 0.6930360374683293, 'beta_2': 0.9410524794109326, 'epsilon': 2.324992003382814e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.028396164395995183, 'tol': 0.0005429703797071911, 'validation_fraction': 0.3988865033708958}
observation time 0.000062, current best -0.967985 at iter 7
suggestion time taken 0.002106 iter 8 next_points [{'alpha': 0.7815747221493062, 'batch_size': 240, 'beta_1': 0.5011517271426114, 'beta_2': 0.9509603224256971, 'epsilon': 9.097571531196147e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00038061173586896135, 'tol': 0.007780457000364897, 'validation_fraction': 0.32938446214948913}]
function_evaluation time 1.333101 value -0.933212 suggestion {'alpha': 0.7815747221493062, 'batch_size': 240, 'beta_1': 0.5011517271426114, 'beta_2': 0.9509603224256971, 'epsilon': 9.097571531196147e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00038061173586896135, 'tol': 0.007780457000364897, 'validation_fraction': 0.32938446214948913}
observation time 0.000068, current best -0.967985 at iter 8
suggestion time taken 0.002091 iter 9 next_points [{'alpha': 8.334978477769536e-05, 'batch_size': 44, 'beta_1': 0.8659276236877742, 'beta_2': 0.9840040208383377, 'epsilon': 2.2311197314120773e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0005304872503031681, 'tol': 1.4096392185140661e-05, 'validation_fraction': 0.3603974496064313}]
function_evaluation time 2.962631 value -0.974944 suggestion {'alpha': 8.334978477769536e-05, 'batch_size': 44, 'beta_1': 0.8659276236877742, 'beta_2': 0.9840040208383377, 'epsilon': 2.2311197314120773e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0005304872503031681, 'tol': 1.4096392185140661e-05, 'validation_fraction': 0.3603974496064313}
observation time 0.000063, current best -0.974944 at iter 9
suggestion time taken 0.002083 iter 10 next_points [{'alpha': 0.00010047839397298443, 'batch_size': 78, 'beta_1': 0.5168307597155064, 'beta_2': 0.9047427385871879, 'epsilon': 1.1391081749496209e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0130827726014466, 'tol': 1.6953977653810188e-05, 'validation_fraction': 0.5956381983266413}]
function_evaluation time 0.750592 value -0.959652 suggestion {'alpha': 0.00010047839397298443, 'batch_size': 78, 'beta_1': 0.5168307597155064, 'beta_2': 0.9047427385871879, 'epsilon': 1.1391081749496209e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0130827726014466, 'tol': 1.6953977653810188e-05, 'validation_fraction': 0.5956381983266413}
observation time 0.000063, current best -0.974944 at iter 10
suggestion time taken 0.002097 iter 11 next_points [{'alpha': 0.08222463681971785, 'batch_size': 114, 'beta_1': 0.8195783148028272, 'beta_2': 0.9707250383604871, 'epsilon': 8.993774195163932e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.04239067956651569, 'tol': 0.023202348528630064, 'validation_fraction': 0.6564625770923606}]
function_evaluation time 0.364227 value -0.939474 suggestion {'alpha': 0.08222463681971785, 'batch_size': 114, 'beta_1': 0.8195783148028272, 'beta_2': 0.9707250383604871, 'epsilon': 8.993774195163932e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.04239067956651569, 'tol': 0.023202348528630064, 'validation_fraction': 0.6564625770923606}
observation time 0.000067, current best -0.974944 at iter 11
suggestion time taken 0.002367 iter 12 next_points [{'alpha': 0.11108755299741736, 'batch_size': 25, 'beta_1': 0.9019023684431253, 'beta_2': 0.9571304196472338, 'epsilon': 5.08763923199369e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0008687118745027779, 'tol': 0.015582405186732385, 'validation_fraction': 0.22352913695758822}]
function_evaluation time 1.132805 value -0.961048 suggestion {'alpha': 0.11108755299741736, 'batch_size': 25, 'beta_1': 0.9019023684431253, 'beta_2': 0.9571304196472338, 'epsilon': 5.08763923199369e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0008687118745027779, 'tol': 0.015582405186732385, 'validation_fraction': 0.22352913695758822}
observation time 0.000070, current best -0.974944 at iter 12
suggestion time taken 0.002160 iter 13 next_points [{'alpha': 0.0001171310912777601, 'batch_size': 216, 'beta_1': 0.9173446230974738, 'beta_2': 0.9781263507873906, 'epsilon': 1.6823780247751034e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0006437088344075387, 'tol': 0.00035272898929652796, 'validation_fraction': 0.3207796722786491}]
function_evaluation time 1.863590 value -0.956175 suggestion {'alpha': 0.0001171310912777601, 'batch_size': 216, 'beta_1': 0.9173446230974738, 'beta_2': 0.9781263507873906, 'epsilon': 1.6823780247751034e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0006437088344075387, 'tol': 0.00035272898929652796, 'validation_fraction': 0.3207796722786491}
observation time 0.000071, current best -0.974944 at iter 13
suggestion time taken 0.002348 iter 14 next_points [{'alpha': 0.01136283572461386, 'batch_size': 95, 'beta_1': 0.6652067429719782, 'beta_2': 0.9672369964996652, 'epsilon': 2.682113611558728e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.01461409575946628, 'tol': 0.0021445954394134366, 'validation_fraction': 0.2285682025233587}]
function_evaluation time 1.120811 value -0.959652 suggestion {'alpha': 0.01136283572461386, 'batch_size': 95, 'beta_1': 0.6652067429719782, 'beta_2': 0.9672369964996652, 'epsilon': 2.682113611558728e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.01461409575946628, 'tol': 0.0021445954394134366, 'validation_fraction': 0.2285682025233587}
observation time 0.000071, current best -0.974944 at iter 14
saving meta data: {'args': {'--uuid': 'd60a0a43b1965d7f871714bcd2be6f87', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
