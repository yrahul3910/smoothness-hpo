running: {'--uuid': '7e678730a26f59509caad830c3ce01fa', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 7e678730a26f59509caad830c3ce01fa -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002632 iter 0 next_points [{'alpha': 0.09558351270319554, 'batch_size': 166, 'beta_1': 0.8921172102850824, 'beta_2': 0.9997806668633766, 'epsilon': 4.598868850811544e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.06479552920691992, 'tol': 0.01491462159131364, 'validation_fraction': 0.5200312561248595}]
function_evaluation time 0.795419 value -0.810022 suggestion {'alpha': 0.09558351270319554, 'batch_size': 166, 'beta_1': 0.8921172102850824, 'beta_2': 0.9997806668633766, 'epsilon': 4.598868850811544e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.06479552920691992, 'tol': 0.01491462159131364, 'validation_fraction': 0.5200312561248595}
observation time 0.001513, current best -0.810022 at iter 0
suggestion time taken 0.001906 iter 1 next_points [{'alpha': 2.317176901772133, 'batch_size': 50, 'beta_1': 0.9056415700503848, 'beta_2': 0.9190619431898062, 'epsilon': 4.780647773124361e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0022086603131228253, 'tol': 0.009020080249090774, 'validation_fraction': 0.8872982707496484}]
function_evaluation time 0.375863 value -0.880297 suggestion {'alpha': 2.317176901772133, 'batch_size': 50, 'beta_1': 0.9056415700503848, 'beta_2': 0.9190619431898062, 'epsilon': 4.780647773124361e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0022086603131228253, 'tol': 0.009020080249090774, 'validation_fraction': 0.8872982707496484}
observation time 0.001528, current best -0.880297 at iter 1
suggestion time taken 0.001928 iter 2 next_points [{'alpha': 7.496975218864243e-05, 'batch_size': 104, 'beta_1': 0.8590721757550163, 'beta_2': 0.9999987446596412, 'epsilon': 1.2843728348545844e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 2.9164459981204148e-05, 'tol': 0.005006930712475075, 'validation_fraction': 0.35884480748921116}]
function_evaluation time 2.328947 value -0.353845 suggestion {'alpha': 7.496975218864243e-05, 'batch_size': 104, 'beta_1': 0.8590721757550163, 'beta_2': 0.9999987446596412, 'epsilon': 1.2843728348545844e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 2.9164459981204148e-05, 'tol': 0.005006930712475075, 'validation_fraction': 0.35884480748921116}
observation time 0.001672, current best -0.880297 at iter 2
suggestion time taken 0.002038 iter 3 next_points [{'alpha': 2.9765172493059766, 'batch_size': 181, 'beta_1': 0.7652973315362878, 'beta_2': 0.9997282256569897, 'epsilon': 7.726031309720116e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.03407606004695227, 'tol': 0.00018683921695407166, 'validation_fraction': 0.4545466284410978}]
function_evaluation time 0.907764 value -0.957557 suggestion {'alpha': 2.9765172493059766, 'batch_size': 181, 'beta_1': 0.7652973315362878, 'beta_2': 0.9997282256569897, 'epsilon': 7.726031309720116e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.03407606004695227, 'tol': 0.00018683921695407166, 'validation_fraction': 0.4545466284410978}
observation time 0.001571, current best -0.957557 at iter 3
suggestion time taken 0.002085 iter 4 next_points [{'alpha': 9.357643240260217, 'batch_size': 38, 'beta_1': 0.935301854799734, 'beta_2': 0.9999929664873048, 'epsilon': 1.2574794722815718e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0055962951019776315, 'tol': 1.6262131774060947e-05, 'validation_fraction': 0.38842441844565084}]
function_evaluation time 0.948032 value -0.949209 suggestion {'alpha': 9.357643240260217, 'batch_size': 38, 'beta_1': 0.935301854799734, 'beta_2': 0.9999929664873048, 'epsilon': 1.2574794722815718e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0055962951019776315, 'tol': 1.6262131774060947e-05, 'validation_fraction': 0.38842441844565084}
observation time 0.001528, current best -0.957557 at iter 4
suggestion time taken 0.001877 iter 5 next_points [{'alpha': 0.012301969052549504, 'batch_size': 194, 'beta_1': 0.9885544254947629, 'beta_2': 0.9999539280175527, 'epsilon': 1.1850127672623454e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0001036573276121813, 'tol': 0.028512213381313024, 'validation_fraction': 0.6393495485166986}]
function_evaluation time 0.293907 value -0.147549 suggestion {'alpha': 0.012301969052549504, 'batch_size': 194, 'beta_1': 0.9885544254947629, 'beta_2': 0.9999539280175527, 'epsilon': 1.1850127672623454e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0001036573276121813, 'tol': 0.028512213381313024, 'validation_fraction': 0.6393495485166986}
observation time 0.001462, current best -0.957557 at iter 5
suggestion time taken 0.001922 iter 6 next_points [{'alpha': 0.030658572472327512, 'batch_size': 127, 'beta_1': 0.9193459020084509, 'beta_2': 0.9987851297828889, 'epsilon': 7.141664108344348e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.013267873689308226, 'tol': 9.128609722548587e-05, 'validation_fraction': 0.10328785604247351}]
function_evaluation time 1.106775 value -0.968682 suggestion {'alpha': 0.030658572472327512, 'batch_size': 127, 'beta_1': 0.9193459020084509, 'beta_2': 0.9987851297828889, 'epsilon': 7.141664108344348e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.013267873689308226, 'tol': 9.128609722548587e-05, 'validation_fraction': 0.10328785604247351}
observation time 0.001482, current best -0.968682 at iter 6
suggestion time taken 0.001909 iter 7 next_points [{'alpha': 0.0018564655155411825, 'batch_size': 226, 'beta_1': 0.9843398871853297, 'beta_2': 0.9994665624840801, 'epsilon': 3.743065003143622e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.04327840307673548, 'tol': 0.00013832329784712916, 'validation_fraction': 0.17027837943542498}]
function_evaluation time 1.551694 value -0.865696 suggestion {'alpha': 0.0018564655155411825, 'batch_size': 226, 'beta_1': 0.9843398871853297, 'beta_2': 0.9994665624840801, 'epsilon': 3.743065003143622e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.04327840307673548, 'tol': 0.00013832329784712916, 'validation_fraction': 0.17027837943542498}
observation time 0.001438, current best -0.968682 at iter 7
suggestion time taken 0.001871 iter 8 next_points [{'alpha': 0.0013266474537790727, 'batch_size': 216, 'beta_1': 0.9750344693308279, 'beta_2': 0.9970910696553983, 'epsilon': 5.672805198240645e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0003821826453605665, 'tol': 0.0009790737266715773, 'validation_fraction': 0.7713340637220415}]
function_evaluation time 1.579222 value -0.747002 suggestion {'alpha': 0.0013266474537790727, 'batch_size': 216, 'beta_1': 0.9750344693308279, 'beta_2': 0.9970910696553983, 'epsilon': 5.672805198240645e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0003821826453605665, 'tol': 0.0009790737266715773, 'validation_fraction': 0.7713340637220415}
observation time 0.001483, current best -0.968682 at iter 8
suggestion time taken 0.001883 iter 9 next_points [{'alpha': 0.0004161324679838538, 'batch_size': 24, 'beta_1': 0.7750638954696188, 'beta_2': 0.9896785808794388, 'epsilon': 2.6734369563281146e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 6.464342868499326e-05, 'tol': 1.2047227951145745e-05, 'validation_fraction': 0.6434188633032751}]
function_evaluation time 6.732466 value -0.943646 suggestion {'alpha': 0.0004161324679838538, 'batch_size': 24, 'beta_1': 0.7750638954696188, 'beta_2': 0.9896785808794388, 'epsilon': 2.6734369563281146e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 6.464342868499326e-05, 'tol': 1.2047227951145745e-05, 'validation_fraction': 0.6434188633032751}
observation time 0.001531, current best -0.968682 at iter 9
suggestion time taken 0.002023 iter 10 next_points [{'alpha': 0.00010303195065955257, 'batch_size': 88, 'beta_1': 0.7124606352919729, 'beta_2': 0.999996754940127, 'epsilon': 1.7958284978259887e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.003648028961862786, 'tol': 5.208230157610611e-05, 'validation_fraction': 0.7840513576908764}]
function_evaluation time 1.225956 value -0.935308 suggestion {'alpha': 0.00010303195065955257, 'batch_size': 88, 'beta_1': 0.7124606352919729, 'beta_2': 0.999996754940127, 'epsilon': 1.7958284978259887e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.003648028961862786, 'tol': 5.208230157610611e-05, 'validation_fraction': 0.7840513576908764}
observation time 0.001479, current best -0.968682 at iter 10
suggestion time taken 0.002162 iter 11 next_points [{'alpha': 0.39202763134296165, 'batch_size': 146, 'beta_1': 0.9657965579650637, 'beta_2': 0.9998803634746533, 'epsilon': 1.8625993237574526e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0012780794955046073, 'tol': 3.612826921383852e-05, 'validation_fraction': 0.7382534486574371}]
function_evaluation time 1.140773 value -0.923466 suggestion {'alpha': 0.39202763134296165, 'batch_size': 146, 'beta_1': 0.9657965579650637, 'beta_2': 0.9998803634746533, 'epsilon': 1.8625993237574526e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0012780794955046073, 'tol': 3.612826921383852e-05, 'validation_fraction': 0.7382534486574371}
observation time 0.001515, current best -0.968682 at iter 11
suggestion time taken 0.002244 iter 12 next_points [{'alpha': 0.8393678556258876, 'batch_size': 117, 'beta_1': 0.5593099494693641, 'beta_2': 0.9999867147110149, 'epsilon': 3.632332773079136e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.1063354381564042e-05, 'tol': 0.00032623792229772945, 'validation_fraction': 0.23492553850044065}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.840953 value -0.105681 suggestion {'alpha': 0.8393678556258876, 'batch_size': 117, 'beta_1': 0.5593099494693641, 'beta_2': 0.9999867147110149, 'epsilon': 3.632332773079136e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.1063354381564042e-05, 'tol': 0.00032623792229772945, 'validation_fraction': 0.23492553850044065}
observation time 0.001440, current best -0.968682 at iter 12
suggestion time taken 0.002178 iter 13 next_points [{'alpha': 4.2284337083584566e-05, 'batch_size': 201, 'beta_1': 0.5841145216675282, 'beta_2': 0.9999946841023963, 'epsilon': 9.209839297443103e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0001603654535405165, 'tol': 0.0007514875261192494, 'validation_fraction': 0.20044924031008296}]
function_evaluation time 2.437670 value -0.878944 suggestion {'alpha': 4.2284337083584566e-05, 'batch_size': 201, 'beta_1': 0.5841145216675282, 'beta_2': 0.9999946841023963, 'epsilon': 9.209839297443103e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0001603654535405165, 'tol': 0.0007514875261192494, 'validation_fraction': 0.20044924031008296}
observation time 0.001468, current best -0.968682 at iter 13
suggestion time taken 0.001841 iter 14 next_points [{'alpha': 0.23063242502371975, 'batch_size': 84, 'beta_1': 0.6213887442463827, 'beta_2': 0.9921013900964397, 'epsilon': 1.738193211422427e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0005248032710548584, 'tol': 0.0465184825478964, 'validation_fraction': 0.8439853988302819}]
function_evaluation time 0.210320 value -0.366834 suggestion {'alpha': 0.23063242502371975, 'batch_size': 84, 'beta_1': 0.6213887442463827, 'beta_2': 0.9921013900964397, 'epsilon': 1.738193211422427e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0005248032710548584, 'tol': 0.0465184825478964, 'validation_fraction': 0.8439853988302819}
observation time 0.001488, current best -0.968682 at iter 14
saving meta data: {'args': {'--uuid': '7e678730a26f59509caad830c3ce01fa', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
