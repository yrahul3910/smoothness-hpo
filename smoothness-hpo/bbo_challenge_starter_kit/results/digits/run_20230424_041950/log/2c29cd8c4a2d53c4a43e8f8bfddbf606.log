running: {'--uuid': '2c29cd8c4a2d53c4a43e8f8bfddbf606', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 2c29cd8c4a2d53c4a43e8f8bfddbf606 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002481 iter 0 next_points [{'alpha': 0.0002469198752653499, 'batch_size': 224, 'beta_1': 0.5930579824463689, 'beta_2': 0.9997456088450102, 'epsilon': 1.8006527049507615e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.018216648657948385, 'tol': 0.005462464830495457, 'validation_fraction': 0.38268013290562486}]
function_evaluation time 0.591719 value -0.961738 suggestion {'alpha': 0.0002469198752653499, 'batch_size': 224, 'beta_1': 0.5930579824463689, 'beta_2': 0.9997456088450102, 'epsilon': 1.8006527049507615e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.018216648657948385, 'tol': 0.005462464830495457, 'validation_fraction': 0.38268013290562486}
observation time 0.001595, current best -0.961738 at iter 0
suggestion time taken 0.001847 iter 1 next_points [{'alpha': 0.0004072745816913931, 'batch_size': 83, 'beta_1': 0.9856290596313872, 'beta_2': 0.9984237218106505, 'epsilon': 1.438496584764878e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0527203678509707, 'tol': 0.014379090166149917, 'validation_fraction': 0.4686725339356883}]
function_evaluation time 0.688206 value -0.548343 suggestion {'alpha': 0.0004072745816913931, 'batch_size': 83, 'beta_1': 0.9856290596313872, 'beta_2': 0.9984237218106505, 'epsilon': 1.438496584764878e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0527203678509707, 'tol': 0.014379090166149917, 'validation_fraction': 0.4686725339356883}
observation time 0.001338, current best -0.961738 at iter 1
suggestion time taken 0.001725 iter 2 next_points [{'alpha': 6.946694000672293e-05, 'batch_size': 145, 'beta_1': 0.689941942428765, 'beta_2': 0.9999861333612888, 'epsilon': 8.248705087137282e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.1362811867891607e-05, 'tol': 0.0013219289195219401, 'validation_fraction': 0.49971495014480194}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.937425 value -0.192874 suggestion {'alpha': 6.946694000672293e-05, 'batch_size': 145, 'beta_1': 0.689941942428765, 'beta_2': 0.9999861333612888, 'epsilon': 8.248705087137282e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.1362811867891607e-05, 'tol': 0.0013219289195219401, 'validation_fraction': 0.49971495014480194}
observation time 0.001363, current best -0.961738 at iter 2
suggestion time taken 0.001996 iter 3 next_points [{'alpha': 0.0009262550004441743, 'batch_size': 20, 'beta_1': 0.9772591512950148, 'beta_2': 0.9751086787935479, 'epsilon': 1.3361160854454764e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.00014186637440882874, 'tol': 0.0024070824217584984, 'validation_fraction': 0.5535538070936638}]
function_evaluation time 3.575879 value -0.949206 suggestion {'alpha': 0.0009262550004441743, 'batch_size': 20, 'beta_1': 0.9772591512950148, 'beta_2': 0.9751086787935479, 'epsilon': 1.3361160854454764e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.00014186637440882874, 'tol': 0.0024070824217584984, 'validation_fraction': 0.5535538070936638}
observation time 0.001388, current best -0.961738 at iter 3
suggestion time taken 0.001779 iter 4 next_points [{'alpha': 0.05858547436638284, 'batch_size': 192, 'beta_1': 0.8368272475893641, 'beta_2': 0.9371826545378955, 'epsilon': 5.463926981440164e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.006397445001802647, 'tol': 0.0320914881075517, 'validation_fraction': 0.2775366294399575}]
function_evaluation time 0.476650 value -0.961031 suggestion {'alpha': 0.05858547436638284, 'batch_size': 192, 'beta_1': 0.8368272475893641, 'beta_2': 0.9371826545378955, 'epsilon': 5.463926981440164e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.006397445001802647, 'tol': 0.0320914881075517, 'validation_fraction': 0.2775366294399575}
observation time 0.001611, current best -0.961738 at iter 4
suggestion time taken 0.001790 iter 5 next_points [{'alpha': 0.6328891748868319, 'batch_size': 63, 'beta_1': 0.8705315772734548, 'beta_2': 0.9999477788786094, 'epsilon': 3.125290684526877e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0034741447846167667, 'tol': 1.7860087179742187e-05, 'validation_fraction': 0.7881875006264241}]
function_evaluation time 1.015849 value -0.917197 suggestion {'alpha': 0.6328891748868319, 'batch_size': 63, 'beta_1': 0.8705315772734548, 'beta_2': 0.9999477788786094, 'epsilon': 3.125290684526877e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0034741447846167667, 'tol': 1.7860087179742187e-05, 'validation_fraction': 0.7881875006264241}
observation time 0.001332, current best -0.961738 at iter 5
suggestion time taken 0.001716 iter 6 next_points [{'alpha': 1.851305873054738, 'batch_size': 90, 'beta_1': 0.9320940330034267, 'beta_2': 0.9997872003084933, 'epsilon': 8.540390791557822e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0009848344435037179, 'tol': 3.721522362605609e-05, 'validation_fraction': 0.8394097825813144}]
function_evaluation time 1.486924 value -0.865016 suggestion {'alpha': 1.851305873054738, 'batch_size': 90, 'beta_1': 0.9320940330034267, 'beta_2': 0.9997872003084933, 'epsilon': 8.540390791557822e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0009848344435037179, 'tol': 3.721522362605609e-05, 'validation_fraction': 0.8394097825813144}
observation time 0.001353, current best -0.961738 at iter 6
suggestion time taken 0.002024 iter 7 next_points [{'alpha': 0.01745043610553715, 'batch_size': 153, 'beta_1': 0.5181850177936926, 'beta_2': 0.9999685796266606, 'epsilon': 1.4741800836191008e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0018066545242614055, 'tol': 0.005316687151097894, 'validation_fraction': 0.7115635658188508}]
function_evaluation time 0.698089 value -0.882416 suggestion {'alpha': 0.01745043610553715, 'batch_size': 153, 'beta_1': 0.5181850177936926, 'beta_2': 0.9999685796266606, 'epsilon': 1.4741800836191008e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0018066545242614055, 'tol': 0.005316687151097894, 'validation_fraction': 0.7115635658188508}
observation time 0.001382, current best -0.961738 at iter 7
suggestion time taken 0.001777 iter 8 next_points [{'alpha': 0.00016094989542162058, 'batch_size': 242, 'beta_1': 0.9044243110164008, 'beta_2': 0.9999003696031936, 'epsilon': 4.327110789702257e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.014224391918050697, 'tol': 0.0009629735480877365, 'validation_fraction': 0.6359921943070956}]
function_evaluation time 0.800872 value -0.940159 suggestion {'alpha': 0.00016094989542162058, 'batch_size': 242, 'beta_1': 0.9044243110164008, 'beta_2': 0.9999003696031936, 'epsilon': 4.327110789702257e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.014224391918050697, 'tol': 0.0009629735480877365, 'validation_fraction': 0.6359921943070956}
observation time 0.001372, current best -0.961738 at iter 8
suggestion time taken 0.001742 iter 9 next_points [{'alpha': 2.381889331631351, 'batch_size': 26, 'beta_1': 0.9882097166160421, 'beta_2': 0.9999989213985839, 'epsilon': 9.021222258127603e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00018958610346683243, 'tol': 0.0005341428084072295, 'validation_fraction': 0.1340160301567037}]
function_evaluation time 3.062323 value -0.944326 suggestion {'alpha': 2.381889331631351, 'batch_size': 26, 'beta_1': 0.9882097166160421, 'beta_2': 0.9999989213985839, 'epsilon': 9.021222258127603e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00018958610346683243, 'tol': 0.0005341428084072295, 'validation_fraction': 0.1340160301567037}
observation time 0.001399, current best -0.961738 at iter 9
suggestion time taken 0.001806 iter 10 next_points [{'alpha': 0.010328015871106594, 'batch_size': 177, 'beta_1': 0.9717910371250899, 'beta_2': 0.9999923394504869, 'epsilon': 1.8372851366098162e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 2.106755339645002e-05, 'tol': 8.388838736670673e-05, 'validation_fraction': 0.2584099781464427}]
function_evaluation time 0.591776 value -0.087064 suggestion {'alpha': 0.010328015871106594, 'batch_size': 177, 'beta_1': 0.9717910371250899, 'beta_2': 0.9999923394504869, 'epsilon': 1.8372851366098162e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 2.106755339645002e-05, 'tol': 8.388838736670673e-05, 'validation_fraction': 0.2584099781464427}
observation time 0.001452, current best -0.961738 at iter 10
suggestion time taken 0.001704 iter 11 next_points [{'alpha': 2.7093573220629935e-05, 'batch_size': 108, 'beta_1': 0.9661828512932225, 'beta_2': 0.9991810468681475, 'epsilon': 4.670638374775727e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0027615530082936244, 'tol': 0.04317608830636155, 'validation_fraction': 0.19359241788413725}]
function_evaluation time 0.639720 value -0.958950 suggestion {'alpha': 2.7093573220629935e-05, 'batch_size': 108, 'beta_1': 0.9661828512932225, 'beta_2': 0.9991810468681475, 'epsilon': 4.670638374775727e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0027615530082936244, 'tol': 0.04317608830636155, 'validation_fraction': 0.19359241788413725}
observation time 0.001420, current best -0.961738 at iter 11
suggestion time taken 0.002014 iter 12 next_points [{'alpha': 0.09845944262139032, 'batch_size': 116, 'beta_1': 0.7983267455203558, 'beta_2': 0.9905993131279036, 'epsilon': 3.392500380627605e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.07388371924052396, 'tol': 0.00014870643946616387, 'validation_fraction': 0.8751837503890454}]
function_evaluation time 0.679152 value -0.575322 suggestion {'alpha': 0.09845944262139032, 'batch_size': 116, 'beta_1': 0.7983267455203558, 'beta_2': 0.9905993131279036, 'epsilon': 3.392500380627605e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.07388371924052396, 'tol': 0.00014870643946616387, 'validation_fraction': 0.8751837503890454}
observation time 0.001357, current best -0.961738 at iter 12
suggestion time taken 0.001714 iter 13 next_points [{'alpha': 1.2647527364507948e-05, 'batch_size': 211, 'beta_1': 0.6385878615460857, 'beta_2': 0.9999972183605281, 'epsilon': 2.311488692568522e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 8.268642181863113e-05, 'tol': 0.00018611090168175833, 'validation_fraction': 0.6587864224120931}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.526507 value -0.554759 suggestion {'alpha': 1.2647527364507948e-05, 'batch_size': 211, 'beta_1': 0.6385878615460857, 'beta_2': 0.9999972183605281, 'epsilon': 2.311488692568522e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 8.268642181863113e-05, 'tol': 0.00018611090168175833, 'validation_fraction': 0.6587864224120931}
observation time 0.001336, current best -0.961738 at iter 13
suggestion time taken 0.002038 iter 14 next_points [{'alpha': 0.004436340659295258, 'batch_size': 36, 'beta_1': 0.9814211098052503, 'beta_2': 0.9999952743939102, 'epsilon': 9.381350233006834e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0007548756689273393, 'tol': 1.0147880187499307e-05, 'validation_fraction': 0.7658762185304779}]
function_evaluation time 1.385408 value -0.929043 suggestion {'alpha': 0.004436340659295258, 'batch_size': 36, 'beta_1': 0.9814211098052503, 'beta_2': 0.9999952743939102, 'epsilon': 9.381350233006834e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0007548756689273393, 'tol': 1.0147880187499307e-05, 'validation_fraction': 0.7658762185304779}
observation time 0.001388, current best -0.961738 at iter 14
saving meta data: {'args': {'--uuid': '2c29cd8c4a2d53c4a43e8f8bfddbf606', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
