running: {'--uuid': '51f0d81bfa525c688f007ea07a24331f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 51f0d81bfa525c688f007ea07a24331f -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002604 iter 0 next_points [{'alpha': 0.001558307113947189, 'batch_size': 103, 'beta_1': 0.9877592316504626, 'beta_2': 0.9932072473165494, 'epsilon': 2.0398034078910427e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0003671151001882796, 'tol': 0.013647309324891537, 'validation_fraction': 0.35612813531079757}]
function_evaluation time 1.003440 value -0.917204 suggestion {'alpha': 0.001558307113947189, 'batch_size': 103, 'beta_1': 0.9877592316504626, 'beta_2': 0.9932072473165494, 'epsilon': 2.0398034078910427e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0003671151001882796, 'tol': 0.013647309324891537, 'validation_fraction': 0.35612813531079757}
observation time 0.000007, current best -0.917204 at iter 0
suggestion time taken 0.002536 iter 1 next_points [{'alpha': 0.010831247073038444, 'batch_size': 99, 'beta_1': 0.7358540605771414, 'beta_2': 0.9380242711341823, 'epsilon': 3.1883525393060623e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 2.8916018015857278e-05, 'tol': 0.0022577176494861344, 'validation_fraction': 0.8495910468675469}]
function_evaluation time 0.157782 value -0.063320 suggestion {'alpha': 0.010831247073038444, 'batch_size': 99, 'beta_1': 0.7358540605771414, 'beta_2': 0.9380242711341823, 'epsilon': 3.1883525393060623e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 2.8916018015857278e-05, 'tol': 0.0022577176494861344, 'validation_fraction': 0.8495910468675469}
observation time 0.000006, current best -0.917204 at iter 1
suggestion time taken 0.002798 iter 2 next_points [{'alpha': 3.062701147848954, 'batch_size': 122, 'beta_1': 0.8005653016671826, 'beta_2': 0.9998768110779437, 'epsilon': 3.4284307545221147e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.01752405101348123, 'tol': 0.0026461633763359654, 'validation_fraction': 0.3243688316013586}]
function_evaluation time 0.648064 value -0.965924 suggestion {'alpha': 3.062701147848954, 'batch_size': 122, 'beta_1': 0.8005653016671826, 'beta_2': 0.9998768110779437, 'epsilon': 3.4284307545221147e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.01752405101348123, 'tol': 0.0026461633763359654, 'validation_fraction': 0.3243688316013586}
observation time 0.000006, current best -0.965924 at iter 2
suggestion time taken 0.002487 iter 3 next_points [{'alpha': 1.6148509483688511, 'batch_size': 191, 'beta_1': 0.8836497303104239, 'beta_2': 0.9997432822561826, 'epsilon': 8.385329525052696e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 6.803034552483522e-05, 'tol': 0.0663909752671082, 'validation_fraction': 0.4043581806594972}]
function_evaluation time 0.369779 value -0.182937 suggestion {'alpha': 1.6148509483688511, 'batch_size': 191, 'beta_1': 0.8836497303104239, 'beta_2': 0.9997432822561826, 'epsilon': 8.385329525052696e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 6.803034552483522e-05, 'tol': 0.0663909752671082, 'validation_fraction': 0.4043581806594972}
observation time 0.000006, current best -0.965924 at iter 3
suggestion time taken 0.002549 iter 4 next_points [{'alpha': 0.0007563889136797293, 'batch_size': 190, 'beta_1': 0.9642044442701316, 'beta_2': 0.9999952783316916, 'epsilon': 1.8802817952882383e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.0006813530270300476, 'tol': 0.04327535011066025, 'validation_fraction': 0.5186466824640351}]
function_evaluation time 0.474041 value -0.864956 suggestion {'alpha': 0.0007563889136797293, 'batch_size': 190, 'beta_1': 0.9642044442701316, 'beta_2': 0.9999952783316916, 'epsilon': 1.8802817952882383e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.0006813530270300476, 'tol': 0.04327535011066025, 'validation_fraction': 0.5186466824640351}
observation time 0.000006, current best -0.965924 at iter 4
suggestion time taken 0.002470 iter 5 next_points [{'alpha': 0.00026917421585994326, 'batch_size': 107, 'beta_1': 0.7305290646888783, 'beta_2': 0.9991723184395267, 'epsilon': 1.019421960181246e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 7.590756699178005e-05, 'tol': 0.07686244240946394, 'validation_fraction': 0.6000393862171388}]
function_evaluation time 0.259117 value -0.151725 suggestion {'alpha': 0.00026917421585994326, 'batch_size': 107, 'beta_1': 0.7305290646888783, 'beta_2': 0.9991723184395267, 'epsilon': 1.019421960181246e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 7.590756699178005e-05, 'tol': 0.07686244240946394, 'validation_fraction': 0.6000393862171388}
observation time 0.000005, current best -0.965924 at iter 5
suggestion time taken 0.002480 iter 6 next_points [{'alpha': 4.245258858425936, 'batch_size': 132, 'beta_1': 0.9836649468107816, 'beta_2': 0.9999633256333877, 'epsilon': 1.6990530763772458e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.005322027088802456, 'tol': 0.0573589380803408, 'validation_fraction': 0.8885875520907776}]
function_evaluation time 0.198537 value -0.764804 suggestion {'alpha': 4.245258858425936, 'batch_size': 132, 'beta_1': 0.9836649468107816, 'beta_2': 0.9999633256333877, 'epsilon': 1.6990530763772458e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.005322027088802456, 'tol': 0.0573589380803408, 'validation_fraction': 0.8885875520907776}
observation time 0.000004, current best -0.965924 at iter 6
suggestion time taken 0.002793 iter 7 next_points [{'alpha': 9.965892389407164, 'batch_size': 126, 'beta_1': 0.9764677038785798, 'beta_2': 0.9999961872692121, 'epsilon': 1.3726200382270036e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 3.06167147318889e-05, 'tol': 0.0040927731303931555, 'validation_fraction': 0.8479952177662955}]
function_evaluation time 0.146878 value -0.075121 suggestion {'alpha': 9.965892389407164, 'batch_size': 126, 'beta_1': 0.9764677038785798, 'beta_2': 0.9999961872692121, 'epsilon': 1.3726200382270036e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 3.06167147318889e-05, 'tol': 0.0040927731303931555, 'validation_fraction': 0.8479952177662955}
observation time 0.000005, current best -0.965924 at iter 7
suggestion time taken 0.002518 iter 8 next_points [{'alpha': 0.17122659302625004, 'batch_size': 111, 'beta_1': 0.8097043088376297, 'beta_2': 0.9999989446690156, 'epsilon': 5.261939439226936e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0002612961885448843, 'tol': 0.06488160202349856, 'validation_fraction': 0.3547937267835025}]
function_evaluation time 0.510677 value -0.688308 suggestion {'alpha': 0.17122659302625004, 'batch_size': 111, 'beta_1': 0.8097043088376297, 'beta_2': 0.9999989446690156, 'epsilon': 5.261939439226936e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0002612961885448843, 'tol': 0.06488160202349856, 'validation_fraction': 0.3547937267835025}
observation time 0.000005, current best -0.965924 at iter 8
suggestion time taken 0.002562 iter 9 next_points [{'alpha': 0.01968392419579902, 'batch_size': 176, 'beta_1': 0.8322060960495069, 'beta_2': 0.9998910399123487, 'epsilon': 2.891789213658402e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0031624987572546246, 'tol': 0.0032015641653616272, 'validation_fraction': 0.2885516847538923}]
function_evaluation time 0.705265 value -0.961019 suggestion {'alpha': 0.01968392419579902, 'batch_size': 176, 'beta_1': 0.8322060960495069, 'beta_2': 0.9998910399123487, 'epsilon': 2.891789213658402e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0031624987572546246, 'tol': 0.0032015641653616272, 'validation_fraction': 0.2885516847538923}
observation time 0.000005, current best -0.965924 at iter 9
suggestion time taken 0.002533 iter 10 next_points [{'alpha': 3.2383675236760553e-05, 'batch_size': 84, 'beta_1': 0.9565035323054171, 'beta_2': 0.9999368197320384, 'epsilon': 2.3829415420303974e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 8.395847755124013e-05, 'tol': 6.409165281335996e-05, 'validation_fraction': 0.8950197065559659}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.563370 value -0.376084 suggestion {'alpha': 3.2383675236760553e-05, 'batch_size': 84, 'beta_1': 0.9565035323054171, 'beta_2': 0.9999368197320384, 'epsilon': 2.3829415420303974e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 8.395847755124013e-05, 'tol': 6.409165281335996e-05, 'validation_fraction': 0.8950197065559659}
observation time 0.000006, current best -0.965924 at iter 10
suggestion time taken 0.002569 iter 11 next_points [{'alpha': 1.2040747588632406, 'batch_size': 235, 'beta_1': 0.9886282591896851, 'beta_2': 0.9984414354038188, 'epsilon': 2.08406219329192e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 2.9039168620942195e-05, 'tol': 0.025363136300402114, 'validation_fraction': 0.7496680289403082}]
function_evaluation time 0.171221 value -0.080043 suggestion {'alpha': 1.2040747588632406, 'batch_size': 235, 'beta_1': 0.9886282591896851, 'beta_2': 0.9984414354038188, 'epsilon': 2.08406219329192e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 2.9039168620942195e-05, 'tol': 0.025363136300402114, 'validation_fraction': 0.7496680289403082}
observation time 0.000005, current best -0.965924 at iter 11
suggestion time taken 0.002492 iter 12 next_points [{'alpha': 0.06929847302383374, 'batch_size': 53, 'beta_1': 0.9585620769869361, 'beta_2': 0.9998109218242585, 'epsilon': 1.7249109055953086e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.02625940236819531, 'tol': 2.2541283917659988e-05, 'validation_fraction': 0.1359245609723038}]
function_evaluation time 0.994038 value -0.964518 suggestion {'alpha': 0.06929847302383374, 'batch_size': 53, 'beta_1': 0.9585620769869361, 'beta_2': 0.9998109218242585, 'epsilon': 1.7249109055953086e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.02625940236819531, 'tol': 2.2541283917659988e-05, 'validation_fraction': 0.1359245609723038}
observation time 0.000005, current best -0.965924 at iter 12
suggestion time taken 0.002460 iter 13 next_points [{'alpha': 1.0110973073044072, 'batch_size': 188, 'beta_1': 0.779414621081582, 'beta_2': 0.9999966326218236, 'epsilon': 4.874641803288542e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.023316438952771933, 'tol': 0.07571702667881741, 'validation_fraction': 0.3605602168773268}]
function_evaluation time 0.323407 value -0.954767 suggestion {'alpha': 1.0110973073044072, 'batch_size': 188, 'beta_1': 0.779414621081582, 'beta_2': 0.9999966326218236, 'epsilon': 4.874641803288542e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.023316438952771933, 'tol': 0.07571702667881741, 'validation_fraction': 0.3605602168773268}
observation time 0.000006, current best -0.965924 at iter 13
suggestion time taken 0.002414 iter 14 next_points [{'alpha': 0.00032005931504419573, 'batch_size': 32, 'beta_1': 0.9899279733711177, 'beta_2': 0.9998977358107378, 'epsilon': 2.4119593936513597e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.001141760825161735, 'tol': 0.0005821655652878439, 'validation_fraction': 0.5337397943288709}]
function_evaluation time 1.606254 value -0.939453 suggestion {'alpha': 0.00032005931504419573, 'batch_size': 32, 'beta_1': 0.9899279733711177, 'beta_2': 0.9998977358107378, 'epsilon': 2.4119593936513597e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.001141760825161735, 'tol': 0.0005821655652878439, 'validation_fraction': 0.5337397943288709}
observation time 0.000006, current best -0.965924 at iter 14
saving meta data: {'args': {'--uuid': '51f0d81bfa525c688f007ea07a24331f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
