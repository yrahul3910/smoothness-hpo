running: {'--uuid': '461881ce930c59c19293a433eee5bc25', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d digits -o opentuner -u 461881ce930c59c19293a433eee5bc25 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study opentuner MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.017998 iter 0 next_points [{'hidden_layer_sizes': 117, 'alpha': 3.3528120375475026, 'batch_size': 30, 'learning_rate_init': 0.07828597470333658, 'tol': 0.08178206622712351, 'validation_fraction': 0.2542693774027585, 'beta_1': 0.9623400832043387, 'beta_2': 0.9849759379812221, 'epsilon': 3.821791380314844e-07}]
function_evaluation time 0.813092 value -0.895625 suggestion {'hidden_layer_sizes': 117, 'alpha': 3.3528120375475026, 'batch_size': 30, 'learning_rate_init': 0.07828597470333658, 'tol': 0.08178206622712351, 'validation_fraction': 0.2542693774027585, 'beta_1': 0.9623400832043387, 'beta_2': 0.9849759379812221, 'epsilon': 3.821791380314844e-07}
observation time 0.004213, current best -0.895625 at iter 0
suggestion time taken 0.021402 iter 1 next_points [{'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.20351334182579184}]
function_evaluation time 0.646242 value -0.955468 suggestion {'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.20351334182579184}
observation time 0.001870, current best -0.955468 at iter 1
suggestion time taken 0.046129 iter 2 next_points [{'hidden_layer_sizes': 135, 'batch_size': 134, 'tol': 0.05334612273772781, 'learning_rate_init': 0.08445470162804118, 'epsilon': 6.732668433045697e-07, 'beta_2': 0.9061185483170556, 'alpha': 3.4609200514410747, 'beta_1': 0.5149171893336155, 'validation_fraction': 0.5904422169748695}]
function_evaluation time 0.343605 value -0.620785 suggestion {'hidden_layer_sizes': 135, 'batch_size': 134, 'tol': 0.05334612273772781, 'learning_rate_init': 0.08445470162804118, 'epsilon': 6.732668433045697e-07, 'beta_2': 0.9061185483170556, 'alpha': 3.4609200514410747, 'beta_1': 0.5149171893336155, 'validation_fraction': 0.5904422169748695}
observation time 0.001908, current best -0.955468 at iter 2
suggestion time taken 0.006869 iter 3 next_points [{'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9235222508538271, 'alpha': 0.4007762671343071, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.20351334182579184}]
function_evaluation time 0.639931 value -0.938057 suggestion {'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9235222508538271, 'alpha': 0.4007762671343071, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.20351334182579184}
observation time 0.001881, current best -0.955468 at iter 3
suggestion time taken 0.007084 iter 4 next_points [{'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09589161569616793, 'learning_rate_init': 0.03732213052624849, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.2157436355977959, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.20351334182579184}]
function_evaluation time 0.641374 value -0.942944 suggestion {'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09589161569616793, 'learning_rate_init': 0.03732213052624849, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.2157436355977959, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.20351334182579184}
observation time 0.001856, current best -0.955468 at iter 4
suggestion time taken 0.005910 iter 5 next_points [{'hidden_layer_sizes': 137, 'batch_size': 192, 'tol': 0.07208478396104938, 'learning_rate_init': 0.05509742935326927, 'epsilon': 7.838459573921975e-07, 'beta_2': 0.9705193483950203, 'alpha': 4.617685548148609, 'beta_1': 0.949954001198416, 'validation_fraction': 0.12196432417833583}]
function_evaluation time 0.489180 value -0.938749 suggestion {'hidden_layer_sizes': 137, 'batch_size': 192, 'tol': 0.07208478396104938, 'learning_rate_init': 0.05509742935326927, 'epsilon': 7.838459573921975e-07, 'beta_2': 0.9705193483950203, 'alpha': 4.617685548148609, 'beta_1': 0.949954001198416, 'validation_fraction': 0.12196432417833583}
observation time 0.002235, current best -0.955468 at iter 5
suggestion time taken 0.007289 iter 6 next_points [{'hidden_layer_sizes': 146, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026657620550566575, 'epsilon': 9.457492859138151e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.21061737192523708}]
function_evaluation time 0.653997 value -0.949204 suggestion {'hidden_layer_sizes': 146, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026657620550566575, 'epsilon': 9.457492859138151e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.21061737192523708}
observation time 0.001831, current best -0.955468 at iter 6
suggestion time taken 0.005822 iter 7 next_points [{'hidden_layer_sizes': 127, 'batch_size': 231, 'tol': 0.05602630505160538, 'learning_rate_init': 0.01946324888344957, 'epsilon': 7.531472236149407e-07, 'beta_2': 0.9807298197609954, 'alpha': 0.7797629147814596, 'beta_1': 0.7108517989272464, 'validation_fraction': 0.6298657700649885}]
function_evaluation time 0.271552 value -0.931826 suggestion {'hidden_layer_sizes': 127, 'batch_size': 231, 'tol': 0.05602630505160538, 'learning_rate_init': 0.01946324888344957, 'epsilon': 7.531472236149407e-07, 'beta_2': 0.9807298197609954, 'alpha': 0.7797629147814596, 'beta_1': 0.7108517989272464, 'validation_fraction': 0.6298657700649885}
observation time 0.002125, current best -0.955468 at iter 7
suggestion time taken 0.006247 iter 8 next_points [{'hidden_layer_sizes': 130, 'batch_size': 68, 'tol': 0.025416375234247713, 'learning_rate_init': 0.07496256341894718, 'epsilon': 2.159641857851492e-07, 'beta_2': 0.9476531970896067, 'alpha': 1.824077299070157, 'beta_1': 0.6835136979312015, 'validation_fraction': 0.17893056739403576}]
function_evaluation time 1.136861 value -0.700196 suggestion {'hidden_layer_sizes': 130, 'batch_size': 68, 'tol': 0.025416375234247713, 'learning_rate_init': 0.07496256341894718, 'epsilon': 2.159641857851492e-07, 'beta_2': 0.9476531970896067, 'alpha': 1.824077299070157, 'beta_1': 0.6835136979312015, 'validation_fraction': 0.17893056739403576}
observation time 0.001839, current best -0.955468 at iter 8
suggestion time taken 0.007074 iter 9 next_points [{'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.08613042693443777, 'learning_rate_init': 0.03746576162714959, 'epsilon': 9.777163804408342e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8124083926315984, 'validation_fraction': 0.20351334182579184}]
function_evaluation time 0.650004 value -0.942259 suggestion {'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.08613042693443777, 'learning_rate_init': 0.03746576162714959, 'epsilon': 9.777163804408342e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8124083926315984, 'validation_fraction': 0.20351334182579184}
observation time 0.002770, current best -0.955468 at iter 9
suggestion time taken 0.006572 iter 10 next_points [{'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8891737710159164, 'validation_fraction': 0.20351334182579184}]
function_evaluation time 0.646616 value -0.946436 suggestion {'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.4007762671343071, 'beta_1': 0.8891737710159164, 'validation_fraction': 0.20351334182579184}
observation time 0.001840, current best -0.955468 at iter 10
suggestion time taken 0.005882 iter 11 next_points [{'hidden_layer_sizes': 181, 'batch_size': 247, 'tol': 0.0826015030629436, 'learning_rate_init': 0.08161702347433801, 'epsilon': 1.9977391177480774e-07, 'beta_2': 0.9027745641302104, 'alpha': 7.003453670848602, 'beta_1': 0.6962531503407562, 'validation_fraction': 0.6471950177505456}]
function_evaluation time 0.350701 value -0.629566 suggestion {'hidden_layer_sizes': 181, 'batch_size': 247, 'tol': 0.0826015030629436, 'learning_rate_init': 0.08161702347433801, 'epsilon': 1.9977391177480774e-07, 'beta_2': 0.9027745641302104, 'alpha': 7.003453670848602, 'beta_1': 0.6962531503407562, 'validation_fraction': 0.6471950177505456}
observation time 0.001999, current best -0.955468 at iter 11
suggestion time taken 0.005043 iter 12 next_points [{'hidden_layer_sizes': 193, 'batch_size': 220, 'tol': 0.044046604478779, 'learning_rate_init': 0.07489258385390822, 'epsilon': 8.760612782485088e-08, 'beta_2': 0.9760378199443068, 'alpha': 0.9798258958569509, 'beta_1': 0.966859185322324, 'validation_fraction': 0.5036011623805395}]
function_evaluation time 0.608289 value -0.920681 suggestion {'hidden_layer_sizes': 193, 'batch_size': 220, 'tol': 0.044046604478779, 'learning_rate_init': 0.07489258385390822, 'epsilon': 8.760612782485088e-08, 'beta_2': 0.9760378199443068, 'alpha': 0.9798258958569509, 'beta_1': 0.966859185322324, 'validation_fraction': 0.5036011623805395}
observation time 0.001853, current best -0.955468 at iter 12
suggestion time taken 0.006935 iter 13 next_points [{'hidden_layer_sizes': 142, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 3.7365674270701548, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.45142763005532494}]
function_evaluation time 0.523902 value -0.936675 suggestion {'hidden_layer_sizes': 142, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.026929203452127282, 'epsilon': 9.990317146052187e-07, 'beta_2': 0.9548149603333771, 'alpha': 3.7365674270701548, 'beta_1': 0.8557095260432277, 'validation_fraction': 0.45142763005532494}
observation time 0.001846, current best -0.955468 at iter 13
suggestion time taken 0.007223 iter 14 next_points [{'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.0427105158081617, 'epsilon': 9.55756212090402e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.791324132226812, 'beta_1': 0.8999927716704987, 'validation_fraction': 0.20351334182579184}]
function_evaluation time 0.653571 value -0.935286 suggestion {'hidden_layer_sizes': 135, 'batch_size': 59, 'tol': 0.09272124622185156, 'learning_rate_init': 0.0427105158081617, 'epsilon': 9.55756212090402e-07, 'beta_2': 0.9548149603333771, 'alpha': 0.791324132226812, 'beta_1': 0.8999927716704987, 'validation_fraction': 0.20351334182579184}
observation time 0.001811, current best -0.955468 at iter 14
saving meta data: {'args': {'--uuid': '461881ce930c59c19293a433eee5bc25', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
