running: {'--uuid': '65916867f2875621babada651f44ea75', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 65916867f2875621babada651f44ea75 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002335 iter 0 next_points [{'alpha': 2.3091551480190873, 'batch_size': 134, 'beta_1': 0.9258943037141758, 'beta_2': 0.9876629909765213, 'epsilon': 1.7893873398752225e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 9.172189688390613e-05, 'tol': 0.050116892176799745, 'validation_fraction': 0.1271002265384736}]
function_evaluation time 0.373884 value -0.222631 suggestion {'alpha': 2.3091551480190873, 'batch_size': 134, 'beta_1': 0.9258943037141758, 'beta_2': 0.9876629909765213, 'epsilon': 1.7893873398752225e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 9.172189688390613e-05, 'tol': 0.050116892176799745, 'validation_fraction': 0.1271002265384736}
observation time 0.000064, current best -0.222631 at iter 0
suggestion time taken 0.002317 iter 1 next_points [{'alpha': 8.567030284841883e-05, 'batch_size': 245, 'beta_1': 0.5975852432904208, 'beta_2': 0.9255559587153998, 'epsilon': 4.442511597771901e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.004071986352220648, 'tol': 1.398204154603324e-05, 'validation_fraction': 0.15359357620248779}]
function_evaluation time 0.928722 value -0.971467 suggestion {'alpha': 8.567030284841883e-05, 'batch_size': 245, 'beta_1': 0.5975852432904208, 'beta_2': 0.9255559587153998, 'epsilon': 4.442511597771901e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.004071986352220648, 'tol': 1.398204154603324e-05, 'validation_fraction': 0.15359357620248779}
observation time 0.000068, current best -0.971467 at iter 1
suggestion time taken 0.002107 iter 2 next_points [{'alpha': 3.7234929475002054e-05, 'batch_size': 110, 'beta_1': 0.9122012592993496, 'beta_2': 0.985279823554935, 'epsilon': 3.6140359240721685e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00887699357862596, 'tol': 0.0011497193128103855, 'validation_fraction': 0.2058551014297035}]
function_evaluation time 0.802814 value -0.962423 suggestion {'alpha': 3.7234929475002054e-05, 'batch_size': 110, 'beta_1': 0.9122012592993496, 'beta_2': 0.985279823554935, 'epsilon': 3.6140359240721685e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00887699357862596, 'tol': 0.0011497193128103855, 'validation_fraction': 0.2058551014297035}
observation time 0.000064, current best -0.971467 at iter 2
suggestion time taken 0.002063 iter 3 next_points [{'alpha': 0.00010800064996122248, 'batch_size': 46, 'beta_1': 0.7326068849448553, 'beta_2': 0.9261863686605436, 'epsilon': 7.77712475350016e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.05950722526935225, 'tol': 0.00038991919558962524, 'validation_fraction': 0.2659921180063158}]
function_evaluation time 1.766107 value -0.927635 suggestion {'alpha': 0.00010800064996122248, 'batch_size': 46, 'beta_1': 0.7326068849448553, 'beta_2': 0.9261863686605436, 'epsilon': 7.77712475350016e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.05950722526935225, 'tol': 0.00038991919558962524, 'validation_fraction': 0.2659921180063158}
observation time 0.000066, current best -0.971467 at iter 3
suggestion time taken 0.002317 iter 4 next_points [{'alpha': 0.042282774220226305, 'batch_size': 139, 'beta_1': 0.6708181955033445, 'beta_2': 0.979212831555608, 'epsilon': 3.8406563452590864e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.002781282116555495, 'tol': 4.097099986961257e-05, 'validation_fraction': 0.3334008260020948}]
function_evaluation time 1.353066 value -0.964516 suggestion {'alpha': 0.042282774220226305, 'batch_size': 139, 'beta_1': 0.6708181955033445, 'beta_2': 0.979212831555608, 'epsilon': 3.8406563452590864e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.002781282116555495, 'tol': 4.097099986961257e-05, 'validation_fraction': 0.3334008260020948}
observation time 0.000064, current best -0.971467 at iter 4
suggestion time taken 0.002084 iter 5 next_points [{'alpha': 0.002540067044586378, 'batch_size': 52, 'beta_1': 0.6311113880964017, 'beta_2': 0.9711318665320062, 'epsilon': 2.603238648948017e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.009344665676803256, 'tol': 0.08268101681874733, 'validation_fraction': 0.1748736494875804}]
function_evaluation time 0.820234 value -0.961738 suggestion {'alpha': 0.002540067044586378, 'batch_size': 52, 'beta_1': 0.6311113880964017, 'beta_2': 0.9711318665320062, 'epsilon': 2.603238648948017e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.009344665676803256, 'tol': 0.08268101681874733, 'validation_fraction': 0.1748736494875804}
observation time 0.000070, current best -0.971467 at iter 5
suggestion time taken 0.002111 iter 6 next_points [{'alpha': 0.009760514222814515, 'batch_size': 195, 'beta_1': 0.9844757492445692, 'beta_2': 0.916380603991138, 'epsilon': 3.691129790675719e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0012226639944518908, 'tol': 0.0008111033961539101, 'validation_fraction': 0.12055109677050105}]
function_evaluation time 1.277434 value -0.951991 suggestion {'alpha': 0.009760514222814515, 'batch_size': 195, 'beta_1': 0.9844757492445692, 'beta_2': 0.916380603991138, 'epsilon': 3.691129790675719e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0012226639944518908, 'tol': 0.0008111033961539101, 'validation_fraction': 0.12055109677050105}
observation time 0.000071, current best -0.971467 at iter 6
suggestion time taken 0.002177 iter 7 next_points [{'alpha': 2.6152537869598804, 'batch_size': 44, 'beta_1': 0.6167765134256745, 'beta_2': 0.9723910288940406, 'epsilon': 4.3815486960648456e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00023788895024247424, 'tol': 0.00018139306301351757, 'validation_fraction': 0.17435768235190782}]
function_evaluation time 2.835913 value -0.962415 suggestion {'alpha': 2.6152537869598804, 'batch_size': 44, 'beta_1': 0.6167765134256745, 'beta_2': 0.9723910288940406, 'epsilon': 4.3815486960648456e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00023788895024247424, 'tol': 0.00018139306301351757, 'validation_fraction': 0.17435768235190782}
observation time 0.000067, current best -0.971467 at iter 7
suggestion time taken 0.002095 iter 8 next_points [{'alpha': 0.0014217091321709783, 'batch_size': 72, 'beta_1': 0.735962156516636, 'beta_2': 0.9294595724696411, 'epsilon': 8.711194728815547e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00012457604370810554, 'tol': 5.756976729782918e-05, 'validation_fraction': 0.6628302128018467}]
function_evaluation time 3.548464 value -0.945015 suggestion {'alpha': 0.0014217091321709783, 'batch_size': 72, 'beta_1': 0.735962156516636, 'beta_2': 0.9294595724696411, 'epsilon': 8.711194728815547e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00012457604370810554, 'tol': 5.756976729782918e-05, 'validation_fraction': 0.6628302128018467}
observation time 0.000070, current best -0.971467 at iter 8
suggestion time taken 0.002114 iter 9 next_points [{'alpha': 0.899153113892907, 'batch_size': 227, 'beta_1': 0.6674578087884703, 'beta_2': 0.9731894633043443, 'epsilon': 5.58206931584204e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.03052916355950026, 'tol': 3.279403498389916e-05, 'validation_fraction': 0.26903390631319823}]
function_evaluation time 0.673509 value -0.965902 suggestion {'alpha': 0.899153113892907, 'batch_size': 227, 'beta_1': 0.6674578087884703, 'beta_2': 0.9731894633043443, 'epsilon': 5.58206931584204e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.03052916355950026, 'tol': 3.279403498389916e-05, 'validation_fraction': 0.26903390631319823}
observation time 0.000069, current best -0.971467 at iter 9
suggestion time taken 0.002400 iter 10 next_points [{'alpha': 7.522748498671232e-05, 'batch_size': 62, 'beta_1': 0.7909329693785463, 'beta_2': 0.901609129366702, 'epsilon': 1.6901315087034605e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.08598994932955395, 'tol': 4.7999578651789556e-05, 'validation_fraction': 0.8603727376395328}]
function_evaluation time 0.532755 value -0.582508 suggestion {'alpha': 7.522748498671232e-05, 'batch_size': 62, 'beta_1': 0.7909329693785463, 'beta_2': 0.901609129366702, 'epsilon': 1.6901315087034605e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.08598994932955395, 'tol': 4.7999578651789556e-05, 'validation_fraction': 0.8603727376395328}
observation time 0.000069, current best -0.971467 at iter 10
suggestion time taken 0.002103 iter 11 next_points [{'alpha': 6.654595171919967e-05, 'batch_size': 109, 'beta_1': 0.8147899292652977, 'beta_2': 0.9414493472194106, 'epsilon': 1.9644366814989327e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.07636261252143596, 'tol': 0.000533855854610392, 'validation_fraction': 0.4354660100500799}]
function_evaluation time 0.973317 value -0.558769 suggestion {'alpha': 6.654595171919967e-05, 'batch_size': 109, 'beta_1': 0.8147899292652977, 'beta_2': 0.9414493472194106, 'epsilon': 1.9644366814989327e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.07636261252143596, 'tol': 0.000533855854610392, 'validation_fraction': 0.4354660100500799}
observation time 0.000073, current best -0.971467 at iter 11
suggestion time taken 0.002134 iter 12 next_points [{'alpha': 0.2784668912080139, 'batch_size': 52, 'beta_1': 0.8050815563936637, 'beta_2': 0.9725018093375121, 'epsilon': 3.737291071167078e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 4.1652276063002685e-05, 'tol': 2.3395225670861476e-05, 'validation_fraction': 0.4072759669666806}]
function_evaluation time 6.542263 value -0.933198 suggestion {'alpha': 0.2784668912080139, 'batch_size': 52, 'beta_1': 0.8050815563936637, 'beta_2': 0.9725018093375121, 'epsilon': 3.737291071167078e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 4.1652276063002685e-05, 'tol': 2.3395225670861476e-05, 'validation_fraction': 0.4072759669666806}
observation time 0.000067, current best -0.971467 at iter 12
suggestion time taken 0.002172 iter 13 next_points [{'alpha': 0.0012769510568105633, 'batch_size': 68, 'beta_1': 0.8571216477561944, 'beta_2': 0.9454095130197593, 'epsilon': 1.0786400980503726e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 6.24548726725596e-05, 'tol': 1.8166343159602434e-05, 'validation_fraction': 0.5338696377193373}]
function_evaluation time 4.673734 value -0.903980 suggestion {'alpha': 0.0012769510568105633, 'batch_size': 68, 'beta_1': 0.8571216477561944, 'beta_2': 0.9454095130197593, 'epsilon': 1.0786400980503726e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 6.24548726725596e-05, 'tol': 1.8166343159602434e-05, 'validation_fraction': 0.5338696377193373}
observation time 0.000071, current best -0.971467 at iter 13
suggestion time taken 0.002062 iter 14 next_points [{'alpha': 9.56353276474899e-05, 'batch_size': 102, 'beta_1': 0.5641632443963878, 'beta_2': 0.9451467326673908, 'epsilon': 1.868257342565013e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0024669574873892788, 'tol': 0.01477123093913631, 'validation_fraction': 0.17296921916953573}]
function_evaluation time 0.727849 value -0.963816 suggestion {'alpha': 9.56353276474899e-05, 'batch_size': 102, 'beta_1': 0.5641632443963878, 'beta_2': 0.9451467326673908, 'epsilon': 1.868257342565013e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0024669574873892788, 'tol': 0.01477123093913631, 'validation_fraction': 0.17296921916953573}
observation time 0.000070, current best -0.971467 at iter 14
saving meta data: {'args': {'--uuid': '65916867f2875621babada651f44ea75', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
