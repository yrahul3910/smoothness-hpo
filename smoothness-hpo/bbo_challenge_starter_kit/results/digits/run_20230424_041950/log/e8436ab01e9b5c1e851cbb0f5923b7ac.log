running: {'--uuid': 'e8436ab01e9b5c1e851cbb0f5923b7ac', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u e8436ab01e9b5c1e851cbb0f5923b7ac -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002394 iter 0 next_points [{'alpha': 0.019375637156401476, 'batch_size': 135, 'beta_1': 0.727155943171541, 'beta_2': 0.9037192607584643, 'epsilon': 1.3684910075814603e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 3.258344332009833e-05, 'tol': 0.01589654124427332, 'validation_fraction': 0.14804310027486667}]
function_evaluation time 1.455251 value -0.438840 suggestion {'alpha': 0.019375637156401476, 'batch_size': 135, 'beta_1': 0.727155943171541, 'beta_2': 0.9037192607584643, 'epsilon': 1.3684910075814603e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 3.258344332009833e-05, 'tol': 0.01589654124427332, 'validation_fraction': 0.14804310027486667}
observation time 0.000067, current best -0.438840 at iter 0
suggestion time taken 0.002371 iter 1 next_points [{'alpha': 0.0004078156660942235, 'batch_size': 185, 'beta_1': 0.7464166604154845, 'beta_2': 0.9678987606924997, 'epsilon': 2.056256537858798e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.00010452661440921197, 'tol': 7.576350397330252e-05, 'validation_fraction': 0.12818956640272952}]
function_evaluation time 2.894041 value -0.926936 suggestion {'alpha': 0.0004078156660942235, 'batch_size': 185, 'beta_1': 0.7464166604154845, 'beta_2': 0.9678987606924997, 'epsilon': 2.056256537858798e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.00010452661440921197, 'tol': 7.576350397330252e-05, 'validation_fraction': 0.12818956640272952}
observation time 0.000067, current best -0.926936 at iter 1
suggestion time taken 0.002126 iter 2 next_points [{'alpha': 5.468499406951428, 'batch_size': 161, 'beta_1': 0.5209035770765663, 'beta_2': 0.9578336082124597, 'epsilon': 3.389095245388912e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 5.629450931218917e-05, 'tol': 0.0002074712178696747, 'validation_fraction': 0.6855157195501368}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.462986 value -0.835784 suggestion {'alpha': 5.468499406951428, 'batch_size': 161, 'beta_1': 0.5209035770765663, 'beta_2': 0.9578336082124597, 'epsilon': 3.389095245388912e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 5.629450931218917e-05, 'tol': 0.0002074712178696747, 'validation_fraction': 0.6855157195501368}
observation time 0.000064, current best -0.926936 at iter 2
suggestion time taken 0.002125 iter 3 next_points [{'alpha': 0.006338228371403662, 'batch_size': 137, 'beta_1': 0.8157698797016857, 'beta_2': 0.9078771981939491, 'epsilon': 6.547276195106053e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00022480918909185743, 'tol': 0.0026252490090932223, 'validation_fraction': 0.16591431166856044}]
function_evaluation time 1.971171 value -0.947832 suggestion {'alpha': 0.006338228371403662, 'batch_size': 137, 'beta_1': 0.8157698797016857, 'beta_2': 0.9078771981939491, 'epsilon': 6.547276195106053e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00022480918909185743, 'tol': 0.0026252490090932223, 'validation_fraction': 0.16591431166856044}
observation time 0.000071, current best -0.947832 at iter 3
suggestion time taken 0.002132 iter 4 next_points [{'alpha': 0.00016346215618286784, 'batch_size': 149, 'beta_1': 0.5134011349233946, 'beta_2': 0.907200145644565, 'epsilon': 5.785461622401353e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0014235885057104407, 'tol': 0.00030867969667192665, 'validation_fraction': 0.11070328252081474}]
function_evaluation time 0.669053 value -0.940861 suggestion {'alpha': 0.00016346215618286784, 'batch_size': 149, 'beta_1': 0.5134011349233946, 'beta_2': 0.907200145644565, 'epsilon': 5.785461622401353e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0014235885057104407, 'tol': 0.00030867969667192665, 'validation_fraction': 0.11070328252081474}
observation time 0.000072, current best -0.947832 at iter 4
suggestion time taken 0.002152 iter 5 next_points [{'alpha': 0.052175723988421394, 'batch_size': 86, 'beta_1': 0.6703791835989987, 'beta_2': 0.9099855426880332, 'epsilon': 1.856567434614944e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.030820661600130608, 'tol': 7.335330414130258e-05, 'validation_fraction': 0.10973100517447222}]
function_evaluation time 0.914631 value -0.952671 suggestion {'alpha': 0.052175723988421394, 'batch_size': 86, 'beta_1': 0.6703791835989987, 'beta_2': 0.9099855426880332, 'epsilon': 1.856567434614944e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.030820661600130608, 'tol': 7.335330414130258e-05, 'validation_fraction': 0.10973100517447222}
observation time 0.000070, current best -0.952671 at iter 5
suggestion time taken 0.002147 iter 6 next_points [{'alpha': 5.999913738719445e-05, 'batch_size': 108, 'beta_1': 0.644916576216797, 'beta_2': 0.991447010085438, 'epsilon': 3.234199354127324e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.001543329002120173, 'tol': 1.2971684117794703e-05, 'validation_fraction': 0.2736741306465073}]
function_evaluation time 1.292541 value -0.956855 suggestion {'alpha': 5.999913738719445e-05, 'batch_size': 108, 'beta_1': 0.644916576216797, 'beta_2': 0.991447010085438, 'epsilon': 3.234199354127324e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.001543329002120173, 'tol': 1.2971684117794703e-05, 'validation_fraction': 0.2736741306465073}
observation time 0.000071, current best -0.956855 at iter 6
suggestion time taken 0.002194 iter 7 next_points [{'alpha': 0.15935946159693695, 'batch_size': 151, 'beta_1': 0.6895412038132127, 'beta_2': 0.9085450528727878, 'epsilon': 8.569865507201074e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.003706378727720294, 'tol': 0.001859490439324068, 'validation_fraction': 0.10940978598307899}]
function_evaluation time 1.073008 value -0.975639 suggestion {'alpha': 0.15935946159693695, 'batch_size': 151, 'beta_1': 0.6895412038132127, 'beta_2': 0.9085450528727878, 'epsilon': 8.569865507201074e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.003706378727720294, 'tol': 0.001859490439324068, 'validation_fraction': 0.10940978598307899}
observation time 0.000078, current best -0.975639 at iter 7
suggestion time taken 0.002337 iter 8 next_points [{'alpha': 5.760540867026933e-05, 'batch_size': 221, 'beta_1': 0.7827052164895448, 'beta_2': 0.90906058874661, 'epsilon': 1.0184890413357097e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.007466721856871887, 'tol': 0.023344323803750268, 'validation_fraction': 0.4248321849348338}]
function_evaluation time 0.311589 value -0.946412 suggestion {'alpha': 5.760540867026933e-05, 'batch_size': 221, 'beta_1': 0.7827052164895448, 'beta_2': 0.90906058874661, 'epsilon': 1.0184890413357097e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.007466721856871887, 'tol': 0.023344323803750268, 'validation_fraction': 0.4248321849348338}
observation time 0.000067, current best -0.975639 at iter 8
suggestion time taken 0.002337 iter 9 next_points [{'alpha': 0.0004202165879948356, 'batch_size': 249, 'beta_1': 0.7204774915178909, 'beta_2': 0.9378074923932056, 'epsilon': 1.9935771567054705e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0015273379667034696, 'tol': 8.288136884243462e-05, 'validation_fraction': 0.13119211553524626}]
function_evaluation time 1.144714 value -0.954769 suggestion {'alpha': 0.0004202165879948356, 'batch_size': 249, 'beta_1': 0.7204774915178909, 'beta_2': 0.9378074923932056, 'epsilon': 1.9935771567054705e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0015273379667034696, 'tol': 8.288136884243462e-05, 'validation_fraction': 0.13119211553524626}
observation time 0.000074, current best -0.975639 at iter 9
suggestion time taken 0.002129 iter 10 next_points [{'alpha': 0.00011981114378485598, 'batch_size': 51, 'beta_1': 0.7622053689731828, 'beta_2': 0.9150230457139474, 'epsilon': 3.256097093257182e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00017864416239847354, 'tol': 0.01333448307726493, 'validation_fraction': 0.18929973401523909}]
function_evaluation time 1.241132 value -0.908142 suggestion {'alpha': 0.00011981114378485598, 'batch_size': 51, 'beta_1': 0.7622053689731828, 'beta_2': 0.9150230457139474, 'epsilon': 3.256097093257182e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00017864416239847354, 'tol': 0.01333448307726493, 'validation_fraction': 0.18929973401523909}
observation time 0.000070, current best -0.975639 at iter 10
suggestion time taken 0.002328 iter 11 next_points [{'alpha': 0.08497038527398473, 'batch_size': 19, 'beta_1': 0.904568379203224, 'beta_2': 0.9140605808095796, 'epsilon': 1.833449030927897e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.015538377569601301, 'tol': 0.051743040502463214, 'validation_fraction': 0.7118769743092827}]
function_evaluation time 0.471804 value -0.920659 suggestion {'alpha': 0.08497038527398473, 'batch_size': 19, 'beta_1': 0.904568379203224, 'beta_2': 0.9140605808095796, 'epsilon': 1.833449030927897e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.015538377569601301, 'tol': 0.051743040502463214, 'validation_fraction': 0.7118769743092827}
observation time 0.000071, current best -0.975639 at iter 11
suggestion time taken 0.002117 iter 12 next_points [{'alpha': 4.1095837926513405e-05, 'batch_size': 169, 'beta_1': 0.5416300205857031, 'beta_2': 0.9497296149042235, 'epsilon': 3.97187154566003e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 5.7563936539146254e-05, 'tol': 0.002338798367345664, 'validation_fraction': 0.22642408452484702}]
function_evaluation time 3.639128 value -0.733251 suggestion {'alpha': 4.1095837926513405e-05, 'batch_size': 169, 'beta_1': 0.5416300205857031, 'beta_2': 0.9497296149042235, 'epsilon': 3.97187154566003e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 5.7563936539146254e-05, 'tol': 0.002338798367345664, 'validation_fraction': 0.22642408452484702}
observation time 0.000077, current best -0.975639 at iter 12
suggestion time taken 0.002172 iter 13 next_points [{'alpha': 3.905858079466024e-05, 'batch_size': 60, 'beta_1': 0.8824500275436646, 'beta_2': 0.984373719738011, 'epsilon': 2.783832181272216e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.004668148099553104, 'tol': 0.004205341076518051, 'validation_fraction': 0.19891058552334456}]
function_evaluation time 1.188919 value -0.972169 suggestion {'alpha': 3.905858079466024e-05, 'batch_size': 60, 'beta_1': 0.8824500275436646, 'beta_2': 0.984373719738011, 'epsilon': 2.783832181272216e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.004668148099553104, 'tol': 0.004205341076518051, 'validation_fraction': 0.19891058552334456}
observation time 0.000074, current best -0.975639 at iter 13
suggestion time taken 0.002101 iter 14 next_points [{'alpha': 2.541556779488806e-05, 'batch_size': 187, 'beta_1': 0.5403062530336711, 'beta_2': 0.9115628276990071, 'epsilon': 4.796357600381561e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 3.8018011065790734e-05, 'tol': 0.0002573929439741071, 'validation_fraction': 0.1794910951664937}]
function_evaluation time 3.700807 value -0.570783 suggestion {'alpha': 2.541556779488806e-05, 'batch_size': 187, 'beta_1': 0.5403062530336711, 'beta_2': 0.9115628276990071, 'epsilon': 4.796357600381561e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 3.8018011065790734e-05, 'tol': 0.0002573929439741071, 'validation_fraction': 0.1794910951664937}
observation time 0.000069, current best -0.975639 at iter 14
saving meta data: {'args': {'--uuid': 'e8436ab01e9b5c1e851cbb0f5923b7ac', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
