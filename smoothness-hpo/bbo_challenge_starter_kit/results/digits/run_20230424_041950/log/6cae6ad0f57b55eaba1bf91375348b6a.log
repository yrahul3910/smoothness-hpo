running: {'--uuid': '6cae6ad0f57b55eaba1bf91375348b6a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 6cae6ad0f57b55eaba1bf91375348b6a -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002425 iter 0 next_points [{'alpha': 0.9262351241318817, 'batch_size': 199, 'beta_1': 0.7659238762427787, 'beta_2': 0.9792292191710242, 'epsilon': 7.495572397501393e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.863763829561806e-05, 'tol': 0.0008354064953594047, 'validation_fraction': 0.548177494945793}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.226147 value -0.404351 suggestion {'alpha': 0.9262351241318817, 'batch_size': 199, 'beta_1': 0.7659238762427787, 'beta_2': 0.9792292191710242, 'epsilon': 7.495572397501393e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.863763829561806e-05, 'tol': 0.0008354064953594047, 'validation_fraction': 0.548177494945793}
observation time 0.000065, current best -0.404351 at iter 0
suggestion time taken 0.002379 iter 1 next_points [{'alpha': 0.7650357871351977, 'batch_size': 55, 'beta_1': 0.5180993940161329, 'beta_2': 0.9428857545013345, 'epsilon': 1.0779761999004988e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0030686414867215025, 'tol': 0.010895691102647884, 'validation_fraction': 0.4887368985031303}]
function_evaluation time 0.863073 value -0.961745 suggestion {'alpha': 0.7650357871351977, 'batch_size': 55, 'beta_1': 0.5180993940161329, 'beta_2': 0.9428857545013345, 'epsilon': 1.0779761999004988e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0030686414867215025, 'tol': 0.010895691102647884, 'validation_fraction': 0.4887368985031303}
observation time 0.000065, current best -0.961745 at iter 1
suggestion time taken 0.002105 iter 2 next_points [{'alpha': 0.11960457083262348, 'batch_size': 245, 'beta_1': 0.657153692824678, 'beta_2': 0.9829757302836628, 'epsilon': 1.5488496649927744e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.02583910913295332, 'tol': 0.04822744296654752, 'validation_fraction': 0.7006267055732538}]
function_evaluation time 0.261243 value -0.912996 suggestion {'alpha': 0.11960457083262348, 'batch_size': 245, 'beta_1': 0.657153692824678, 'beta_2': 0.9829757302836628, 'epsilon': 1.5488496649927744e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.02583910913295332, 'tol': 0.04822744296654752, 'validation_fraction': 0.7006267055732538}
observation time 0.000063, current best -0.961745 at iter 2
suggestion time taken 0.002128 iter 3 next_points [{'alpha': 0.19034555703789702, 'batch_size': 68, 'beta_1': 0.7375366924701703, 'beta_2': 0.9503784208543145, 'epsilon': 5.7405855156192486e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0009423057337954557, 'tol': 2.2496386696559332e-05, 'validation_fraction': 0.14066159558710273}]
function_evaluation time 1.734530 value -0.967289 suggestion {'alpha': 0.19034555703789702, 'batch_size': 68, 'beta_1': 0.7375366924701703, 'beta_2': 0.9503784208543145, 'epsilon': 5.7405855156192486e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0009423057337954557, 'tol': 2.2496386696559332e-05, 'validation_fraction': 0.14066159558710273}
observation time 0.000070, current best -0.967289 at iter 3
suggestion time taken 0.002343 iter 4 next_points [{'alpha': 0.00010326722094639742, 'batch_size': 56, 'beta_1': 0.5083177465968047, 'beta_2': 0.959286170980056, 'epsilon': 1.6893080562962044e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.001141580412033565, 'tol': 0.00031208408533485595, 'validation_fraction': 0.14423922292312374}]
function_evaluation time 1.995996 value -0.970780 suggestion {'alpha': 0.00010326722094639742, 'batch_size': 56, 'beta_1': 0.5083177465968047, 'beta_2': 0.959286170980056, 'epsilon': 1.6893080562962044e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.001141580412033565, 'tol': 0.00031208408533485595, 'validation_fraction': 0.14423922292312374}
observation time 0.000075, current best -0.970780 at iter 4
suggestion time taken 0.002145 iter 5 next_points [{'alpha': 0.0010057434816014208, 'batch_size': 107, 'beta_1': 0.7929151018613421, 'beta_2': 0.9437914733535047, 'epsilon': 1.5983015945522977e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00010392105914558566, 'tol': 0.0007894853301507917, 'validation_fraction': 0.16651563069204642}]
function_evaluation time 2.410573 value -0.930425 suggestion {'alpha': 0.0010057434816014208, 'batch_size': 107, 'beta_1': 0.7929151018613421, 'beta_2': 0.9437914733535047, 'epsilon': 1.5983015945522977e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00010392105914558566, 'tol': 0.0007894853301507917, 'validation_fraction': 0.16651563069204642}
observation time 0.000068, current best -0.970780 at iter 5
suggestion time taken 0.002139 iter 6 next_points [{'alpha': 0.04050453766678821, 'batch_size': 124, 'beta_1': 0.8797184458688864, 'beta_2': 0.9400986811315198, 'epsilon': 4.181665563525124e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.071894169573889, 'tol': 0.00013244563036437582, 'validation_fraction': 0.1589649053850886}]
function_evaluation time 1.502892 value -0.939462 suggestion {'alpha': 0.04050453766678821, 'batch_size': 124, 'beta_1': 0.8797184458688864, 'beta_2': 0.9400986811315198, 'epsilon': 4.181665563525124e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.071894169573889, 'tol': 0.00013244563036437582, 'validation_fraction': 0.1589649053850886}
observation time 0.000072, current best -0.970780 at iter 6
suggestion time taken 0.002189 iter 7 next_points [{'alpha': 6.954002858858784e-05, 'batch_size': 165, 'beta_1': 0.6109944339131377, 'beta_2': 0.9633800709689386, 'epsilon': 1.66545109444659e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.020974279208286914, 'tol': 1.2134998862717102e-05, 'validation_fraction': 0.16883215914646785}]
function_evaluation time 0.664131 value -0.956855 suggestion {'alpha': 6.954002858858784e-05, 'batch_size': 165, 'beta_1': 0.6109944339131377, 'beta_2': 0.9633800709689386, 'epsilon': 1.66545109444659e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.020974279208286914, 'tol': 1.2134998862717102e-05, 'validation_fraction': 0.16883215914646785}
observation time 0.000072, current best -0.970780 at iter 7
suggestion time taken 0.002151 iter 8 next_points [{'alpha': 2.3874147854281746, 'batch_size': 97, 'beta_1': 0.9542497006437817, 'beta_2': 0.9637692974361195, 'epsilon': 5.43182385802402e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.011168561756377527, 'tol': 0.009434123011213127, 'validation_fraction': 0.10682403666781405}]
function_evaluation time 0.733211 value -0.957569 suggestion {'alpha': 2.3874147854281746, 'batch_size': 97, 'beta_1': 0.9542497006437817, 'beta_2': 0.9637692974361195, 'epsilon': 5.43182385802402e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.011168561756377527, 'tol': 0.009434123011213127, 'validation_fraction': 0.10682403666781405}
observation time 0.000073, current best -0.970780 at iter 8
suggestion time taken 0.002136 iter 9 next_points [{'alpha': 0.008241262092083732, 'batch_size': 179, 'beta_1': 0.8067690810822105, 'beta_2': 0.9925326118358818, 'epsilon': 3.0910967451538734e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.011663396017910839, 'tol': 1.0565611697273574e-05, 'validation_fraction': 0.6519913255328078}]
function_evaluation time 0.869896 value -0.949214 suggestion {'alpha': 0.008241262092083732, 'batch_size': 179, 'beta_1': 0.8067690810822105, 'beta_2': 0.9925326118358818, 'epsilon': 3.0910967451538734e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.011663396017910839, 'tol': 1.0565611697273574e-05, 'validation_fraction': 0.6519913255328078}
observation time 0.000079, current best -0.970780 at iter 9
suggestion time taken 0.002151 iter 10 next_points [{'alpha': 2.05349852549133, 'batch_size': 164, 'beta_1': 0.5188320087240829, 'beta_2': 0.9852467638582387, 'epsilon': 1.0892397211827715e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.09916729859470624, 'tol': 0.000918370190643729, 'validation_fraction': 0.1283517205128194}]
function_evaluation time 0.423369 value -0.288768 suggestion {'alpha': 2.05349852549133, 'batch_size': 164, 'beta_1': 0.5188320087240829, 'beta_2': 0.9852467638582387, 'epsilon': 1.0892397211827715e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.09916729859470624, 'tol': 0.000918370190643729, 'validation_fraction': 0.1283517205128194}
observation time 0.000071, current best -0.970780 at iter 10
suggestion time taken 0.002152 iter 11 next_points [{'alpha': 0.002519245987948747, 'batch_size': 162, 'beta_1': 0.5843941762755613, 'beta_2': 0.9967062840569114, 'epsilon': 1.0174027882299836e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 7.861463603045407e-05, 'tol': 0.0059709029517375535, 'validation_fraction': 0.20679355416378709}]
function_evaluation time 2.376462 value -0.853891 suggestion {'alpha': 0.002519245987948747, 'batch_size': 162, 'beta_1': 0.5843941762755613, 'beta_2': 0.9967062840569114, 'epsilon': 1.0174027882299836e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 7.861463603045407e-05, 'tol': 0.0059709029517375535, 'validation_fraction': 0.20679355416378709}
observation time 0.000073, current best -0.970780 at iter 11
suggestion time taken 0.002211 iter 12 next_points [{'alpha': 0.4792706634053115, 'batch_size': 13, 'beta_1': 0.8553915766219014, 'beta_2': 0.9112176508450986, 'epsilon': 3.3244983987528285e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.008597729399081674, 'tol': 0.0036998255357016206, 'validation_fraction': 0.8165851350083854}]
function_evaluation time 1.096554 value -0.910964 suggestion {'alpha': 0.4792706634053115, 'batch_size': 13, 'beta_1': 0.8553915766219014, 'beta_2': 0.9112176508450986, 'epsilon': 3.3244983987528285e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.008597729399081674, 'tol': 0.0036998255357016206, 'validation_fraction': 0.8165851350083854}
observation time 0.000073, current best -0.970780 at iter 12
suggestion time taken 0.002193 iter 13 next_points [{'alpha': 0.0025719816328943572, 'batch_size': 52, 'beta_1': 0.5800436853806705, 'beta_2': 0.9301416160770318, 'epsilon': 3.5421465947755226e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.011719575563241512, 'tol': 0.022887330880984096, 'validation_fraction': 0.43489446973521567}]
function_evaluation time 0.775791 value -0.967296 suggestion {'alpha': 0.0025719816328943572, 'batch_size': 52, 'beta_1': 0.5800436853806705, 'beta_2': 0.9301416160770318, 'epsilon': 3.5421465947755226e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.011719575563241512, 'tol': 0.022887330880984096, 'validation_fraction': 0.43489446973521567}
observation time 0.000072, current best -0.970780 at iter 13
suggestion time taken 0.002149 iter 14 next_points [{'alpha': 0.000330042567553063, 'batch_size': 135, 'beta_1': 0.7723982582975686, 'beta_2': 0.9763657873008521, 'epsilon': 7.077038034812215e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00011593161067699904, 'tol': 0.07533558376726975, 'validation_fraction': 0.4536316381737227}]
function_evaluation time 0.332943 value -0.255360 suggestion {'alpha': 0.000330042567553063, 'batch_size': 135, 'beta_1': 0.7723982582975686, 'beta_2': 0.9763657873008521, 'epsilon': 7.077038034812215e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00011593161067699904, 'tol': 0.07533558376726975, 'validation_fraction': 0.4536316381737227}
observation time 0.000077, current best -0.970780 at iter 14
saving meta data: {'args': {'--uuid': '6cae6ad0f57b55eaba1bf91375348b6a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
