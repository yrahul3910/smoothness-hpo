running: {'--uuid': 'b51e59a3f09053ea9705d50a6de57c55', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d digits -o opentuner -u b51e59a3f09053ea9705d50a6de57c55 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study opentuner MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.016972 iter 0 next_points [{'hidden_layer_sizes': 88, 'alpha': 5.366062465764372, 'batch_size': 149, 'learning_rate_init': 0.039326243006097376, 'tol': 0.036574785301687944, 'validation_fraction': 0.7075803365067709, 'beta_1': 0.9312874057569918, 'beta_2': 0.9894488997729473, 'epsilon': 8.498998564093464e-07}]
function_evaluation time 0.324904 value 0.246344 suggestion {'hidden_layer_sizes': 88, 'alpha': 5.366062465764372, 'batch_size': 149, 'learning_rate_init': 0.039326243006097376, 'tol': 0.036574785301687944, 'validation_fraction': 0.7075803365067709, 'beta_1': 0.9312874057569918, 'beta_2': 0.9894488997729473, 'epsilon': 8.498998564093464e-07}
observation time 0.004595, current best 0.246344 at iter 0
suggestion time taken 0.021461 iter 1 next_points [{'beta_2': 0.9048066682408917, 'epsilon': 7.618751360077548e-07, 'hidden_layer_sizes': 165, 'batch_size': 64, 'tol': 0.09842806385457885, 'beta_1': 0.8052966348654751, 'learning_rate_init': 0.0662182938071189, 'validation_fraction': 0.23722085689903977, 'alpha': 3.55222450278842}]
function_evaluation time 0.694502 value 0.345293 suggestion {'beta_2': 0.9048066682408917, 'epsilon': 7.618751360077548e-07, 'hidden_layer_sizes': 165, 'batch_size': 64, 'tol': 0.09842806385457885, 'beta_1': 0.8052966348654751, 'learning_rate_init': 0.0662182938071189, 'validation_fraction': 0.23722085689903977, 'alpha': 3.55222450278842}
observation time 0.001987, current best 0.246344 at iter 1
suggestion time taken 0.007137 iter 2 next_points [{'hidden_layer_sizes': 88, 'alpha': 5.079023081466736, 'batch_size': 158, 'learning_rate_init': 0.039326243006097376, 'tol': 0.036574785301687944, 'validation_fraction': 0.7075803365067709, 'beta_1': 0.9312874057569918, 'beta_2': 0.9891428760001875, 'epsilon': 9.724643813829583e-07}]
function_evaluation time 0.346914 value 0.300515 suggestion {'hidden_layer_sizes': 88, 'alpha': 5.079023081466736, 'batch_size': 158, 'learning_rate_init': 0.039326243006097376, 'tol': 0.036574785301687944, 'validation_fraction': 0.7075803365067709, 'beta_1': 0.9312874057569918, 'beta_2': 0.9891428760001875, 'epsilon': 9.724643813829583e-07}
observation time 0.001870, current best 0.246344 at iter 2
suggestion time taken 0.046368 iter 3 next_points [{'beta_2': 0.9257355068574707, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.552886940955333, 'hidden_layer_sizes': 142, 'tol': 0.07852533263236931, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}]
function_evaluation time 0.384581 value 0.178598 suggestion {'beta_2': 0.9257355068574707, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.552886940955333, 'hidden_layer_sizes': 142, 'tol': 0.07852533263236931, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}
observation time 0.001984, current best 0.178598 at iter 3
suggestion time taken 0.005112 iter 4 next_points [{'beta_2': 0.9189423437140779, 'beta_1': 0.6093114020213504, 'alpha': 8.230722891546286, 'learning_rate_init': 0.047911149026779114, 'validation_fraction': 0.5509911156112081, 'hidden_layer_sizes': 174, 'tol': 0.09869169474152988, 'epsilon': 8.875281091452459e-07, 'batch_size': 207}]
function_evaluation time 0.386429 value 0.325252 suggestion {'beta_2': 0.9189423437140779, 'beta_1': 0.6093114020213504, 'alpha': 8.230722891546286, 'learning_rate_init': 0.047911149026779114, 'validation_fraction': 0.5509911156112081, 'hidden_layer_sizes': 174, 'tol': 0.09869169474152988, 'epsilon': 8.875281091452459e-07, 'batch_size': 207}
observation time 0.002059, current best 0.178598 at iter 4
suggestion time taken 0.007148 iter 5 next_points [{'beta_2': 0.9257355068574707, 'beta_1': 0.6304448998302081, 'alpha': 2.3412799574552094, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.552886940955333, 'hidden_layer_sizes': 142, 'tol': 0.07852533263236931, 'epsilon': 9.698853683798016e-07, 'batch_size': 23}]
function_evaluation time 0.676255 value 0.325994 suggestion {'beta_2': 0.9257355068574707, 'beta_1': 0.6304448998302081, 'alpha': 2.3412799574552094, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.552886940955333, 'hidden_layer_sizes': 142, 'tol': 0.07852533263236931, 'epsilon': 9.698853683798016e-07, 'batch_size': 23}
observation time 0.001815, current best 0.178598 at iter 5
suggestion time taken 0.005287 iter 6 next_points [{'beta_2': 0.9236725930015902, 'beta_1': 0.7297443661490869, 'alpha': 1.3438333170594765, 'learning_rate_init': 0.028727816325032563, 'validation_fraction': 0.6524515935526918, 'hidden_layer_sizes': 67, 'tol': 0.0007350259152211669, 'epsilon': 4.97131682847789e-07, 'batch_size': 30}]
function_evaluation time 0.708915 value 0.238958 suggestion {'beta_2': 0.9236725930015902, 'beta_1': 0.7297443661490869, 'alpha': 1.3438333170594765, 'learning_rate_init': 0.028727816325032563, 'validation_fraction': 0.6524515935526918, 'hidden_layer_sizes': 67, 'tol': 0.0007350259152211669, 'epsilon': 4.97131682847789e-07, 'batch_size': 30}
observation time 0.001805, current best 0.178598 at iter 6
suggestion time taken 0.006671 iter 7 next_points [{'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.07852533263236931, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}]
function_evaluation time 0.450156 value 0.129830 suggestion {'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.07852533263236931, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}
observation time 0.001857, current best 0.129830 at iter 7
suggestion time taken 0.006930 iter 8 next_points [{'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}]
function_evaluation time 0.493182 value 0.113154 suggestion {'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}
observation time 0.001853, current best 0.113154 at iter 8
suggestion time taken 0.006680 iter 9 next_points [{'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.1742321259640357, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 14}]
function_evaluation time 1.973898 value 0.308573 suggestion {'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.1742321259640357, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 14}
observation time 0.001844, current best 0.113154 at iter 9
suggestion time taken 0.006999 iter 10 next_points [{'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.7038181918144115, 'learning_rate_init': 0.0981871269816003, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}]
function_evaluation time 0.690371 value 0.297957 suggestion {'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.7038181918144115, 'learning_rate_init': 0.0981871269816003, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}
observation time 0.002678, current best 0.113154 at iter 10
suggestion time taken 0.006568 iter 11 next_points [{'beta_2': 0.9379097838753299, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}]
function_evaluation time 0.498752 value 0.138027 suggestion {'beta_2': 0.9379097838753299, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 96}
observation time 0.001852, current best 0.113154 at iter 11
suggestion time taken 0.006711 iter 12 next_points [{'beta_2': 0.9755821983573045, 'beta_1': 0.9095097593588635, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.8717207548160876, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 228}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.327051 value 0.462261 suggestion {'beta_2': 0.9755821983573045, 'beta_1': 0.9095097593588635, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.8717207548160876, 'hidden_layer_sizes': 142, 'tol': 0.03315655089777108, 'epsilon': 9.698853683798016e-07, 'batch_size': 228}
observation time 0.002007, current best 0.113154 at iter 12
suggestion time taken 0.006963 iter 13 next_points [{'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.08715906783787634, 'epsilon': 9.698853683798016e-07, 'batch_size': 161}]
function_evaluation time 0.392651 value 0.132544 suggestion {'beta_2': 0.9755821983573045, 'beta_1': 0.9113216107728423, 'alpha': 2.4475593428479203, 'learning_rate_init': 0.015556724430159919, 'validation_fraction': 0.36146212891685214, 'hidden_layer_sizes': 142, 'tol': 0.08715906783787634, 'epsilon': 9.698853683798016e-07, 'batch_size': 161}
observation time 0.001846, current best 0.113154 at iter 13
suggestion time taken 0.005076 iter 14 next_points [{'beta_2': 0.9651429815719201, 'beta_1': 0.6894511609638033, 'alpha': 2.424208589450323, 'learning_rate_init': 0.027650031577349955, 'validation_fraction': 0.4031109205906701, 'hidden_layer_sizes': 174, 'tol': 0.03482300603172355, 'epsilon': 6.838544285575333e-07, 'batch_size': 135}]
function_evaluation time 0.473923 value 0.213081 suggestion {'beta_2': 0.9651429815719201, 'beta_1': 0.6894511609638033, 'alpha': 2.424208589450323, 'learning_rate_init': 0.027650031577349955, 'validation_fraction': 0.4031109205906701, 'hidden_layer_sizes': 174, 'tol': 0.03482300603172355, 'epsilon': 6.838544285575333e-07, 'batch_size': 135}
observation time 0.001820, current best 0.113154 at iter 14
saving meta data: {'args': {'--uuid': 'b51e59a3f09053ea9705d50a6de57c55', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
