running: {'--uuid': '83915805313b559597f684351aa16768', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 83915805313b559597f684351aa16768 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002354 iter 0 next_points [{'alpha': 0.05405496371389303, 'batch_size': 231, 'beta_1': 0.603647409418241, 'beta_2': 0.9121272354408458, 'epsilon': 1.0408932766560647e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00039014507132937855, 'tol': 0.06989036813701477, 'validation_fraction': 0.7713322463137304}]
function_evaluation time 0.164735 value 6.095814 suggestion {'alpha': 0.05405496371389303, 'batch_size': 231, 'beta_1': 0.603647409418241, 'beta_2': 0.9121272354408458, 'epsilon': 1.0408932766560647e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00039014507132937855, 'tol': 0.06989036813701477, 'validation_fraction': 0.7713322463137304}
observation time 0.000071, current best 6.095814 at iter 0
suggestion time taken 0.002343 iter 1 next_points [{'alpha': 0.4087584335956858, 'batch_size': 24, 'beta_1': 0.543574498099829, 'beta_2': 0.947312298880618, 'epsilon': 6.222561076996351e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.07818195100736197, 'tol': 0.04515136587737709, 'validation_fraction': 0.3345922434946949}]
function_evaluation time 1.034923 value 1.289354 suggestion {'alpha': 0.4087584335956858, 'batch_size': 24, 'beta_1': 0.543574498099829, 'beta_2': 0.947312298880618, 'epsilon': 6.222561076996351e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.07818195100736197, 'tol': 0.04515136587737709, 'validation_fraction': 0.3345922434946949}
observation time 0.000068, current best 1.289354 at iter 1
suggestion time taken 0.002107 iter 2 next_points [{'alpha': 0.0031851374681530343, 'batch_size': 143, 'beta_1': 0.5655361013392306, 'beta_2': 0.9050604521370871, 'epsilon': 5.320791457887498e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.03587321420598592, 'tol': 0.005019276397666472, 'validation_fraction': 0.3980309669275637}]
function_evaluation time 0.622033 value 0.180305 suggestion {'alpha': 0.0031851374681530343, 'batch_size': 143, 'beta_1': 0.5655361013392306, 'beta_2': 0.9050604521370871, 'epsilon': 5.320791457887498e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.03587321420598592, 'tol': 0.005019276397666472, 'validation_fraction': 0.3980309669275637}
observation time 0.000072, current best 0.180305 at iter 2
suggestion time taken 0.002106 iter 3 next_points [{'alpha': 8.992772096383538e-05, 'batch_size': 189, 'beta_1': 0.9606901690364077, 'beta_2': 0.9106895301509865, 'epsilon': 7.788400936513134e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.02656833680760282, 'tol': 0.057794477679716294, 'validation_fraction': 0.3046909870536603}]
function_evaluation time 0.465490 value 0.397406 suggestion {'alpha': 8.992772096383538e-05, 'batch_size': 189, 'beta_1': 0.9606901690364077, 'beta_2': 0.9106895301509865, 'epsilon': 7.788400936513134e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.02656833680760282, 'tol': 0.057794477679716294, 'validation_fraction': 0.3046909870536603}
observation time 0.000074, current best 0.180305 at iter 3
suggestion time taken 0.002101 iter 4 next_points [{'alpha': 4.3262244359746616, 'batch_size': 14, 'beta_1': 0.5002838304070267, 'beta_2': 0.9904717202115667, 'epsilon': 1.2933693098093115e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.007866237604268926, 'tol': 0.00688141771127364, 'validation_fraction': 0.10929653399392485}]
function_evaluation time 4.239985 value 0.524591 suggestion {'alpha': 4.3262244359746616, 'batch_size': 14, 'beta_1': 0.5002838304070267, 'beta_2': 0.9904717202115667, 'epsilon': 1.2933693098093115e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.007866237604268926, 'tol': 0.00688141771127364, 'validation_fraction': 0.10929653399392485}
observation time 0.000068, current best 0.180305 at iter 4
suggestion time taken 0.002349 iter 5 next_points [{'alpha': 0.010313650050879692, 'batch_size': 112, 'beta_1': 0.6571624323363834, 'beta_2': 0.9210857563812529, 'epsilon': 9.377683464256201e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 1.2773007373728252e-05, 'tol': 0.044411305379779345, 'validation_fraction': 0.6114460718844494}]
function_evaluation time 0.328725 value 7.218937 suggestion {'alpha': 0.010313650050879692, 'batch_size': 112, 'beta_1': 0.6571624323363834, 'beta_2': 0.9210857563812529, 'epsilon': 9.377683464256201e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 1.2773007373728252e-05, 'tol': 0.044411305379779345, 'validation_fraction': 0.6114460718844494}
observation time 0.000073, current best 0.180305 at iter 5
suggestion time taken 0.002128 iter 6 next_points [{'alpha': 0.0001727097777602661, 'batch_size': 166, 'beta_1': 0.6750716265416928, 'beta_2': 0.9340595863039834, 'epsilon': 2.063699598657192e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0001356593933952039, 'tol': 0.0005665693760728488, 'validation_fraction': 0.8345467054146928}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.882193 value 7.608413 suggestion {'alpha': 0.0001727097777602661, 'batch_size': 166, 'beta_1': 0.6750716265416928, 'beta_2': 0.9340595863039834, 'epsilon': 2.063699598657192e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0001356593933952039, 'tol': 0.0005665693760728488, 'validation_fraction': 0.8345467054146928}
observation time 0.000068, current best 0.180305 at iter 6
suggestion time taken 0.002161 iter 7 next_points [{'alpha': 0.0006036472036388439, 'batch_size': 102, 'beta_1': 0.7655596567468178, 'beta_2': 0.9356578914446121, 'epsilon': 3.6312714994490975e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.033213836111149315, 'tol': 0.008546377617971461, 'validation_fraction': 0.14116932981508115}]
function_evaluation time 0.783706 value 0.166325 suggestion {'alpha': 0.0006036472036388439, 'batch_size': 102, 'beta_1': 0.7655596567468178, 'beta_2': 0.9356578914446121, 'epsilon': 3.6312714994490975e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.033213836111149315, 'tol': 0.008546377617971461, 'validation_fraction': 0.14116932981508115}
observation time 0.000068, current best 0.166325 at iter 7
suggestion time taken 0.002118 iter 8 next_points [{'alpha': 0.0008017063306621628, 'batch_size': 122, 'beta_1': 0.7352332281340372, 'beta_2': 0.9385600735098488, 'epsilon': 5.171462868249323e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.008515666823585278, 'tol': 0.00947018619037833, 'validation_fraction': 0.6859498226003703}]
function_evaluation time 0.367487 value 0.218367 suggestion {'alpha': 0.0008017063306621628, 'batch_size': 122, 'beta_1': 0.7352332281340372, 'beta_2': 0.9385600735098488, 'epsilon': 5.171462868249323e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.008515666823585278, 'tol': 0.00947018619037833, 'validation_fraction': 0.6859498226003703}
observation time 0.000072, current best 0.166325 at iter 8
suggestion time taken 0.002151 iter 9 next_points [{'alpha': 6.260269335443509, 'batch_size': 183, 'beta_1': 0.6952809285396699, 'beta_2': 0.9941089883956431, 'epsilon': 1.5197549878975705e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.048102015832321474, 'tol': 0.0004416333336608922, 'validation_fraction': 0.12906021695833755}]
function_evaluation time 0.827400 value 0.165186 suggestion {'alpha': 6.260269335443509, 'batch_size': 183, 'beta_1': 0.6952809285396699, 'beta_2': 0.9941089883956431, 'epsilon': 1.5197549878975705e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.048102015832321474, 'tol': 0.0004416333336608922, 'validation_fraction': 0.12906021695833755}
observation time 0.000073, current best 0.165186 at iter 9
suggestion time taken 0.002341 iter 10 next_points [{'alpha': 0.0006247073384253074, 'batch_size': 199, 'beta_1': 0.7254936630860119, 'beta_2': 0.985938806985195, 'epsilon': 8.365097963613145e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.06611628939565149, 'tol': 0.0003916446438169784, 'validation_fraction': 0.6166378885508227}]
function_evaluation time 0.928941 value 0.424318 suggestion {'alpha': 0.0006247073384253074, 'batch_size': 199, 'beta_1': 0.7254936630860119, 'beta_2': 0.985938806985195, 'epsilon': 8.365097963613145e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.06611628939565149, 'tol': 0.0003916446438169784, 'validation_fraction': 0.6166378885508227}
observation time 0.000073, current best 0.165186 at iter 10
suggestion time taken 0.002132 iter 11 next_points [{'alpha': 0.0025984764785766702, 'batch_size': 17, 'beta_1': 0.9424222026408036, 'beta_2': 0.9275306951395542, 'epsilon': 7.439256393833722e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0006091389679876862, 'tol': 2.64456601400677e-05, 'validation_fraction': 0.2667441699268112}]
function_evaluation time 3.142920 value 0.104933 suggestion {'alpha': 0.0025984764785766702, 'batch_size': 17, 'beta_1': 0.9424222026408036, 'beta_2': 0.9275306951395542, 'epsilon': 7.439256393833722e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0006091389679876862, 'tol': 2.64456601400677e-05, 'validation_fraction': 0.2667441699268112}
observation time 0.000076, current best 0.104933 at iter 11
suggestion time taken 0.002128 iter 12 next_points [{'alpha': 0.1913837296660097, 'batch_size': 197, 'beta_1': 0.5191715184911171, 'beta_2': 0.9402272709761186, 'epsilon': 1.3135866653432507e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.01669388108313426, 'tol': 1.9859337663552136e-05, 'validation_fraction': 0.264590162814761}]
function_evaluation time 0.917245 value 0.110345 suggestion {'alpha': 0.1913837296660097, 'batch_size': 197, 'beta_1': 0.5191715184911171, 'beta_2': 0.9402272709761186, 'epsilon': 1.3135866653432507e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.01669388108313426, 'tol': 1.9859337663552136e-05, 'validation_fraction': 0.264590162814761}
observation time 0.000075, current best 0.104933 at iter 12
suggestion time taken 0.002164 iter 13 next_points [{'alpha': 1.0732519298709053, 'batch_size': 99, 'beta_1': 0.6528264673842029, 'beta_2': 0.9296100983623773, 'epsilon': 2.2944796430856466e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.004629576826568621, 'tol': 0.000490863699060617, 'validation_fraction': 0.13082899646002927}]
function_evaluation time 0.804099 value 0.121694 suggestion {'alpha': 1.0732519298709053, 'batch_size': 99, 'beta_1': 0.6528264673842029, 'beta_2': 0.9296100983623773, 'epsilon': 2.2944796430856466e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.004629576826568621, 'tol': 0.000490863699060617, 'validation_fraction': 0.13082899646002927}
observation time 0.000071, current best 0.104933 at iter 13
suggestion time taken 0.002141 iter 14 next_points [{'alpha': 0.18939871667792385, 'batch_size': 244, 'beta_1': 0.6956125521456619, 'beta_2': 0.9288966934741756, 'epsilon': 1.9424230280308524e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0033389797967209637, 'tol': 0.0023277292947064495, 'validation_fraction': 0.4568372558986478}]
function_evaluation time 0.753506 value 0.151487 suggestion {'alpha': 0.18939871667792385, 'batch_size': 244, 'beta_1': 0.6956125521456619, 'beta_2': 0.9288966934741756, 'epsilon': 1.9424230280308524e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0033389797967209637, 'tol': 0.0023277292947064495, 'validation_fraction': 0.4568372558986478}
observation time 0.000071, current best 0.104933 at iter 14
saving meta data: {'args': {'--uuid': '83915805313b559597f684351aa16768', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
