running: {'--uuid': 'b657bb95844c5cf99a9a37f1022370db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d digits -o opentuner -u b657bb95844c5cf99a9a37f1022370db -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study opentuner MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.017205 iter 0 next_points [{'hidden_layer_sizes': 115, 'alpha': 5.86944576026498, 'batch_size': 207, 'learning_rate_init': 0.0690474752012346, 'tol': 0.058398608538868295, 'validation_fraction': 0.27164752285559257, 'beta_1': 0.6778910129633754, 'beta_2': 0.9358358561257054, 'epsilon': 7.478519698239362e-07}]
function_evaluation time 0.472462 value -0.521932 suggestion {'hidden_layer_sizes': 115, 'alpha': 5.86944576026498, 'batch_size': 207, 'learning_rate_init': 0.0690474752012346, 'tol': 0.058398608538868295, 'validation_fraction': 0.27164752285559257, 'beta_1': 0.6778910129633754, 'beta_2': 0.9358358561257054, 'epsilon': 7.478519698239362e-07}
observation time 0.004134, current best -0.521932 at iter 0
suggestion time taken 0.046089 iter 1 next_points [{'alpha': 2.3171810155316104, 'beta_2': 0.908679775215665, 'hidden_layer_sizes': 200, 'epsilon': 4.5264160500377195e-07, 'validation_fraction': 0.46684006916264686, 'tol': 0.08832193051246177, 'beta_1': 0.5173228476080622, 'batch_size': 61, 'learning_rate_init': 0.08251150696658509}]
function_evaluation time 0.637275 value -0.556543 suggestion {'alpha': 2.3171810155316104, 'beta_2': 0.908679775215665, 'hidden_layer_sizes': 200, 'epsilon': 4.5264160500377195e-07, 'validation_fraction': 0.46684006916264686, 'tol': 0.08832193051246177, 'beta_1': 0.5173228476080622, 'batch_size': 61, 'learning_rate_init': 0.08251150696658509}
observation time 0.001835, current best -0.556543 at iter 1
suggestion time taken 0.021323 iter 2 next_points [{'alpha': 0.5249181291260253, 'beta_2': 0.9118236935160501, 'hidden_layer_sizes': 56, 'epsilon': 8.552084817264594e-07, 'validation_fraction': 0.3522221638658547, 'tol': 0.08117347841116189, 'beta_1': 0.8208226834244525, 'batch_size': 198, 'learning_rate_init': 0.03807405089960552}]
function_evaluation time 0.278100 value -0.941541 suggestion {'alpha': 0.5249181291260253, 'beta_2': 0.9118236935160501, 'hidden_layer_sizes': 56, 'epsilon': 8.552084817264594e-07, 'validation_fraction': 0.3522221638658547, 'tol': 0.08117347841116189, 'beta_1': 0.8208226834244525, 'batch_size': 198, 'learning_rate_init': 0.03807405089960552}
observation time 0.002137, current best -0.941541 at iter 2
suggestion time taken 0.007200 iter 3 next_points [{'alpha': 0.5249181291260253, 'beta_2': 0.9118236935160501, 'hidden_layer_sizes': 56, 'epsilon': 2.1665032692905106e-07, 'validation_fraction': 0.3522221638658547, 'tol': 0.0977331414901798, 'beta_1': 0.8208226834244525, 'batch_size': 198, 'learning_rate_init': 0.03807405089960552}]
function_evaluation time 0.274211 value -0.938756 suggestion {'alpha': 0.5249181291260253, 'beta_2': 0.9118236935160501, 'hidden_layer_sizes': 56, 'epsilon': 2.1665032692905106e-07, 'validation_fraction': 0.3522221638658547, 'tol': 0.0977331414901798, 'beta_1': 0.8208226834244525, 'batch_size': 198, 'learning_rate_init': 0.03807405089960552}
observation time 0.002258, current best -0.941541 at iter 3
suggestion time taken 0.005096 iter 4 next_points [{'alpha': 0.31770431137029703, 'beta_2': 0.9809188692239876, 'hidden_layer_sizes': 168, 'epsilon': 2.5810876916384964e-07, 'validation_fraction': 0.11219238635070648, 'tol': 0.04133810187512282, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.042171480019963674}]
function_evaluation time 0.608126 value -0.960330 suggestion {'alpha': 0.31770431137029703, 'beta_2': 0.9809188692239876, 'hidden_layer_sizes': 168, 'epsilon': 2.5810876916384964e-07, 'validation_fraction': 0.11219238635070648, 'tol': 0.04133810187512282, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.042171480019963674}
observation time 0.001825, current best -0.960330 at iter 4
suggestion time taken 0.005904 iter 5 next_points [{'alpha': 8.437412854499705, 'beta_2': 0.9816475304946417, 'hidden_layer_sizes': 139, 'epsilon': 9.802999922098034e-07, 'validation_fraction': 0.6750582931759618, 'tol': 0.014418289880676328, 'beta_1': 0.8888911626026267, 'batch_size': 97, 'learning_rate_init': 0.038938276022723865}]
function_evaluation time 0.464978 value -0.938778 suggestion {'alpha': 8.437412854499705, 'beta_2': 0.9816475304946417, 'hidden_layer_sizes': 139, 'epsilon': 9.802999922098034e-07, 'validation_fraction': 0.6750582931759618, 'tol': 0.014418289880676328, 'beta_1': 0.8888911626026267, 'batch_size': 97, 'learning_rate_init': 0.038938276022723865}
observation time 0.001873, current best -0.960330 at iter 5
suggestion time taken 0.007239 iter 6 next_points [{'alpha': 0.07066623451898495, 'beta_2': 0.9736226346262862, 'hidden_layer_sizes': 168, 'epsilon': 3.520228534508997e-07, 'validation_fraction': 0.11219238635070648, 'tol': 0.05669461166065031, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.042171480019963674}]
function_evaluation time 0.596380 value -0.949913 suggestion {'alpha': 0.07066623451898495, 'beta_2': 0.9736226346262862, 'hidden_layer_sizes': 168, 'epsilon': 3.520228534508997e-07, 'validation_fraction': 0.11219238635070648, 'tol': 0.05669461166065031, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.042171480019963674}
observation time 0.001830, current best -0.960330 at iter 6
suggestion time taken 0.005044 iter 7 next_points [{'alpha': 5.048480377711956, 'beta_2': 0.9999917997964586, 'hidden_layer_sizes': 124, 'epsilon': 5.885752844275439e-07, 'validation_fraction': 0.8314165028440798, 'tol': 0.04413055276578886, 'beta_1': 0.6254569835702337, 'batch_size': 245, 'learning_rate_init': 0.020154485680146262}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.254248 value -0.897733 suggestion {'alpha': 5.048480377711956, 'beta_2': 0.9999917997964586, 'hidden_layer_sizes': 124, 'epsilon': 5.885752844275439e-07, 'validation_fraction': 0.8314165028440798, 'tol': 0.04413055276578886, 'beta_1': 0.6254569835702337, 'batch_size': 245, 'learning_rate_init': 0.020154485680146262}
observation time 0.001815, current best -0.960330 at iter 7
suggestion time taken 0.005081 iter 8 next_points [{'alpha': 1.5674191534318829, 'beta_2': 0.9181583366848685, 'hidden_layer_sizes': 198, 'epsilon': 8.813851876404422e-07, 'validation_fraction': 0.38500455177415416, 'tol': 0.015352853767713826, 'beta_1': 0.8901878754111072, 'batch_size': 174, 'learning_rate_init': 0.04573854932839743}]
function_evaluation time 0.708302 value -0.929024 suggestion {'alpha': 1.5674191534318829, 'beta_2': 0.9181583366848685, 'hidden_layer_sizes': 198, 'epsilon': 8.813851876404422e-07, 'validation_fraction': 0.38500455177415416, 'tol': 0.015352853767713826, 'beta_1': 0.8901878754111072, 'batch_size': 174, 'learning_rate_init': 0.04573854932839743}
observation time 0.001937, current best -0.960330 at iter 8
suggestion time taken 0.005833 iter 9 next_points [{'alpha': 3.2917291700752576, 'beta_2': 0.9908738789204503, 'hidden_layer_sizes': 163, 'epsilon': 3.504647093926773e-07, 'validation_fraction': 0.8496123878506955, 'tol': 0.09209189402521549, 'beta_1': 0.6466474578046615, 'batch_size': 93, 'learning_rate_init': 0.09534572692278902}]
function_evaluation time 0.233401 value -0.411300 suggestion {'alpha': 3.2917291700752576, 'beta_2': 0.9908738789204503, 'hidden_layer_sizes': 163, 'epsilon': 3.504647093926773e-07, 'validation_fraction': 0.8496123878506955, 'tol': 0.09209189402521549, 'beta_1': 0.6466474578046615, 'batch_size': 93, 'learning_rate_init': 0.09534572692278902}
observation time 0.001859, current best -0.960330 at iter 9
suggestion time taken 0.006876 iter 10 next_points [{'alpha': 0.31770431137029703, 'beta_2': 0.9831203326900851, 'hidden_layer_sizes': 159, 'epsilon': 2.5810876916384964e-07, 'validation_fraction': 0.12653330244288397, 'tol': 0.04133810187512282, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.03007240096779056}]
function_evaluation time 0.554181 value -0.952693 suggestion {'alpha': 0.31770431137029703, 'beta_2': 0.9831203326900851, 'hidden_layer_sizes': 159, 'epsilon': 2.5810876916384964e-07, 'validation_fraction': 0.12653330244288397, 'tol': 0.04133810187512282, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.03007240096779056}
observation time 0.002644, current best -0.960330 at iter 10
suggestion time taken 0.004973 iter 11 next_points [{'alpha': 6.314459937217204, 'beta_2': 0.908124579672399, 'hidden_layer_sizes': 122, 'epsilon': 6.911680974827538e-08, 'validation_fraction': 0.7304071540519045, 'tol': 0.043006732559345666, 'beta_1': 0.55413673997467, 'batch_size': 109, 'learning_rate_init': 0.08949667638673968}]
function_evaluation time 0.267404 value -0.515701 suggestion {'alpha': 6.314459937217204, 'beta_2': 0.908124579672399, 'hidden_layer_sizes': 122, 'epsilon': 6.911680974827538e-08, 'validation_fraction': 0.7304071540519045, 'tol': 0.043006732559345666, 'beta_1': 0.55413673997467, 'batch_size': 109, 'learning_rate_init': 0.08949667638673968}
observation time 0.001787, current best -0.960330 at iter 11
suggestion time taken 0.005003 iter 12 next_points [{'alpha': 5.127589197826637, 'beta_2': 0.9780480979706031, 'hidden_layer_sizes': 73, 'epsilon': 9.274750766568852e-07, 'validation_fraction': 0.6089137349413736, 'tol': 0.02094780186649652, 'beta_1': 0.5293706996632941, 'batch_size': 200, 'learning_rate_init': 0.06398053178541645}]
function_evaluation time 0.361881 value -0.855224 suggestion {'alpha': 5.127589197826637, 'beta_2': 0.9780480979706031, 'hidden_layer_sizes': 73, 'epsilon': 9.274750766568852e-07, 'validation_fraction': 0.6089137349413736, 'tol': 0.02094780186649652, 'beta_1': 0.5293706996632941, 'batch_size': 200, 'learning_rate_init': 0.06398053178541645}
observation time 0.001821, current best -0.960330 at iter 12
suggestion time taken 0.006605 iter 13 next_points [{'alpha': 0.31770431137029703, 'beta_2': 0.9809188692239876, 'hidden_layer_sizes': 175, 'epsilon': 2.5810876916384964e-07, 'validation_fraction': 0.11219238635070648, 'tol': 0.04133810187512282, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.042171480019963674}]
function_evaluation time 0.604113 value -0.954767 suggestion {'alpha': 0.31770431137029703, 'beta_2': 0.9809188692239876, 'hidden_layer_sizes': 175, 'epsilon': 2.5810876916384964e-07, 'validation_fraction': 0.11219238635070648, 'tol': 0.04133810187512282, 'beta_1': 0.6231723957822366, 'batch_size': 111, 'learning_rate_init': 0.042171480019963674}
observation time 0.001859, current best -0.960330 at iter 13
suggestion time taken 0.005828 iter 14 next_points [{'alpha': 9.272121367908387, 'beta_2': 0.9581746423082014, 'hidden_layer_sizes': 171, 'epsilon': 9.503368839144832e-08, 'validation_fraction': 0.43636637015127344, 'tol': 0.07796842144988607, 'beta_1': 0.790518959332843, 'batch_size': 175, 'learning_rate_init': 0.027718568461650262}]
function_evaluation time 0.375144 value -0.940858 suggestion {'alpha': 9.272121367908387, 'beta_2': 0.9581746423082014, 'hidden_layer_sizes': 171, 'epsilon': 9.503368839144832e-08, 'validation_fraction': 0.43636637015127344, 'tol': 0.07796842144988607, 'beta_1': 0.790518959332843, 'batch_size': 175, 'learning_rate_init': 0.027718568461650262}
observation time 0.001802, current best -0.960330 at iter 14
saving meta data: {'args': {'--uuid': 'b657bb95844c5cf99a9a37f1022370db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
