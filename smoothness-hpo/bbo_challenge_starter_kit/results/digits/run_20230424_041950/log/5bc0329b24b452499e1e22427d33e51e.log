running: {'--uuid': '5bc0329b24b452499e1e22427d33e51e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 5bc0329b24b452499e1e22427d33e51e -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 11.832048 iter 0 next_points [{'alpha': 0.1360458177374764, 'batch_size': 50, 'beta_1': 0.8816204950735648, 'beta_2': 0.9999799560503007, 'epsilon': 1.7918091359001244e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0002717987983683115, 'tol': 0.004421740219465609, 'validation_fraction': 0.11708042377435376}]
function_evaluation time 1.890971 value 0.218179 suggestion {'alpha': 0.1360458177374764, 'batch_size': 50, 'beta_1': 0.8816204950735648, 'beta_2': 0.9999799560503007, 'epsilon': 1.7918091359001244e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0002717987983683115, 'tol': 0.004421740219465609, 'validation_fraction': 0.11708042377435376}
observation time 0.000006, current best 0.218179 at iter 0
suggestion time taken 12.381783 iter 1 next_points [{'alpha': 0.003688820212814133, 'batch_size': 31, 'beta_1': 0.9274251982714887, 'beta_2': 0.948571608231652, 'epsilon': 6.72076721483841e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.04204304492821597, 'tol': 0.0006767289362714287, 'validation_fraction': 0.2899726427287447}]
function_evaluation time 1.821556 value 0.612724 suggestion {'alpha': 0.003688820212814133, 'batch_size': 31, 'beta_1': 0.9274251982714887, 'beta_2': 0.948571608231652, 'epsilon': 6.72076721483841e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.04204304492821597, 'tol': 0.0006767289362714287, 'validation_fraction': 0.2899726427287447}
observation time 0.000006, current best 0.218179 at iter 1
suggestion time taken 12.022659 iter 2 next_points [{'alpha': 0.0037778213797922517, 'batch_size': 63, 'beta_1': 0.5779020790701587, 'beta_2': 0.9519644015178594, 'epsilon': 2.0006089775936798e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.006119450109490389, 'tol': 0.00041209005503408774, 'validation_fraction': 0.8681212710110182}]
function_evaluation time 0.997763 value 0.466803 suggestion {'alpha': 0.0037778213797922517, 'batch_size': 63, 'beta_1': 0.5779020790701587, 'beta_2': 0.9519644015178594, 'epsilon': 2.0006089775936798e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.006119450109490389, 'tol': 0.00041209005503408774, 'validation_fraction': 0.8681212710110182}
observation time 0.000006, current best 0.218179 at iter 2
suggestion time taken 12.060119 iter 3 next_points [{'alpha': 7.102870731734423e-05, 'batch_size': 71, 'beta_1': 0.9787608229431306, 'beta_2': 0.9999445438944942, 'epsilon': 2.217099739640472e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 3.513379929435982e-05, 'tol': 0.004687452265053601, 'validation_fraction': 0.10229166454603018}]
function_evaluation time 4.401832 value 0.490654 suggestion {'alpha': 7.102870731734423e-05, 'batch_size': 71, 'beta_1': 0.9787608229431306, 'beta_2': 0.9999445438944942, 'epsilon': 2.217099739640472e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 3.513379929435982e-05, 'tol': 0.004687452265053601, 'validation_fraction': 0.10229166454603018}
observation time 0.000007, current best 0.218179 at iter 3
suggestion time taken 11.730651 iter 4 next_points [{'alpha': 7.006357071503916e-05, 'batch_size': 104, 'beta_1': 0.9244400420622306, 'beta_2': 0.9999950259634273, 'epsilon': 6.273897396401207e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 2.2004086327222848e-05, 'tol': 4.3248000185099166e-05, 'validation_fraction': 0.7538551378270272}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.104091 value 8.660591 suggestion {'alpha': 7.006357071503916e-05, 'batch_size': 104, 'beta_1': 0.9244400420622306, 'beta_2': 0.9999950259634273, 'epsilon': 6.273897396401207e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 2.2004086327222848e-05, 'tol': 4.3248000185099166e-05, 'validation_fraction': 0.7538551378270272}
observation time 0.000005, current best 0.218179 at iter 4
suggestion time taken 11.959125 iter 5 next_points [{'alpha': 0.168690928722694, 'batch_size': 36, 'beta_1': 0.9040556072546727, 'beta_2': 0.9997583979847904, 'epsilon': 8.738272563993296e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.060828312190775134, 'tol': 0.06099443186872221, 'validation_fraction': 0.13218711092880736}]
function_evaluation time 0.848166 value 0.743181 suggestion {'alpha': 0.168690928722694, 'batch_size': 36, 'beta_1': 0.9040556072546727, 'beta_2': 0.9997583979847904, 'epsilon': 8.738272563993296e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.060828312190775134, 'tol': 0.06099443186872221, 'validation_fraction': 0.13218711092880736}
observation time 0.000006, current best 0.218179 at iter 5
suggestion time taken 12.646531 iter 6 next_points [{'alpha': 0.00578854766497979, 'batch_size': 158, 'beta_1': 0.7705170468008882, 'beta_2': 0.999885429989601, 'epsilon': 3.4131254076068676e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0005427716839009215, 'tol': 1.1759196455026794e-05, 'validation_fraction': 0.6853801106538918}]
function_evaluation time 1.872231 value 0.335729 suggestion {'alpha': 0.00578854766497979, 'batch_size': 158, 'beta_1': 0.7705170468008882, 'beta_2': 0.999885429989601, 'epsilon': 3.4131254076068676e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0005427716839009215, 'tol': 1.1759196455026794e-05, 'validation_fraction': 0.6853801106538918}
observation time 0.000005, current best 0.218179 at iter 6
suggestion time taken 12.097462 iter 7 next_points [{'alpha': 2.047498661303843e-05, 'batch_size': 63, 'beta_1': 0.905014611300754, 'beta_2': 0.9950302320768925, 'epsilon': 4.698520622837499e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 1.1969784603170039e-05, 'tol': 0.0005357542634556854, 'validation_fraction': 0.3835597808890022}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.082107 value 10.070552 suggestion {'alpha': 2.047498661303843e-05, 'batch_size': 63, 'beta_1': 0.905014611300754, 'beta_2': 0.9950302320768925, 'epsilon': 4.698520622837499e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 1.1969784603170039e-05, 'tol': 0.0005357542634556854, 'validation_fraction': 0.3835597808890022}
observation time 0.000006, current best 0.218179 at iter 7
suggestion time taken 12.002509 iter 8 next_points [{'alpha': 0.04067920878179142, 'batch_size': 51, 'beta_1': 0.9888893609176769, 'beta_2': 0.9998821433972062, 'epsilon': 3.495405953433205e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.2269742639455233e-05, 'tol': 0.0026726661279915195, 'validation_fraction': 0.7687159189258786}]
function_evaluation time 0.273843 value 11.489315 suggestion {'alpha': 0.04067920878179142, 'batch_size': 51, 'beta_1': 0.9888893609176769, 'beta_2': 0.9998821433972062, 'epsilon': 3.495405953433205e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.2269742639455233e-05, 'tol': 0.0026726661279915195, 'validation_fraction': 0.7687159189258786}
observation time 0.000006, current best 0.218179 at iter 8
suggestion time taken 12.515911 iter 9 next_points [{'alpha': 7.18606583466377e-05, 'batch_size': 84, 'beta_1': 0.9787415752358507, 'beta_2': 0.9988615214259247, 'epsilon': 1.7500653398204275e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.005191459663294923, 'tol': 9.530877091882571e-05, 'validation_fraction': 0.24879623467797415}]
function_evaluation time 1.011132 value 0.145954 suggestion {'alpha': 7.18606583466377e-05, 'batch_size': 84, 'beta_1': 0.9787415752358507, 'beta_2': 0.9988615214259247, 'epsilon': 1.7500653398204275e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.005191459663294923, 'tol': 9.530877091882571e-05, 'validation_fraction': 0.24879623467797415}
observation time 0.000006, current best 0.145954 at iter 9
suggestion time taken 12.293873 iter 10 next_points [{'alpha': 0.010532182010293621, 'batch_size': 73, 'beta_1': 0.7690266052693201, 'beta_2': 0.9844126356933803, 'epsilon': 1.6466858874086472e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0014382295904170797, 'tol': 0.054498209933151485, 'validation_fraction': 0.2588441744684764}]
function_evaluation time 0.507760 value 0.219165 suggestion {'alpha': 0.010532182010293621, 'batch_size': 73, 'beta_1': 0.7690266052693201, 'beta_2': 0.9844126356933803, 'epsilon': 1.6466858874086472e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0014382295904170797, 'tol': 0.054498209933151485, 'validation_fraction': 0.2588441744684764}
observation time 0.000006, current best 0.145954 at iter 10
suggestion time taken 12.111780 iter 11 next_points [{'alpha': 1.7194922313694678e-05, 'batch_size': 57, 'beta_1': 0.9528564640981578, 'beta_2': 0.9995319778608542, 'epsilon': 9.3889469485744e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.004563657347053815, 'tol': 0.020121354055503967, 'validation_fraction': 0.3496637004318513}]
function_evaluation time 0.551626 value 0.150087 suggestion {'alpha': 1.7194922313694678e-05, 'batch_size': 57, 'beta_1': 0.9528564640981578, 'beta_2': 0.9995319778608542, 'epsilon': 9.3889469485744e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.004563657347053815, 'tol': 0.020121354055503967, 'validation_fraction': 0.3496637004318513}
observation time 0.000007, current best 0.145954 at iter 11
suggestion time taken 12.525211 iter 12 next_points [{'alpha': 8.483834148995223, 'batch_size': 145, 'beta_1': 0.8408950493755069, 'beta_2': 0.9977703314238613, 'epsilon': 1.9174909674478123e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00020384721084519685, 'tol': 0.049935617986562396, 'validation_fraction': 0.6568625936356961}]
function_evaluation time 0.202536 value 4.896415 suggestion {'alpha': 8.483834148995223, 'batch_size': 145, 'beta_1': 0.8408950493755069, 'beta_2': 0.9977703314238613, 'epsilon': 1.9174909674478123e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00020384721084519685, 'tol': 0.049935617986562396, 'validation_fraction': 0.6568625936356961}
observation time 0.000005, current best 0.145954 at iter 12
suggestion time taken 12.361349 iter 13 next_points [{'alpha': 0.026818761845463425, 'batch_size': 128, 'beta_1': 0.9057601941513874, 'beta_2': 0.9870623514992637, 'epsilon': 9.478863830154971e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.028296906750321798, 'tol': 0.0001678511755185714, 'validation_fraction': 0.7598281960989705}]
function_evaluation time 0.717305 value 0.380869 suggestion {'alpha': 0.026818761845463425, 'batch_size': 128, 'beta_1': 0.9057601941513874, 'beta_2': 0.9870623514992637, 'epsilon': 9.478863830154971e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.028296906750321798, 'tol': 0.0001678511755185714, 'validation_fraction': 0.7598281960989705}
observation time 0.000006, current best 0.145954 at iter 13
suggestion time taken 12.338632 iter 14 next_points [{'alpha': 0.000690703977109771, 'batch_size': 113, 'beta_1': 0.9881587134987132, 'beta_2': 0.999053304347362, 'epsilon': 7.337481126673773e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.019812918021532986, 'tol': 0.08428650078672462, 'validation_fraction': 0.6161386151689102}]
function_evaluation time 0.267456 value 0.493719 suggestion {'alpha': 0.000690703977109771, 'batch_size': 113, 'beta_1': 0.9881587134987132, 'beta_2': 0.999053304347362, 'epsilon': 7.337481126673773e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.019812918021532986, 'tol': 0.08428650078672462, 'validation_fraction': 0.6161386151689102}
observation time 0.000007, current best 0.145954 at iter 14
saving meta data: {'args': {'--uuid': '5bc0329b24b452499e1e22427d33e51e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
