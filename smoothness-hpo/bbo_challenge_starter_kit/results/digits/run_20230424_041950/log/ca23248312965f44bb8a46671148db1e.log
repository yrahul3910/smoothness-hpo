running: {'--uuid': 'ca23248312965f44bb8a46671148db1e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u ca23248312965f44bb8a46671148db1e -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002682 iter 0 next_points [{'alpha': 1.8431780980762127e-05, 'batch_size': 44, 'beta_1': 0.936557297735732, 'beta_2': 0.9680105452769578, 'epsilon': 3.860359135652427e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0047600654737941775, 'tol': 0.0003670134088990264, 'validation_fraction': 0.23131470816109057}]
function_evaluation time 1.514527 value -0.969391 suggestion {'alpha': 1.8431780980762127e-05, 'batch_size': 44, 'beta_1': 0.936557297735732, 'beta_2': 0.9680105452769578, 'epsilon': 3.860359135652427e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0047600654737941775, 'tol': 0.0003670134088990264, 'validation_fraction': 0.23131470816109057}
observation time 0.000006, current best -0.969391 at iter 0
suggestion time taken 0.002524 iter 1 next_points [{'alpha': 0.0010241012746041154, 'batch_size': 146, 'beta_1': 0.9635688717282241, 'beta_2': 0.9999962398071431, 'epsilon': 1.990284811814475e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.03881732788355614, 'tol': 0.05362833621966727, 'validation_fraction': 0.24920483589381498}]
function_evaluation time 0.402874 value -0.900452 suggestion {'alpha': 0.0010241012746041154, 'batch_size': 146, 'beta_1': 0.9635688717282241, 'beta_2': 0.9999962398071431, 'epsilon': 1.990284811814475e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.03881732788355614, 'tol': 0.05362833621966727, 'validation_fraction': 0.24920483589381498}
observation time 0.000005, current best -0.969391 at iter 1
suggestion time taken 0.002522 iter 2 next_points [{'alpha': 0.08194064264135419, 'batch_size': 174, 'beta_1': 0.8315349565767762, 'beta_2': 0.9997333736986711, 'epsilon': 2.5614949106373904e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.00213484019482615, 'tol': 0.06611178514244004, 'validation_fraction': 0.6050942060857433}]
function_evaluation time 0.340361 value -0.930415 suggestion {'alpha': 0.08194064264135419, 'batch_size': 174, 'beta_1': 0.8315349565767762, 'beta_2': 0.9997333736986711, 'epsilon': 2.5614949106373904e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.00213484019482615, 'tol': 0.06611178514244004, 'validation_fraction': 0.6050942060857433}
observation time 0.000004, current best -0.969391 at iter 2
suggestion time taken 0.002487 iter 3 next_points [{'alpha': 0.10063707095518708, 'batch_size': 130, 'beta_1': 0.9130926026291747, 'beta_2': 0.9996617050846351, 'epsilon': 1.0976327227823519e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 4.284328245693931e-05, 'tol': 0.046817691894150366, 'validation_fraction': 0.7476314807254298}]
function_evaluation time 0.185636 value -0.112045 suggestion {'alpha': 0.10063707095518708, 'batch_size': 130, 'beta_1': 0.9130926026291747, 'beta_2': 0.9996617050846351, 'epsilon': 1.0976327227823519e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 4.284328245693931e-05, 'tol': 0.046817691894150366, 'validation_fraction': 0.7476314807254298}
observation time 0.000005, current best -0.969391 at iter 3
suggestion time taken 0.002512 iter 4 next_points [{'alpha': 1.117434259254697e-05, 'batch_size': 200, 'beta_1': 0.6266380794729639, 'beta_2': 0.9976626062972329, 'epsilon': 1.1265624435428332e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.01676501181847503, 'tol': 0.010992847066706654, 'validation_fraction': 0.8923920584309711}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.257483 value -0.869861 suggestion {'alpha': 1.117434259254697e-05, 'batch_size': 200, 'beta_1': 0.6266380794729639, 'beta_2': 0.9976626062972329, 'epsilon': 1.1265624435428332e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.01676501181847503, 'tol': 0.010992847066706654, 'validation_fraction': 0.8923920584309711}
observation time 0.000005, current best -0.969391 at iter 4
suggestion time taken 0.002730 iter 5 next_points [{'alpha': 7.51531702602114, 'batch_size': 162, 'beta_1': 0.6974663432007934, 'beta_2': 0.9965922391961203, 'epsilon': 1.6840378808069205e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0003040445841311973, 'tol': 3.748918224802121e-05, 'validation_fraction': 0.17782062026083748}]
function_evaluation time 2.485216 value -0.948519 suggestion {'alpha': 7.51531702602114, 'batch_size': 162, 'beta_1': 0.6974663432007934, 'beta_2': 0.9965922391961203, 'epsilon': 1.6840378808069205e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0003040445841311973, 'tol': 3.748918224802121e-05, 'validation_fraction': 0.17782062026083748}
observation time 0.000005, current best -0.969391 at iter 5
suggestion time taken 0.002504 iter 6 next_points [{'alpha': 1.5539534097463135, 'batch_size': 197, 'beta_1': 0.6528758273854068, 'beta_2': 0.9999540805887458, 'epsilon': 7.772230662834857e-08, 'hidden_layer_sizes': 139, 'learning_rate_init': 2.6296210225242095e-05, 'tol': 0.004746476746607424, 'validation_fraction': 0.868369623700868}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.176149 value -0.076570 suggestion {'alpha': 1.5539534097463135, 'batch_size': 197, 'beta_1': 0.6528758273854068, 'beta_2': 0.9999540805887458, 'epsilon': 7.772230662834857e-08, 'hidden_layer_sizes': 139, 'learning_rate_init': 2.6296210225242095e-05, 'tol': 0.004746476746607424, 'validation_fraction': 0.868369623700868}
observation time 0.000005, current best -0.969391 at iter 6
suggestion time taken 0.002764 iter 7 next_points [{'alpha': 0.17244006836765358, 'batch_size': 11, 'beta_1': 0.7452148324214865, 'beta_2': 0.9999860018537177, 'epsilon': 1.0035689146717023e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.005854421451199075, 'tol': 0.015831812625053628, 'validation_fraction': 0.1615869130933091}]
function_evaluation time 2.605659 value -0.962427 suggestion {'alpha': 0.17244006836765358, 'batch_size': 11, 'beta_1': 0.7452148324214865, 'beta_2': 0.9999860018537177, 'epsilon': 1.0035689146717023e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.005854421451199075, 'tol': 0.015831812625053628, 'validation_fraction': 0.1615869130933091}
observation time 0.000004, current best -0.969391 at iter 7
suggestion time taken 0.002452 iter 8 next_points [{'alpha': 8.211946782565794e-05, 'batch_size': 151, 'beta_1': 0.7200063050505315, 'beta_2': 0.9958435565800424, 'epsilon': 1.1530583154110103e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 3.665341052420821e-05, 'tol': 1.2599277456700277e-05, 'validation_fraction': 0.8994254628925097}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.273067 value -0.084202 suggestion {'alpha': 8.211946782565794e-05, 'batch_size': 151, 'beta_1': 0.7200063050505315, 'beta_2': 0.9958435565800424, 'epsilon': 1.1530583154110103e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 3.665341052420821e-05, 'tol': 1.2599277456700277e-05, 'validation_fraction': 0.8994254628925097}
observation time 0.000004, current best -0.969391 at iter 8
suggestion time taken 0.002463 iter 9 next_points [{'alpha': 3.0399055762633553e-05, 'batch_size': 133, 'beta_1': 0.5816724131839703, 'beta_2': 0.9993874349380932, 'epsilon': 5.28213176919674e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 3.369190514199118e-05, 'tol': 0.023506241242970738, 'validation_fraction': 0.6176537845384098}]
function_evaluation time 0.278051 value -0.083491 suggestion {'alpha': 3.0399055762633553e-05, 'batch_size': 133, 'beta_1': 0.5816724131839703, 'beta_2': 0.9993874349380932, 'epsilon': 5.28213176919674e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 3.369190514199118e-05, 'tol': 0.023506241242970738, 'validation_fraction': 0.6176537845384098}
observation time 0.000004, current best -0.969391 at iter 9
suggestion time taken 0.002451 iter 10 next_points [{'alpha': 1.705430531808644e-05, 'batch_size': 153, 'beta_1': 0.6199362182601381, 'beta_2': 0.9999965307361028, 'epsilon': 9.075458935047549e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.002321144559261369, 'tol': 6.545157650772732e-05, 'validation_fraction': 0.1107535323048048}]
function_evaluation time 0.746500 value -0.944343 suggestion {'alpha': 1.705430531808644e-05, 'batch_size': 153, 'beta_1': 0.6199362182601381, 'beta_2': 0.9999965307361028, 'epsilon': 9.075458935047549e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.002321144559261369, 'tol': 6.545157650772732e-05, 'validation_fraction': 0.1107535323048048}
observation time 0.000004, current best -0.969391 at iter 10
suggestion time taken 0.002516 iter 11 next_points [{'alpha': 0.018031453874171016, 'batch_size': 40, 'beta_1': 0.9895159261848319, 'beta_2': 0.9995784349424581, 'epsilon': 8.292400214977444e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00023132002476721505, 'tol': 2.0150879713280668e-05, 'validation_fraction': 0.23456350243363397}]
function_evaluation time 3.169325 value -0.956182 suggestion {'alpha': 0.018031453874171016, 'batch_size': 40, 'beta_1': 0.9895159261848319, 'beta_2': 0.9995784349424581, 'epsilon': 8.292400214977444e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00023132002476721505, 'tol': 2.0150879713280668e-05, 'validation_fraction': 0.23456350243363397}
observation time 0.000005, current best -0.969391 at iter 11
suggestion time taken 0.002453 iter 12 next_points [{'alpha': 0.1519353305223577, 'batch_size': 16, 'beta_1': 0.948153756011507, 'beta_2': 0.9999941408452262, 'epsilon': 8.22554903658538e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0044321643416702266, 'tol': 0.0003954987310588449, 'validation_fraction': 0.8058556538138741}]
function_evaluation time 1.625788 value -0.934606 suggestion {'alpha': 0.1519353305223577, 'batch_size': 16, 'beta_1': 0.948153756011507, 'beta_2': 0.9999941408452262, 'epsilon': 8.22554903658538e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0044321643416702266, 'tol': 0.0003954987310588449, 'validation_fraction': 0.8058556538138741}
observation time 0.000004, current best -0.969391 at iter 12
suggestion time taken 0.002492 iter 13 next_points [{'alpha': 0.00025271445682272236, 'batch_size': 226, 'beta_1': 0.9659170082281565, 'beta_2': 0.9975479543471459, 'epsilon': 4.269170166345775e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.00029006820754811334, 'tol': 0.0005991068170285182, 'validation_fraction': 0.5009727799175268}]
function_evaluation time 2.484160 value -0.925552 suggestion {'alpha': 0.00025271445682272236, 'batch_size': 226, 'beta_1': 0.9659170082281565, 'beta_2': 0.9975479543471459, 'epsilon': 4.269170166345775e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.00029006820754811334, 'tol': 0.0005991068170285182, 'validation_fraction': 0.5009727799175268}
observation time 0.000005, current best -0.969391 at iter 13
suggestion time taken 0.002396 iter 14 next_points [{'alpha': 1.80482923678325e-05, 'batch_size': 73, 'beta_1': 0.9307168633582308, 'beta_2': 0.9999988654209072, 'epsilon': 4.140493714293757e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0007597054163506588, 'tol': 5.519364293700565e-05, 'validation_fraction': 0.5137079968480661}]
function_evaluation time 2.142633 value -0.942255 suggestion {'alpha': 1.80482923678325e-05, 'batch_size': 73, 'beta_1': 0.9307168633582308, 'beta_2': 0.9999988654209072, 'epsilon': 4.140493714293757e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0007597054163506588, 'tol': 5.519364293700565e-05, 'validation_fraction': 0.5137079968480661}
observation time 0.000005, current best -0.969391 at iter 14
saving meta data: {'args': {'--uuid': 'ca23248312965f44bb8a46671148db1e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
