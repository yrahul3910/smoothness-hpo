running: {'--uuid': '01b3911389de5e16b6a3c2cbd94de76a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 01b3911389de5e16b6a3c2cbd94de76a -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002458 iter 0 next_points [{'alpha': 0.11526411319331592, 'batch_size': 119, 'beta_1': 0.983689235462599, 'beta_2': 0.9984468590031262, 'epsilon': 3.5600505705792454e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0707420009443207, 'tol': 0.004743199050030927, 'validation_fraction': 0.6510213880571267}]
function_evaluation time 1.133327 value -0.852391 suggestion {'alpha': 0.11526411319331592, 'batch_size': 119, 'beta_1': 0.983689235462599, 'beta_2': 0.9984468590031262, 'epsilon': 3.5600505705792454e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0707420009443207, 'tol': 0.004743199050030927, 'validation_fraction': 0.6510213880571267}
observation time 0.001451, current best -0.852391 at iter 0
suggestion time taken 0.001800 iter 1 next_points [{'alpha': 3.412722887397731, 'batch_size': 157, 'beta_1': 0.6924401633933152, 'beta_2': 0.9998374461147065, 'epsilon': 2.4151877967212003e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0007880886233920465, 'tol': 0.002851645116334799, 'validation_fraction': 0.15457615971687658}]
function_evaluation time 1.547872 value -0.947813 suggestion {'alpha': 3.412722887397731, 'batch_size': 157, 'beta_1': 0.6924401633933152, 'beta_2': 0.9998374461147065, 'epsilon': 2.4151877967212003e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0007880886233920465, 'tol': 0.002851645116334799, 'validation_fraction': 0.15457615971687658}
observation time 0.001625, current best -0.947813 at iter 1
suggestion time taken 0.001848 iter 2 next_points [{'alpha': 4.9229771096409145, 'batch_size': 238, 'beta_1': 0.8652838917769092, 'beta_2': 0.9943461553568812, 'epsilon': 5.4977321738453825e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0032809200271519054, 'tol': 0.031174265065041944, 'validation_fraction': 0.4697121165498685}]
function_evaluation time 0.374484 value -0.945724 suggestion {'alpha': 4.9229771096409145, 'batch_size': 238, 'beta_1': 0.8652838917769092, 'beta_2': 0.9943461553568812, 'epsilon': 5.4977321738453825e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0032809200271519054, 'tol': 0.031174265065041944, 'validation_fraction': 0.4697121165498685}
observation time 0.001413, current best -0.947813 at iter 2
suggestion time taken 0.001779 iter 3 next_points [{'alpha': 0.0005581415210113977, 'batch_size': 126, 'beta_1': 0.6297013916229629, 'beta_2': 0.9992493605473879, 'epsilon': 5.1211411873848405e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0004305195762245251, 'tol': 0.0019521579324625956, 'validation_fraction': 0.5090953523985919}]
function_evaluation time 1.935081 value -0.922084 suggestion {'alpha': 0.0005581415210113977, 'batch_size': 126, 'beta_1': 0.6297013916229629, 'beta_2': 0.9992493605473879, 'epsilon': 5.1211411873848405e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0004305195762245251, 'tol': 0.0019521579324625956, 'validation_fraction': 0.5090953523985919}
observation time 0.001396, current best -0.947813 at iter 3
suggestion time taken 0.001809 iter 4 next_points [{'alpha': 0.005798382584090747, 'batch_size': 214, 'beta_1': 0.9873741693254736, 'beta_2': 0.9999964807437645, 'epsilon': 1.9965645066834885e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.010303385171872199, 'tol': 0.00032778702949890794, 'validation_fraction': 0.40983015953305524}]
function_evaluation time 0.951166 value -0.936677 suggestion {'alpha': 0.005798382584090747, 'batch_size': 214, 'beta_1': 0.9873741693254736, 'beta_2': 0.9999964807437645, 'epsilon': 1.9965645066834885e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.010303385171872199, 'tol': 0.00032778702949890794, 'validation_fraction': 0.40983015953305524}
observation time 0.001451, current best -0.947813 at iter 4
suggestion time taken 0.001802 iter 5 next_points [{'alpha': 0.0008170175790140513, 'batch_size': 192, 'beta_1': 0.906609007758813, 'beta_2': 0.9997482733712112, 'epsilon': 1.2500591457509174e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00026354168382424403, 'tol': 1.6641079494814752e-05, 'validation_fraction': 0.35534151234112354}]
function_evaluation time 2.831186 value -0.947793 suggestion {'alpha': 0.0008170175790140513, 'batch_size': 192, 'beta_1': 0.906609007758813, 'beta_2': 0.9997482733712112, 'epsilon': 1.2500591457509174e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00026354168382424403, 'tol': 1.6641079494814752e-05, 'validation_fraction': 0.35534151234112354}
observation time 0.001392, current best -0.947813 at iter 5
suggestion time taken 0.001773 iter 6 next_points [{'alpha': 0.010836958300414843, 'batch_size': 165, 'beta_1': 0.8263323789392234, 'beta_2': 0.9999864447632886, 'epsilon': 4.6540057743834797e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.023666323491536575, 'tol': 0.00018544643177920224, 'validation_fraction': 0.723215731981653}]
function_evaluation time 0.647270 value -0.922065 suggestion {'alpha': 0.010836958300414843, 'batch_size': 165, 'beta_1': 0.8263323789392234, 'beta_2': 0.9999864447632886, 'epsilon': 4.6540057743834797e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.023666323491536575, 'tol': 0.00018544643177920224, 'validation_fraction': 0.723215731981653}
observation time 0.001470, current best -0.947813 at iter 6
suggestion time taken 0.001735 iter 7 next_points [{'alpha': 1.6607520307242927e-05, 'batch_size': 86, 'beta_1': 0.7396563514678538, 'beta_2': 0.999998451053957, 'epsilon': 1.4139762900554947e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 1.1070375339672636e-05, 'tol': 0.000688759907144649, 'validation_fraction': 0.5551598274667787}]
function_evaluation time 3.506968 value -0.385637 suggestion {'alpha': 1.6607520307242927e-05, 'batch_size': 86, 'beta_1': 0.7396563514678538, 'beta_2': 0.999998451053957, 'epsilon': 1.4139762900554947e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 1.1070375339672636e-05, 'tol': 0.000688759907144649, 'validation_fraction': 0.5551598274667787}
observation time 0.001354, current best -0.947813 at iter 7
suggestion time taken 0.001776 iter 8 next_points [{'alpha': 4.7224981550231e-05, 'batch_size': 41, 'beta_1': 0.6141569003033237, 'beta_2': 0.9860863974005054, 'epsilon': 8.686585271963124e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 2.3852939454093872e-05, 'tol': 0.07677970081742, 'validation_fraction': 0.8188589429998367}]
function_evaluation time 0.313282 value -0.137776 suggestion {'alpha': 4.7224981550231e-05, 'batch_size': 41, 'beta_1': 0.6141569003033237, 'beta_2': 0.9860863974005054, 'epsilon': 8.686585271963124e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 2.3852939454093872e-05, 'tol': 0.07677970081742, 'validation_fraction': 0.8188589429998367}
observation time 0.001475, current best -0.947813 at iter 8
suggestion time taken 0.001734 iter 9 next_points [{'alpha': 0.14896918913386548, 'batch_size': 91, 'beta_1': 0.7927669512331674, 'beta_2': 0.9970783944542505, 'epsilon': 1.0144586508704441e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.000667650048023734, 'tol': 4.0991554842278934e-05, 'validation_fraction': 0.301458493008449}]
function_evaluation time 2.077614 value -0.957532 suggestion {'alpha': 0.14896918913386548, 'batch_size': 91, 'beta_1': 0.7927669512331674, 'beta_2': 0.9970783944542505, 'epsilon': 1.0144586508704441e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.000667650048023734, 'tol': 4.0991554842278934e-05, 'validation_fraction': 0.301458493008449}
observation time 0.001447, current best -0.957532 at iter 9
suggestion time taken 0.001762 iter 10 next_points [{'alpha': 0.00021130851392524863, 'batch_size': 101, 'beta_1': 0.8765838850733176, 'beta_2': 0.9609411001700738, 'epsilon': 4.891370284906623e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.007596357309475979, 'tol': 1.0739467036710624e-05, 'validation_fraction': 0.14613965337264512}]
function_evaluation time 0.796427 value -0.967293 suggestion {'alpha': 0.00021130851392524863, 'batch_size': 101, 'beta_1': 0.8765838850733176, 'beta_2': 0.9609411001700738, 'epsilon': 4.891370284906623e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.007596357309475979, 'tol': 1.0739467036710624e-05, 'validation_fraction': 0.14613965337264512}
observation time 0.001406, current best -0.967293 at iter 10
suggestion time taken 0.001748 iter 11 next_points [{'alpha': 0.03310045661926329, 'batch_size': 16, 'beta_1': 0.9786580934841362, 'beta_2': 0.9984737054502837, 'epsilon': 2.143021202822653e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.018705837661661385, 'tol': 0.008565151910089393, 'validation_fraction': 0.7775369650270363}]
function_evaluation time 0.614553 value -0.915106 suggestion {'alpha': 0.03310045661926329, 'batch_size': 16, 'beta_1': 0.9786580934841362, 'beta_2': 0.9984737054502837, 'epsilon': 2.143021202822653e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.018705837661661385, 'tol': 0.008565151910089393, 'validation_fraction': 0.7775369650270363}
observation time 0.001400, current best -0.967293 at iter 11
suggestion time taken 0.001751 iter 12 next_points [{'alpha': 0.30378656032240126, 'batch_size': 56, 'beta_1': 0.9277703334494878, 'beta_2': 0.9999974449840534, 'epsilon': 7.928033418704311e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0017010808419121236, 'tol': 0.0008632359862180243, 'validation_fraction': 0.2238416628019944}]
function_evaluation time 1.791052 value -0.965902 suggestion {'alpha': 0.30378656032240126, 'batch_size': 56, 'beta_1': 0.9277703334494878, 'beta_2': 0.9999974449840534, 'epsilon': 7.928033418704311e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0017010808419121236, 'tol': 0.0008632359862180243, 'validation_fraction': 0.2238416628019944}
observation time 0.001556, current best -0.967293 at iter 12
suggestion time taken 0.001797 iter 13 next_points [{'alpha': 1.6218635025886883, 'batch_size': 225, 'beta_1': 0.9635767166127536, 'beta_2': 0.9999903682537653, 'epsilon': 6.186225635520003e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.004551758828071495, 'tol': 0.057036429069509544, 'validation_fraction': 0.8908508186588815}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.252435 value -0.838572 suggestion {'alpha': 1.6218635025886883, 'batch_size': 225, 'beta_1': 0.9635767166127536, 'beta_2': 0.9999903682537653, 'epsilon': 6.186225635520003e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.004551758828071495, 'tol': 0.057036429069509544, 'validation_fraction': 0.8908508186588815}
observation time 0.001392, current best -0.967293 at iter 13
suggestion time taken 0.001753 iter 14 next_points [{'alpha': 0.00014924490042896087, 'batch_size': 63, 'beta_1': 0.9438712558631628, 'beta_2': 0.9999279654286847, 'epsilon': 1.7080934334586407e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 6.722356731092257e-05, 'tol': 5.597051885662791e-05, 'validation_fraction': 0.87474844534004}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.065472 value -0.186658 suggestion {'alpha': 0.00014924490042896087, 'batch_size': 63, 'beta_1': 0.9438712558631628, 'beta_2': 0.9999279654286847, 'epsilon': 1.7080934334586407e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 6.722356731092257e-05, 'tol': 5.597051885662791e-05, 'validation_fraction': 0.87474844534004}
observation time 0.001393, current best -0.967293 at iter 14
saving meta data: {'args': {'--uuid': '01b3911389de5e16b6a3c2cbd94de76a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
