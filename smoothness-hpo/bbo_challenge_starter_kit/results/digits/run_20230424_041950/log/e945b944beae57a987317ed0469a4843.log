running: {'--uuid': 'e945b944beae57a987317ed0469a4843', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u e945b944beae57a987317ed0469a4843 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002319 iter 0 next_points [{'alpha': 5.721845974064999, 'batch_size': 125, 'beta_1': 0.9871989584001323, 'beta_2': 0.9733723295093055, 'epsilon': 1.0460200556351471e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.046812978029208634, 'tol': 0.009399321367618601, 'validation_fraction': 0.43638047911296185}]
function_evaluation time 0.705300 value 0.551778 suggestion {'alpha': 5.721845974064999, 'batch_size': 125, 'beta_1': 0.9871989584001323, 'beta_2': 0.9733723295093055, 'epsilon': 1.0460200556351471e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.046812978029208634, 'tol': 0.009399321367618601, 'validation_fraction': 0.43638047911296185}
observation time 0.000066, current best 0.551778 at iter 0
suggestion time taken 0.002562 iter 1 next_points [{'alpha': 0.002043706499963061, 'batch_size': 231, 'beta_1': 0.7548083763116838, 'beta_2': 0.9995116753018436, 'epsilon': 3.026596253978038e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.003712272944141724, 'tol': 0.06382282918957403, 'validation_fraction': 0.45872502704924495}]
function_evaluation time 0.329819 value 0.211529 suggestion {'alpha': 0.002043706499963061, 'batch_size': 231, 'beta_1': 0.7548083763116838, 'beta_2': 0.9995116753018436, 'epsilon': 3.026596253978038e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.003712272944141724, 'tol': 0.06382282918957403, 'validation_fraction': 0.45872502704924495}
observation time 0.000066, current best 0.211529 at iter 1
suggestion time taken 0.002294 iter 2 next_points [{'alpha': 0.00484548055143718, 'batch_size': 242, 'beta_1': 0.7781131234772289, 'beta_2': 0.9854911336830866, 'epsilon': 9.446718567973251e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.005470844960512612, 'tol': 0.01802872759471321, 'validation_fraction': 0.18317899996483133}]
function_evaluation time 0.471625 value 0.135621 suggestion {'alpha': 0.00484548055143718, 'batch_size': 242, 'beta_1': 0.7781131234772289, 'beta_2': 0.9854911336830866, 'epsilon': 9.446718567973251e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.005470844960512612, 'tol': 0.01802872759471321, 'validation_fraction': 0.18317899996483133}
observation time 0.000065, current best 0.135621 at iter 2
suggestion time taken 0.002334 iter 3 next_points [{'alpha': 0.002490699023735698, 'batch_size': 33, 'beta_1': 0.8142120104840141, 'beta_2': 0.9130704092431341, 'epsilon': 3.883847313434065e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0240542165007057, 'tol': 0.002660541892504464, 'validation_fraction': 0.1736071274671852}]
function_evaluation time 1.891883 value 0.405794 suggestion {'alpha': 0.002490699023735698, 'batch_size': 33, 'beta_1': 0.8142120104840141, 'beta_2': 0.9130704092431341, 'epsilon': 3.883847313434065e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0240542165007057, 'tol': 0.002660541892504464, 'validation_fraction': 0.1736071274671852}
observation time 0.000064, current best 0.135621 at iter 3
suggestion time taken 0.002113 iter 4 next_points [{'alpha': 0.001658874178920098, 'batch_size': 20, 'beta_1': 0.7438610571669778, 'beta_2': 0.902173900458262, 'epsilon': 2.8715740727005057e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 3.894875686691151e-05, 'tol': 2.5808913656591835e-05, 'validation_fraction': 0.39271051359109044}]
function_evaluation time 8.960331 value 0.227409 suggestion {'alpha': 0.001658874178920098, 'batch_size': 20, 'beta_1': 0.7438610571669778, 'beta_2': 0.902173900458262, 'epsilon': 2.8715740727005057e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 3.894875686691151e-05, 'tol': 2.5808913656591835e-05, 'validation_fraction': 0.39271051359109044}
observation time 0.000066, current best 0.135621 at iter 4
suggestion time taken 0.002310 iter 5 next_points [{'alpha': 8.014304619563961e-05, 'batch_size': 64, 'beta_1': 0.615462557235234, 'beta_2': 0.9061404144542892, 'epsilon': 1.2351125022980177e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 1.1017549508940534e-05, 'tol': 0.008353187921859007, 'validation_fraction': 0.22908962246193373}]
function_evaluation time 0.634326 value 9.300985 suggestion {'alpha': 8.014304619563961e-05, 'batch_size': 64, 'beta_1': 0.615462557235234, 'beta_2': 0.9061404144542892, 'epsilon': 1.2351125022980177e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 1.1017549508940534e-05, 'tol': 0.008353187921859007, 'validation_fraction': 0.22908962246193373}
observation time 0.000068, current best 0.135621 at iter 5
suggestion time taken 0.002123 iter 6 next_points [{'alpha': 6.999775309634271e-05, 'batch_size': 169, 'beta_1': 0.5412444406886934, 'beta_2': 0.913367771934972, 'epsilon': 1.0776198905485991e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0008181914491566701, 'tol': 0.0013255908390713874, 'validation_fraction': 0.23547893848909082}]
function_evaluation time 1.576425 value 0.103241 suggestion {'alpha': 6.999775309634271e-05, 'batch_size': 169, 'beta_1': 0.5412444406886934, 'beta_2': 0.913367771934972, 'epsilon': 1.0776198905485991e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0008181914491566701, 'tol': 0.0013255908390713874, 'validation_fraction': 0.23547893848909082}
observation time 0.000067, current best 0.103241 at iter 6
suggestion time taken 0.002194 iter 7 next_points [{'alpha': 0.0012054722178854893, 'batch_size': 212, 'beta_1': 0.9315899510448209, 'beta_2': 0.918933151046773, 'epsilon': 3.658028336649353e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 6.276489643761037e-05, 'tol': 0.0008817660352996736, 'validation_fraction': 0.37251528144783397}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.701065 value 0.236501 suggestion {'alpha': 0.0012054722178854893, 'batch_size': 212, 'beta_1': 0.9315899510448209, 'beta_2': 0.918933151046773, 'epsilon': 3.658028336649353e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 6.276489643761037e-05, 'tol': 0.0008817660352996736, 'validation_fraction': 0.37251528144783397}
observation time 0.000065, current best 0.103241 at iter 7
suggestion time taken 0.002102 iter 8 next_points [{'alpha': 1.4918854611960037, 'batch_size': 123, 'beta_1': 0.6685878162978073, 'beta_2': 0.9116842392982937, 'epsilon': 6.629328186181907e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0008453396479971408, 'tol': 0.011418753229974122, 'validation_fraction': 0.17523901780445608}]
function_evaluation time 0.783054 value 0.125035 suggestion {'alpha': 1.4918854611960037, 'batch_size': 123, 'beta_1': 0.6685878162978073, 'beta_2': 0.9116842392982937, 'epsilon': 6.629328186181907e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0008453396479971408, 'tol': 0.011418753229974122, 'validation_fraction': 0.17523901780445608}
observation time 0.000068, current best 0.103241 at iter 8
suggestion time taken 0.002100 iter 9 next_points [{'alpha': 0.586829223313398, 'batch_size': 242, 'beta_1': 0.7192419522554776, 'beta_2': 0.9980768807726212, 'epsilon': 2.0266276504395218e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.004867163787734155, 'tol': 0.0018194059966599636, 'validation_fraction': 0.332926594838296}]
function_evaluation time 1.110997 value 0.129882 suggestion {'alpha': 0.586829223313398, 'batch_size': 242, 'beta_1': 0.7192419522554776, 'beta_2': 0.9980768807726212, 'epsilon': 2.0266276504395218e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.004867163787734155, 'tol': 0.0018194059966599636, 'validation_fraction': 0.332926594838296}
observation time 0.000074, current best 0.103241 at iter 9
suggestion time taken 0.002167 iter 10 next_points [{'alpha': 0.0002451084361841554, 'batch_size': 206, 'beta_1': 0.7003088778018287, 'beta_2': 0.987364498592342, 'epsilon': 2.8571288907262093e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 2.1809116872659378e-05, 'tol': 1.7202823722395878e-05, 'validation_fraction': 0.3088496348660215}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.437526 value 4.244639 suggestion {'alpha': 0.0002451084361841554, 'batch_size': 206, 'beta_1': 0.7003088778018287, 'beta_2': 0.987364498592342, 'epsilon': 2.8571288907262093e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 2.1809116872659378e-05, 'tol': 1.7202823722395878e-05, 'validation_fraction': 0.3088496348660215}
observation time 0.000061, current best 0.103241 at iter 10
suggestion time taken 0.002075 iter 11 next_points [{'alpha': 0.021861881710303992, 'batch_size': 35, 'beta_1': 0.6550862544999109, 'beta_2': 0.9782910552965048, 'epsilon': 3.154716449404286e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.003660493391450649, 'tol': 0.0011101388821477807, 'validation_fraction': 0.7007411005436852}]
function_evaluation time 1.368532 value 0.185031 suggestion {'alpha': 0.021861881710303992, 'batch_size': 35, 'beta_1': 0.6550862544999109, 'beta_2': 0.9782910552965048, 'epsilon': 3.154716449404286e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.003660493391450649, 'tol': 0.0011101388821477807, 'validation_fraction': 0.7007411005436852}
observation time 0.000072, current best 0.103241 at iter 11
suggestion time taken 0.002104 iter 12 next_points [{'alpha': 0.009145580643398729, 'batch_size': 212, 'beta_1': 0.9354362581225883, 'beta_2': 0.9580382166017319, 'epsilon': 6.834486802870678e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 1.472432007986887e-05, 'tol': 1.697710037932497e-05, 'validation_fraction': 0.12517323283514076}]
function_evaluation time 0.452539 value 9.820481 suggestion {'alpha': 0.009145580643398729, 'batch_size': 212, 'beta_1': 0.9354362581225883, 'beta_2': 0.9580382166017319, 'epsilon': 6.834486802870678e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 1.472432007986887e-05, 'tol': 1.697710037932497e-05, 'validation_fraction': 0.12517323283514076}
observation time 0.000075, current best 0.103241 at iter 12
suggestion time taken 0.002184 iter 13 next_points [{'alpha': 0.004039854105261082, 'batch_size': 199, 'beta_1': 0.7955910024696362, 'beta_2': 0.9744074048631626, 'epsilon': 1.0859477249667923e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.4566912043381992e-05, 'tol': 0.003145526987550255, 'validation_fraction': 0.39418360269227737}]
function_evaluation time 0.245873 value 10.581456 suggestion {'alpha': 0.004039854105261082, 'batch_size': 199, 'beta_1': 0.7955910024696362, 'beta_2': 0.9744074048631626, 'epsilon': 1.0859477249667923e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.4566912043381992e-05, 'tol': 0.003145526987550255, 'validation_fraction': 0.39418360269227737}
observation time 0.000070, current best 0.103241 at iter 13
suggestion time taken 0.002097 iter 14 next_points [{'alpha': 1.6057888924091843, 'batch_size': 249, 'beta_1': 0.5582603553062262, 'beta_2': 0.9065914922493568, 'epsilon': 1.9896110933615886e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0005421677932283293, 'tol': 0.0011696679471304022, 'validation_fraction': 0.17665628052783938}]
function_evaluation time 1.508876 value 0.114039 suggestion {'alpha': 1.6057888924091843, 'batch_size': 249, 'beta_1': 0.5582603553062262, 'beta_2': 0.9065914922493568, 'epsilon': 1.9896110933615886e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0005421677932283293, 'tol': 0.0011696679471304022, 'validation_fraction': 0.17665628052783938}
observation time 0.000072, current best 0.103241 at iter 14
saving meta data: {'args': {'--uuid': 'e945b944beae57a987317ed0469a4843', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
