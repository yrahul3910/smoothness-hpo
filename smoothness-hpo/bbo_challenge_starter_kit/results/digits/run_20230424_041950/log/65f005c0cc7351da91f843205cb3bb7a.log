running: {'--uuid': '65f005c0cc7351da91f843205cb3bb7a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 65f005c0cc7351da91f843205cb3bb7a -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002392 iter 0 next_points [{'alpha': 0.25325297613768105, 'batch_size': 94, 'beta_1': 0.550722591169767, 'beta_2': 0.9607919549469325, 'epsilon': 2.1764843115570045e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0007002714741870375, 'tol': 1.3186245093417298e-05, 'validation_fraction': 0.5154816446284624}]
function_evaluation time 2.024375 value -0.964523 suggestion {'alpha': 0.25325297613768105, 'batch_size': 94, 'beta_1': 0.550722591169767, 'beta_2': 0.9607919549469325, 'epsilon': 2.1764843115570045e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0007002714741870375, 'tol': 1.3186245093417298e-05, 'validation_fraction': 0.5154816446284624}
observation time 0.000076, current best -0.964523 at iter 0
suggestion time taken 0.002396 iter 1 next_points [{'alpha': 0.007946178724317667, 'batch_size': 50, 'beta_1': 0.9366226262882082, 'beta_2': 0.9462539629922948, 'epsilon': 3.564920745793947e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 1.382720757141773e-05, 'tol': 0.07196247587280001, 'validation_fraction': 0.33679052490071576}]
function_evaluation time 0.543602 value -0.144040 suggestion {'alpha': 0.007946178724317667, 'batch_size': 50, 'beta_1': 0.9366226262882082, 'beta_2': 0.9462539629922948, 'epsilon': 3.564920745793947e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 1.382720757141773e-05, 'tol': 0.07196247587280001, 'validation_fraction': 0.33679052490071576}
observation time 0.000072, current best -0.964523 at iter 1
suggestion time taken 0.002134 iter 2 next_points [{'alpha': 0.04407614508374168, 'batch_size': 96, 'beta_1': 0.969322026457153, 'beta_2': 0.9265228178702328, 'epsilon': 3.131503329610886e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.9736713226247364e-05, 'tol': 0.0023566932117389254, 'validation_fraction': 0.24551773925341447}]
function_evaluation time 3.527178 value -0.576428 suggestion {'alpha': 0.04407614508374168, 'batch_size': 96, 'beta_1': 0.969322026457153, 'beta_2': 0.9265228178702328, 'epsilon': 3.131503329610886e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.9736713226247364e-05, 'tol': 0.0023566932117389254, 'validation_fraction': 0.24551773925341447}
observation time 0.000072, current best -0.964523 at iter 2
suggestion time taken 0.002162 iter 3 next_points [{'alpha': 3.04354860089224, 'batch_size': 225, 'beta_1': 0.7143426660962343, 'beta_2': 0.9156939089522843, 'epsilon': 1.8026338199144157e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.04063792621920807, 'tol': 0.006995470920504673, 'validation_fraction': 0.8051523438602962}]
function_evaluation time 0.519065 value -0.913732 suggestion {'alpha': 3.04354860089224, 'batch_size': 225, 'beta_1': 0.7143426660962343, 'beta_2': 0.9156939089522843, 'epsilon': 1.8026338199144157e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.04063792621920807, 'tol': 0.006995470920504673, 'validation_fraction': 0.8051523438602962}
observation time 0.000071, current best -0.964523 at iter 3
suggestion time taken 0.002220 iter 4 next_points [{'alpha': 0.0005058901508532014, 'batch_size': 182, 'beta_1': 0.5105385173303092, 'beta_2': 0.9568321224664126, 'epsilon': 1.1895756715906221e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0004891773197934459, 'tol': 1.594276897659504e-05, 'validation_fraction': 0.819414821263754}]
function_evaluation time 1.818299 value -0.904668 suggestion {'alpha': 0.0005058901508532014, 'batch_size': 182, 'beta_1': 0.5105385173303092, 'beta_2': 0.9568321224664126, 'epsilon': 1.1895756715906221e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0004891773197934459, 'tol': 1.594276897659504e-05, 'validation_fraction': 0.819414821263754}
observation time 0.000069, current best -0.964523 at iter 4
suggestion time taken 0.002346 iter 5 next_points [{'alpha': 0.007717428336588492, 'batch_size': 197, 'beta_1': 0.614192138834467, 'beta_2': 0.9554134216098932, 'epsilon': 1.066345740358503e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 3.0281496219647753e-05, 'tol': 8.582598143513474e-05, 'validation_fraction': 0.1600699780410318}]
function_evaluation time 2.131563 value -0.278479 suggestion {'alpha': 0.007717428336588492, 'batch_size': 197, 'beta_1': 0.614192138834467, 'beta_2': 0.9554134216098932, 'epsilon': 1.066345740358503e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 3.0281496219647753e-05, 'tol': 8.582598143513474e-05, 'validation_fraction': 0.1600699780410318}
observation time 0.000071, current best -0.964523 at iter 5
suggestion time taken 0.002161 iter 6 next_points [{'alpha': 0.10269276155133683, 'batch_size': 169, 'beta_1': 0.6470409485734302, 'beta_2': 0.9269066933169979, 'epsilon': 2.6813306406089876e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 8.459005501509532e-05, 'tol': 0.02759133815447767, 'validation_fraction': 0.45363948188668657}]
function_evaluation time 0.341911 value -0.205197 suggestion {'alpha': 0.10269276155133683, 'batch_size': 169, 'beta_1': 0.6470409485734302, 'beta_2': 0.9269066933169979, 'epsilon': 2.6813306406089876e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 8.459005501509532e-05, 'tol': 0.02759133815447767, 'validation_fraction': 0.45363948188668657}
observation time 0.000071, current best -0.964523 at iter 6
suggestion time taken 0.002237 iter 7 next_points [{'alpha': 0.04937030813626703, 'batch_size': 227, 'beta_1': 0.5108592099096091, 'beta_2': 0.9731060962412247, 'epsilon': 1.4965558579052966e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.397049155365177e-05, 'tol': 0.016644138050870942, 'validation_fraction': 0.4369773926517504}]
function_evaluation time 0.323423 value -0.107143 suggestion {'alpha': 0.04937030813626703, 'batch_size': 227, 'beta_1': 0.5108592099096091, 'beta_2': 0.9731060962412247, 'epsilon': 1.4965558579052966e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.397049155365177e-05, 'tol': 0.016644138050870942, 'validation_fraction': 0.4369773926517504}
observation time 0.000069, current best -0.964523 at iter 7
suggestion time taken 0.002146 iter 8 next_points [{'alpha': 1.2939170943732413e-05, 'batch_size': 55, 'beta_1': 0.7808020921670084, 'beta_2': 0.9113906093925922, 'epsilon': 2.1792546399528017e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.005092271051858138, 'tol': 0.00011199614308806843, 'validation_fraction': 0.12394175964971417}]
function_evaluation time 1.299045 value -0.957564 suggestion {'alpha': 1.2939170943732413e-05, 'batch_size': 55, 'beta_1': 0.7808020921670084, 'beta_2': 0.9113906093925922, 'epsilon': 2.1792546399528017e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.005092271051858138, 'tol': 0.00011199614308806843, 'validation_fraction': 0.12394175964971417}
observation time 0.000063, current best -0.964523 at iter 8
suggestion time taken 0.002327 iter 9 next_points [{'alpha': 5.492879135794305, 'batch_size': 157, 'beta_1': 0.5590648188325256, 'beta_2': 0.9965013378037572, 'epsilon': 1.879060766672415e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.01476392666328297, 'tol': 0.019493415129362746, 'validation_fraction': 0.1866224124605602}]
function_evaluation time 0.376603 value -0.949903 suggestion {'alpha': 5.492879135794305, 'batch_size': 157, 'beta_1': 0.5590648188325256, 'beta_2': 0.9965013378037572, 'epsilon': 1.879060766672415e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.01476392666328297, 'tol': 0.019493415129362746, 'validation_fraction': 0.1866224124605602}
observation time 0.000072, current best -0.964523 at iter 9
suggestion time taken 0.002157 iter 10 next_points [{'alpha': 1.1034220969026449e-05, 'batch_size': 239, 'beta_1': 0.9400924138497389, 'beta_2': 0.9608654883875479, 'epsilon': 9.586242472453733e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 2.3874208759922867e-05, 'tol': 0.004581688851956445, 'validation_fraction': 0.22845130242079664}]
function_evaluation time 0.309606 value -0.085572 suggestion {'alpha': 1.1034220969026449e-05, 'batch_size': 239, 'beta_1': 0.9400924138497389, 'beta_2': 0.9608654883875479, 'epsilon': 9.586242472453733e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 2.3874208759922867e-05, 'tol': 0.004581688851956445, 'validation_fraction': 0.22845130242079664}
observation time 0.000074, current best -0.964523 at iter 10
suggestion time taken 0.002153 iter 11 next_points [{'alpha': 0.014440566337670973, 'batch_size': 96, 'beta_1': 0.8143894640921376, 'beta_2': 0.9217320996926873, 'epsilon': 3.8006796479792517e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.004969805118718607, 'tol': 1.467378573717752e-05, 'validation_fraction': 0.1375328536272094}]
function_evaluation time 1.077541 value -0.967995 suggestion {'alpha': 0.014440566337670973, 'batch_size': 96, 'beta_1': 0.8143894640921376, 'beta_2': 0.9217320996926873, 'epsilon': 3.8006796479792517e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.004969805118718607, 'tol': 1.467378573717752e-05, 'validation_fraction': 0.1375328536272094}
observation time 0.000073, current best -0.967995 at iter 11
suggestion time taken 0.002187 iter 12 next_points [{'alpha': 0.08609597878415545, 'batch_size': 118, 'beta_1': 0.6282988139290039, 'beta_2': 0.9325796320513982, 'epsilon': 4.1131151173447897e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.04756198553123238, 'tol': 0.0016981160386630523, 'validation_fraction': 0.17514316014947637}]
function_evaluation time 0.996444 value -0.937345 suggestion {'alpha': 0.08609597878415545, 'batch_size': 118, 'beta_1': 0.6282988139290039, 'beta_2': 0.9325796320513982, 'epsilon': 4.1131151173447897e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.04756198553123238, 'tol': 0.0016981160386630523, 'validation_fraction': 0.17514316014947637}
observation time 0.000072, current best -0.967995 at iter 12
suggestion time taken 0.002180 iter 13 next_points [{'alpha': 0.0005735507251946084, 'batch_size': 138, 'beta_1': 0.5195681688296658, 'beta_2': 0.9009814977630969, 'epsilon': 1.765966528377413e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0010993219329748704, 'tol': 0.07826954978224225, 'validation_fraction': 0.36157447176619706}]
function_evaluation time 0.504346 value -0.953385 suggestion {'alpha': 0.0005735507251946084, 'batch_size': 138, 'beta_1': 0.5195681688296658, 'beta_2': 0.9009814977630969, 'epsilon': 1.765966528377413e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0010993219329748704, 'tol': 0.07826954978224225, 'validation_fraction': 0.36157447176619706}
observation time 0.000074, current best -0.967995 at iter 13
suggestion time taken 0.002142 iter 14 next_points [{'alpha': 0.009942016512808575, 'batch_size': 71, 'beta_1': 0.5526297168564838, 'beta_2': 0.9712011046158355, 'epsilon': 6.102195550782328e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.004804595486245303, 'tol': 0.014147904232641187, 'validation_fraction': 0.24063615295822768}]
function_evaluation time 0.901868 value -0.976331 suggestion {'alpha': 0.009942016512808575, 'batch_size': 71, 'beta_1': 0.5526297168564838, 'beta_2': 0.9712011046158355, 'epsilon': 6.102195550782328e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.004804595486245303, 'tol': 0.014147904232641187, 'validation_fraction': 0.24063615295822768}
observation time 0.000077, current best -0.976331 at iter 14
saving meta data: {'args': {'--uuid': '65f005c0cc7351da91f843205cb3bb7a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
