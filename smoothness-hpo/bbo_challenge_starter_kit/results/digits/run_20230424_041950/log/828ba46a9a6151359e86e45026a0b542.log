running: {'--uuid': '828ba46a9a6151359e86e45026a0b542', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 828ba46a9a6151359e86e45026a0b542 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002089 iter 0 next_points [{'alpha': 3.634322358991859e-05, 'batch_size': 28, 'beta_1': 0.9571965767475817, 'beta_2': 0.9987986176633284, 'epsilon': 1.8419858314688393e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0006550942369001823, 'tol': 0.044879377298472425, 'validation_fraction': 0.8104727167015637}]
function_evaluation time 0.438901 value -0.855270 suggestion {'alpha': 3.634322358991859e-05, 'batch_size': 28, 'beta_1': 0.9571965767475817, 'beta_2': 0.9987986176633284, 'epsilon': 1.8419858314688393e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0006550942369001823, 'tol': 0.044879377298472425, 'validation_fraction': 0.8104727167015637}
observation time 0.001420, current best -0.855270 at iter 0
suggestion time taken 0.001765 iter 1 next_points [{'alpha': 0.053309982701360344, 'batch_size': 76, 'beta_1': 0.9267838313703993, 'beta_2': 0.9999879063368641, 'epsilon': 1.3306469862416292e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0011572687256100323, 'tol': 0.0012850077188480556, 'validation_fraction': 0.21871216743235736}]
function_evaluation time 1.794156 value -0.963809 suggestion {'alpha': 0.053309982701360344, 'batch_size': 76, 'beta_1': 0.9267838313703993, 'beta_2': 0.9999879063368641, 'epsilon': 1.3306469862416292e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0011572687256100323, 'tol': 0.0012850077188480556, 'validation_fraction': 0.21871216743235736}
observation time 0.001375, current best -0.963809 at iter 1
suggestion time taken 0.001767 iter 2 next_points [{'alpha': 0.0036321398103429116, 'batch_size': 244, 'beta_1': 0.6129265472171168, 'beta_2': 0.9132624447532393, 'epsilon': 1.9332566023614048e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 2.1179458676871548e-05, 'tol': 0.02251400021299136, 'validation_fraction': 0.12229358912306595}]
function_evaluation time 0.330917 value -0.071651 suggestion {'alpha': 0.0036321398103429116, 'batch_size': 244, 'beta_1': 0.6129265472171168, 'beta_2': 0.9132624447532393, 'epsilon': 1.9332566023614048e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 2.1179458676871548e-05, 'tol': 0.02251400021299136, 'validation_fraction': 0.12229358912306595}
observation time 0.001359, current best -0.963809 at iter 2
suggestion time taken 0.001760 iter 3 next_points [{'alpha': 7.795470884721198, 'batch_size': 169, 'beta_1': 0.8083027235641079, 'beta_2': 0.9960052625653141, 'epsilon': 1.0282204709382718e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.307770318471323e-05, 'tol': 0.0001193132318763064, 'validation_fraction': 0.6409662435314631}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.075624 value -0.517586 suggestion {'alpha': 7.795470884721198, 'batch_size': 169, 'beta_1': 0.8083027235641079, 'beta_2': 0.9960052625653141, 'epsilon': 1.0282204709382718e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.307770318471323e-05, 'tol': 0.0001193132318763064, 'validation_fraction': 0.6409662435314631}
observation time 0.001363, current best -0.963809 at iter 3
suggestion time taken 0.001781 iter 4 next_points [{'alpha': 0.7981910771854175, 'batch_size': 116, 'beta_1': 0.8141700332634513, 'beta_2': 0.9845941270616393, 'epsilon': 2.620159030148862e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0033119759083295613, 'tol': 9.797778166216086e-05, 'validation_fraction': 0.14582178389866018}]
function_evaluation time 0.808031 value -0.957542 suggestion {'alpha': 0.7981910771854175, 'batch_size': 116, 'beta_1': 0.8141700332634513, 'beta_2': 0.9845941270616393, 'epsilon': 2.620159030148862e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0033119759083295613, 'tol': 9.797778166216086e-05, 'validation_fraction': 0.14582178389866018}
observation time 0.001426, current best -0.963809 at iter 4
suggestion time taken 0.001918 iter 5 next_points [{'alpha': 0.40414459097948247, 'batch_size': 126, 'beta_1': 0.7450305917144452, 'beta_2': 0.9999984295535914, 'epsilon': 9.91054773115769e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 7.775209895186266e-05, 'tol': 0.0005767600480572096, 'validation_fraction': 0.5764782181432874}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.648227 value -0.722128 suggestion {'alpha': 0.40414459097948247, 'batch_size': 126, 'beta_1': 0.7450305917144452, 'beta_2': 0.9999984295535914, 'epsilon': 9.91054773115769e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 7.775209895186266e-05, 'tol': 0.0005767600480572096, 'validation_fraction': 0.5764782181432874}
observation time 0.001379, current best -0.963809 at iter 5
suggestion time taken 0.002001 iter 6 next_points [{'alpha': 0.13988058253376126, 'batch_size': 210, 'beta_1': 0.9861520133530896, 'beta_2': 0.9999962861241622, 'epsilon': 1.2268393685265368e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.5543253595069887e-05, 'tol': 0.01022753312201644, 'validation_fraction': 0.5885726690967494}]
function_evaluation time 0.287200 value -0.105798 suggestion {'alpha': 0.13988058253376126, 'batch_size': 210, 'beta_1': 0.9861520133530896, 'beta_2': 0.9999962861241622, 'epsilon': 1.2268393685265368e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.5543253595069887e-05, 'tol': 0.01022753312201644, 'validation_fraction': 0.5885726690967494}
observation time 0.001414, current best -0.963809 at iter 6
suggestion time taken 0.001760 iter 7 next_points [{'alpha': 0.0001456070885301951, 'batch_size': 90, 'beta_1': 0.9728764607212705, 'beta_2': 0.9995442644387121, 'epsilon': 8.048302314069041e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0015924928402809312, 'tol': 0.006009456632948661, 'validation_fraction': 0.37497107829754844}]
function_evaluation time 0.797624 value -0.943631 suggestion {'alpha': 0.0001456070885301951, 'batch_size': 90, 'beta_1': 0.9728764607212705, 'beta_2': 0.9995442644387121, 'epsilon': 8.048302314069041e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0015924928402809312, 'tol': 0.006009456632948661, 'validation_fraction': 0.37497107829754844}
observation time 0.001410, current best -0.963809 at iter 7
suggestion time taken 0.001755 iter 8 next_points [{'alpha': 6.812788274027041e-05, 'batch_size': 151, 'beta_1': 0.5494962968916413, 'beta_2': 0.9999559013709579, 'epsilon': 2.9136193163072906e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 5.515278710748491e-05, 'tol': 0.08032613447697341, 'validation_fraction': 0.2592636589847589}]
function_evaluation time 0.426828 value -0.137790 suggestion {'alpha': 6.812788274027041e-05, 'batch_size': 151, 'beta_1': 0.5494962968916413, 'beta_2': 0.9999559013709579, 'epsilon': 2.9136193163072906e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 5.515278710748491e-05, 'tol': 0.08032613447697341, 'validation_fraction': 0.2592636589847589}
observation time 0.001372, current best -0.963809 at iter 8
suggestion time taken 0.001783 iter 9 next_points [{'alpha': 2.8734569128283196, 'batch_size': 64, 'beta_1': 0.6748528886239576, 'beta_2': 0.9996654742208817, 'epsilon': 3.993259404632028e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.005150777150278346, 'tol': 0.0008074097664728609, 'validation_fraction': 0.7563523471403784}]
function_evaluation time 1.105422 value -0.940871 suggestion {'alpha': 2.8734569128283196, 'batch_size': 64, 'beta_1': 0.6748528886239576, 'beta_2': 0.9996654742208817, 'epsilon': 3.993259404632028e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.005150777150278346, 'tol': 0.0008074097664728609, 'validation_fraction': 0.7563523471403784}
observation time 0.001508, current best -0.963809 at iter 9
suggestion time taken 0.001865 iter 10 next_points [{'alpha': 1.936462095490069e-05, 'batch_size': 37, 'beta_1': 0.9154693361129965, 'beta_2': 0.9999904287545345, 'epsilon': 4.91099199752128e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.07847733114566476, 'tol': 0.00044556057154220566, 'validation_fraction': 0.1582535424098137}]
function_evaluation time 1.187603 value -0.461385 suggestion {'alpha': 1.936462095490069e-05, 'batch_size': 37, 'beta_1': 0.9154693361129965, 'beta_2': 0.9999904287545345, 'epsilon': 4.91099199752128e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.07847733114566476, 'tol': 0.00044556057154220566, 'validation_fraction': 0.1582535424098137}
observation time 0.001392, current best -0.963809 at iter 10
suggestion time taken 0.001748 iter 11 next_points [{'alpha': 0.003078785852917005, 'batch_size': 187, 'beta_1': 0.9745835432945279, 'beta_2': 0.9546305846399359, 'epsilon': 4.538499870843104e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0001380416182619419, 'tol': 4.098343462007551e-05, 'validation_fraction': 0.8283758529050241}]
function_evaluation time 1.121115 value -0.435567 suggestion {'alpha': 0.003078785852917005, 'batch_size': 187, 'beta_1': 0.9745835432945279, 'beta_2': 0.9546305846399359, 'epsilon': 4.538499870843104e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0001380416182619419, 'tol': 4.098343462007551e-05, 'validation_fraction': 0.8283758529050241}
observation time 0.001385, current best -0.963809 at iter 11
suggestion time taken 0.001740 iter 12 next_points [{'alpha': 1.2468842815642294, 'batch_size': 58, 'beta_1': 0.9370838828463317, 'beta_2': 0.9746898491644039, 'epsilon': 1.9596667143238676e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.006695472208596855, 'tol': 0.0052248715988265, 'validation_fraction': 0.262890531886304}]
function_evaluation time 0.704534 value -0.961726 suggestion {'alpha': 1.2468842815642294, 'batch_size': 58, 'beta_1': 0.9370838828463317, 'beta_2': 0.9746898491644039, 'epsilon': 1.9596667143238676e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.006695472208596855, 'tol': 0.0052248715988265, 'validation_fraction': 0.262890531886304}
observation time 0.001380, current best -0.963809 at iter 12
suggestion time taken 0.001728 iter 13 next_points [{'alpha': 0.017676055372319362, 'batch_size': 108, 'beta_1': 0.8926977526848318, 'beta_2': 0.997228157597755, 'epsilon': 1.1708310812441765e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.018896494967621687, 'tol': 5.161532394504612e-05, 'validation_fraction': 0.8600553554841754}]
function_evaluation time 0.742665 value -0.910934 suggestion {'alpha': 0.017676055372319362, 'batch_size': 108, 'beta_1': 0.8926977526848318, 'beta_2': 0.997228157597755, 'epsilon': 1.1708310812441765e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.018896494967621687, 'tol': 5.161532394504612e-05, 'validation_fraction': 0.8600553554841754}
observation time 0.001343, current best -0.963809 at iter 13
suggestion time taken 0.001707 iter 14 next_points [{'alpha': 0.0003168924814731032, 'batch_size': 218, 'beta_1': 0.9662521939524652, 'beta_2': 0.9999968288660334, 'epsilon': 5.198037251880459e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.010630379496041044, 'tol': 0.00026733670978287436, 'validation_fraction': 0.4942477402867792}]
function_evaluation time 0.860045 value -0.959647 suggestion {'alpha': 0.0003168924814731032, 'batch_size': 218, 'beta_1': 0.9662521939524652, 'beta_2': 0.9999968288660334, 'epsilon': 5.198037251880459e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.010630379496041044, 'tol': 0.00026733670978287436, 'validation_fraction': 0.4942477402867792}
observation time 0.001376, current best -0.963809 at iter 14
saving meta data: {'args': {'--uuid': '828ba46a9a6151359e86e45026a0b542', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
