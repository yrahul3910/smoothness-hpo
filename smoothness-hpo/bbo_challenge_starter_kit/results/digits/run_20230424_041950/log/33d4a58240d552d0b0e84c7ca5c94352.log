running: {'--uuid': '33d4a58240d552d0b0e84c7ca5c94352', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 33d4a58240d552d0b0e84c7ca5c94352 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 12.108941 iter 0 next_points [{'alpha': 7.757109203452821, 'batch_size': 40, 'beta_1': 0.7052482869665979, 'beta_2': 0.98618742082001, 'epsilon': 1.3741275772695042e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0023767804975228985, 'tol': 0.007096145944776234, 'validation_fraction': 0.39050234420476365}]
function_evaluation time 0.868911 value -0.951984 suggestion {'alpha': 7.757109203452821, 'batch_size': 40, 'beta_1': 0.7052482869665979, 'beta_2': 0.98618742082001, 'epsilon': 1.3741275772695042e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0023767804975228985, 'tol': 0.007096145944776234, 'validation_fraction': 0.39050234420476365}
observation time 0.000007, current best -0.951984 at iter 0
suggestion time taken 11.726640 iter 1 next_points [{'alpha': 0.11460279327917736, 'batch_size': 178, 'beta_1': 0.9765304078558937, 'beta_2': 0.9226613359853613, 'epsilon': 2.577553250679832e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.029774768533833026, 'tol': 0.04813512096429051, 'validation_fraction': 0.825520468953768}]
function_evaluation time 0.230452 value -0.668072 suggestion {'alpha': 0.11460279327917736, 'batch_size': 178, 'beta_1': 0.9765304078558937, 'beta_2': 0.9226613359853613, 'epsilon': 2.577553250679832e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.029774768533833026, 'tol': 0.04813512096429051, 'validation_fraction': 0.825520468953768}
observation time 0.000005, current best -0.951984 at iter 1
suggestion time taken 11.755300 iter 2 next_points [{'alpha': 7.115434834358478e-05, 'batch_size': 71, 'beta_1': 0.8114568242475326, 'beta_2': 0.9884096697535667, 'epsilon': 1.1805456698152887e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.014213302296592033, 'tol': 9.972685965804925e-05, 'validation_fraction': 0.2887732989358316}]
function_evaluation time 0.964772 value -0.960334 suggestion {'alpha': 7.115434834358478e-05, 'batch_size': 71, 'beta_1': 0.8114568242475326, 'beta_2': 0.9884096697535667, 'epsilon': 1.1805456698152887e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.014213302296592033, 'tol': 9.972685965804925e-05, 'validation_fraction': 0.2887732989358316}
observation time 0.000005, current best -0.960334 at iter 2
suggestion time taken 11.999163 iter 3 next_points [{'alpha': 0.0017833306604060394, 'batch_size': 112, 'beta_1': 0.9833058547986275, 'beta_2': 0.9997933061210708, 'epsilon': 3.937857158574352e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.001320080874180624, 'tol': 0.0004920599227161682, 'validation_fraction': 0.801526666802951}]
function_evaluation time 1.182714 value -0.856642 suggestion {'alpha': 0.0017833306604060394, 'batch_size': 112, 'beta_1': 0.9833058547986275, 'beta_2': 0.9997933061210708, 'epsilon': 3.937857158574352e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.001320080874180624, 'tol': 0.0004920599227161682, 'validation_fraction': 0.801526666802951}
observation time 0.000006, current best -0.960334 at iter 3
suggestion time taken 11.630423 iter 4 next_points [{'alpha': 0.9295233365437617, 'batch_size': 81, 'beta_1': 0.8937020914234989, 'beta_2': 0.999994324963166, 'epsilon': 4.018214785443136e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.076489345984178, 'tol': 0.005553942452748781, 'validation_fraction': 0.847014409737826}]
function_evaluation time 0.520712 value -0.794744 suggestion {'alpha': 0.9295233365437617, 'batch_size': 81, 'beta_1': 0.8937020914234989, 'beta_2': 0.999994324963166, 'epsilon': 4.018214785443136e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.076489345984178, 'tol': 0.005553942452748781, 'validation_fraction': 0.847014409737826}
observation time 0.000006, current best -0.960334 at iter 4
suggestion time taken 12.240291 iter 5 next_points [{'alpha': 8.83261454305931e-05, 'batch_size': 85, 'beta_1': 0.6485644977074071, 'beta_2': 0.9999968485705267, 'epsilon': 3.924441928107178e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.01011082604472307, 'tol': 0.0005041384872561773, 'validation_fraction': 0.8080262558526536}]
function_evaluation time 0.742796 value -0.897014 suggestion {'alpha': 8.83261454305931e-05, 'batch_size': 85, 'beta_1': 0.6485644977074071, 'beta_2': 0.9999968485705267, 'epsilon': 3.924441928107178e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.01011082604472307, 'tol': 0.0005041384872561773, 'validation_fraction': 0.8080262558526536}
observation time 0.000005, current best -0.960334 at iter 5
suggestion time taken 11.804405 iter 6 next_points [{'alpha': 2.7055401534693093, 'batch_size': 99, 'beta_1': 0.9768843971446832, 'beta_2': 0.9994681813854734, 'epsilon': 2.341407800147203e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.016361484288201035, 'tol': 0.0450101902416041, 'validation_fraction': 0.184088833716168}]
function_evaluation time 0.426487 value -0.959628 suggestion {'alpha': 2.7055401534693093, 'batch_size': 99, 'beta_1': 0.9768843971446832, 'beta_2': 0.9994681813854734, 'epsilon': 2.341407800147203e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.016361484288201035, 'tol': 0.0450101902416041, 'validation_fraction': 0.184088833716168}
observation time 0.000006, current best -0.960334 at iter 6
suggestion time taken 11.688380 iter 7 next_points [{'alpha': 2.0890707178990702e-05, 'batch_size': 74, 'beta_1': 0.9521802885625641, 'beta_2': 0.9999936305744442, 'epsilon': 1.4824586902177537e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 1.55359790003062e-05, 'tol': 0.024438978227238596, 'validation_fraction': 0.6147881668663402}]
function_evaluation time 0.279674 value -0.088373 suggestion {'alpha': 2.0890707178990702e-05, 'batch_size': 74, 'beta_1': 0.9521802885625641, 'beta_2': 0.9999936305744442, 'epsilon': 1.4824586902177537e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 1.55359790003062e-05, 'tol': 0.024438978227238596, 'validation_fraction': 0.6147881668663402}
observation time 0.000005, current best -0.960334 at iter 7
suggestion time taken 11.634808 iter 8 next_points [{'alpha': 1.2194415292749393e-05, 'batch_size': 125, 'beta_1': 0.5930980030547774, 'beta_2': 0.9999901825461055, 'epsilon': 1.0619648666239052e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0001179193190315219, 'tol': 0.013822340837062064, 'validation_fraction': 0.8509339152280481}]
function_evaluation time 0.165306 value -0.167743 suggestion {'alpha': 1.2194415292749393e-05, 'batch_size': 125, 'beta_1': 0.5930980030547774, 'beta_2': 0.9999901825461055, 'epsilon': 1.0619648666239052e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0001179193190315219, 'tol': 0.013822340837062064, 'validation_fraction': 0.8509339152280481}
observation time 0.000005, current best -0.960334 at iter 8
suggestion time taken 11.825448 iter 9 next_points [{'alpha': 0.2684210450177187, 'batch_size': 72, 'beta_1': 0.6582777517526205, 'beta_2': 0.9999973201032812, 'epsilon': 2.0498615873847636e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 1.4313124514056797e-05, 'tol': 0.0003036510972813363, 'validation_fraction': 0.111286001758104}]
function_evaluation time 1.303944 value -0.184509 suggestion {'alpha': 0.2684210450177187, 'batch_size': 72, 'beta_1': 0.6582777517526205, 'beta_2': 0.9999973201032812, 'epsilon': 2.0498615873847636e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 1.4313124514056797e-05, 'tol': 0.0003036510972813363, 'validation_fraction': 0.111286001758104}
observation time 0.000005, current best -0.960334 at iter 9
suggestion time taken 11.974442 iter 10 next_points [{'alpha': 0.011909785356104515, 'batch_size': 47, 'beta_1': 0.8977588807640289, 'beta_2': 0.9976962593223063, 'epsilon': 1.0857627496368611e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.001323709080032086, 'tol': 1.5051210913898485e-05, 'validation_fraction': 0.5687985676043794}]
function_evaluation time 1.668343 value -0.942238 suggestion {'alpha': 0.011909785356104515, 'batch_size': 47, 'beta_1': 0.8977588807640289, 'beta_2': 0.9976962593223063, 'epsilon': 1.0857627496368611e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.001323709080032086, 'tol': 1.5051210913898485e-05, 'validation_fraction': 0.5687985676043794}
observation time 0.000005, current best -0.960334 at iter 10
suggestion time taken 11.916983 iter 11 next_points [{'alpha': 0.0005220226598100299, 'batch_size': 81, 'beta_1': 0.7463501258684625, 'beta_2': 0.9999697572206937, 'epsilon': 1.1544136761152758e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0005053595857217362, 'tol': 0.029046136097446194, 'validation_fraction': 0.8123629861624216}]
function_evaluation time 0.372545 value -0.567172 suggestion {'alpha': 0.0005220226598100299, 'batch_size': 81, 'beta_1': 0.7463501258684625, 'beta_2': 0.9999697572206937, 'epsilon': 1.1544136761152758e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0005053595857217362, 'tol': 0.029046136097446194, 'validation_fraction': 0.8123629861624216}
observation time 0.000005, current best -0.960334 at iter 11
suggestion time taken 11.824972 iter 12 next_points [{'alpha': 0.1682721579894694, 'batch_size': 92, 'beta_1': 0.9899768749153942, 'beta_2': 0.9170348001520786, 'epsilon': 1.614162815698606e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 3.710723325241519e-05, 'tol': 0.03662879921212623, 'validation_fraction': 0.34518540629609135}]
function_evaluation time 0.365515 value -0.144023 suggestion {'alpha': 0.1682721579894694, 'batch_size': 92, 'beta_1': 0.9899768749153942, 'beta_2': 0.9170348001520786, 'epsilon': 1.614162815698606e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 3.710723325241519e-05, 'tol': 0.03662879921212623, 'validation_fraction': 0.34518540629609135}
observation time 0.000005, current best -0.960334 at iter 12
suggestion time taken 11.937808 iter 13 next_points [{'alpha': 0.007404610596348547, 'batch_size': 76, 'beta_1': 0.95844349876894, 'beta_2': 0.9999865089699523, 'epsilon': 3.809032680910316e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.003047646546946113, 'tol': 0.023036345940193784, 'validation_fraction': 0.23171106686516632}]
function_evaluation time 0.586285 value -0.949901 suggestion {'alpha': 0.007404610596348547, 'batch_size': 76, 'beta_1': 0.95844349876894, 'beta_2': 0.9999865089699523, 'epsilon': 3.809032680910316e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.003047646546946113, 'tol': 0.023036345940193784, 'validation_fraction': 0.23171106686516632}
observation time 0.000005, current best -0.960334 at iter 13
suggestion time taken 11.719750 iter 14 next_points [{'alpha': 0.11905197558956766, 'batch_size': 124, 'beta_1': 0.9717683165057932, 'beta_2': 0.996726147543475, 'epsilon': 2.105903865609662e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.024715220171072964, 'tol': 0.006695080162025357, 'validation_fraction': 0.5731061589599797}]
function_evaluation time 0.622605 value -0.928327 suggestion {'alpha': 0.11905197558956766, 'batch_size': 124, 'beta_1': 0.9717683165057932, 'beta_2': 0.996726147543475, 'epsilon': 2.105903865609662e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.024715220171072964, 'tol': 0.006695080162025357, 'validation_fraction': 0.5731061589599797}
observation time 0.000006, current best -0.960334 at iter 14
saving meta data: {'args': {'--uuid': '33d4a58240d552d0b0e84c7ca5c94352', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
