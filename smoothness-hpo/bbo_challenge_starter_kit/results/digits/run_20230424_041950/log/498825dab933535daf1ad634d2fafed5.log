running: {'--uuid': '498825dab933535daf1ad634d2fafed5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 498825dab933535daf1ad634d2fafed5 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study random-search MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002497 iter 0 next_points [{'alpha': 0.001741132600662728, 'batch_size': 162, 'beta_1': 0.915632460110313, 'beta_2': 0.999916483873999, 'epsilon': 1.0536125619627043e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0019463896934084298, 'tol': 0.0008704664286866689, 'validation_fraction': 0.22153472188792211}]
function_evaluation time 1.164704 value 0.136823 suggestion {'alpha': 0.001741132600662728, 'batch_size': 162, 'beta_1': 0.915632460110313, 'beta_2': 0.999916483873999, 'epsilon': 1.0536125619627043e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0019463896934084298, 'tol': 0.0008704664286866689, 'validation_fraction': 0.22153472188792211}
observation time 0.000005, current best 0.136823 at iter 0
suggestion time taken 0.002420 iter 1 next_points [{'alpha': 0.06267147130293468, 'batch_size': 182, 'beta_1': 0.9506497891546278, 'beta_2': 0.9998106950932609, 'epsilon': 3.682465312748454e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.05574953185472413, 'tol': 0.0022523394124713187, 'validation_fraction': 0.6621802021283029}]
function_evaluation time 0.678289 value 1.626938 suggestion {'alpha': 0.06267147130293468, 'batch_size': 182, 'beta_1': 0.9506497891546278, 'beta_2': 0.9998106950932609, 'epsilon': 3.682465312748454e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.05574953185472413, 'tol': 0.0022523394124713187, 'validation_fraction': 0.6621802021283029}
observation time 0.000006, current best 0.136823 at iter 1
suggestion time taken 0.002661 iter 2 next_points [{'alpha': 0.03347413033366402, 'batch_size': 98, 'beta_1': 0.9141917819730376, 'beta_2': 0.9998831041787619, 'epsilon': 5.362885261486908e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00957502948235848, 'tol': 0.0001609747046513344, 'validation_fraction': 0.880217901510339}]
function_evaluation time 0.629302 value 0.450788 suggestion {'alpha': 0.03347413033366402, 'batch_size': 98, 'beta_1': 0.9141917819730376, 'beta_2': 0.9998831041787619, 'epsilon': 5.362885261486908e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00957502948235848, 'tol': 0.0001609747046513344, 'validation_fraction': 0.880217901510339}
observation time 0.000005, current best 0.136823 at iter 2
suggestion time taken 0.002418 iter 3 next_points [{'alpha': 0.0004535240205888525, 'batch_size': 39, 'beta_1': 0.9542134659429988, 'beta_2': 0.9996756508496186, 'epsilon': 9.735969955143523e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0002552368823819883, 'tol': 0.00028231092419466776, 'validation_fraction': 0.47720743213636396}]
function_evaluation time 3.065783 value 0.222532 suggestion {'alpha': 0.0004535240205888525, 'batch_size': 39, 'beta_1': 0.9542134659429988, 'beta_2': 0.9996756508496186, 'epsilon': 9.735969955143523e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0002552368823819883, 'tol': 0.00028231092419466776, 'validation_fraction': 0.47720743213636396}
observation time 0.000004, current best 0.136823 at iter 3
suggestion time taken 0.002468 iter 4 next_points [{'alpha': 7.132376134051965e-05, 'batch_size': 82, 'beta_1': 0.9869737279790239, 'beta_2': 0.9182424464925311, 'epsilon': 2.604417574084923e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 5.6555987964673406e-05, 'tol': 0.0008954496251218646, 'validation_fraction': 0.25540772319615745}]
function_evaluation time 3.477224 value 0.245068 suggestion {'alpha': 7.132376134051965e-05, 'batch_size': 82, 'beta_1': 0.9869737279790239, 'beta_2': 0.9182424464925311, 'epsilon': 2.604417574084923e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 5.6555987964673406e-05, 'tol': 0.0008954496251218646, 'validation_fraction': 0.25540772319615745}
observation time 0.000005, current best 0.136823 at iter 4
suggestion time taken 0.002475 iter 5 next_points [{'alpha': 0.0012940850098498646, 'batch_size': 153, 'beta_1': 0.8348393748366788, 'beta_2': 0.9999876747620033, 'epsilon': 2.4776236440206756e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00016904911614424182, 'tol': 0.01407902801453298, 'validation_fraction': 0.6286464021136802}]
function_evaluation time 0.951504 value 0.730241 suggestion {'alpha': 0.0012940850098498646, 'batch_size': 153, 'beta_1': 0.8348393748366788, 'beta_2': 0.9999876747620033, 'epsilon': 2.4776236440206756e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00016904911614424182, 'tol': 0.01407902801453298, 'validation_fraction': 0.6286464021136802}
observation time 0.000006, current best 0.136823 at iter 5
suggestion time taken 0.002438 iter 6 next_points [{'alpha': 4.777233251322753, 'batch_size': 201, 'beta_1': 0.7498611570622401, 'beta_2': 0.9999979142171083, 'epsilon': 1.455049064422569e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.008302453238505406, 'tol': 0.000786137400134091, 'validation_fraction': 0.39365677837246343}]
function_evaluation time 0.793428 value 0.119212 suggestion {'alpha': 4.777233251322753, 'batch_size': 201, 'beta_1': 0.7498611570622401, 'beta_2': 0.9999979142171083, 'epsilon': 1.455049064422569e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.008302453238505406, 'tol': 0.000786137400134091, 'validation_fraction': 0.39365677837246343}
observation time 0.000005, current best 0.119212 at iter 6
suggestion time taken 0.002449 iter 7 next_points [{'alpha': 0.04459385965741548, 'batch_size': 43, 'beta_1': 0.8560927546641601, 'beta_2': 0.9980764765151485, 'epsilon': 1.4600395465988526e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.030752158525603e-05, 'tol': 2.470870535424032e-05, 'validation_fraction': 0.542672497622841}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.937194 value 8.008290 suggestion {'alpha': 0.04459385965741548, 'batch_size': 43, 'beta_1': 0.8560927546641601, 'beta_2': 0.9980764765151485, 'epsilon': 1.4600395465988526e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.030752158525603e-05, 'tol': 2.470870535424032e-05, 'validation_fraction': 0.542672497622841}
observation time 0.000005, current best 0.119212 at iter 7
suggestion time taken 0.002404 iter 8 next_points [{'alpha': 0.3769163732880572, 'batch_size': 109, 'beta_1': 0.8281376325174209, 'beta_2': 0.9999884073028719, 'epsilon': 8.057446288598872e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.07653748211850575, 'tol': 3.881372958180885e-05, 'validation_fraction': 0.4370315152427274}]
function_evaluation time 1.093107 value 0.783853 suggestion {'alpha': 0.3769163732880572, 'batch_size': 109, 'beta_1': 0.8281376325174209, 'beta_2': 0.9999884073028719, 'epsilon': 8.057446288598872e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.07653748211850575, 'tol': 3.881372958180885e-05, 'validation_fraction': 0.4370315152427274}
observation time 0.000005, current best 0.119212 at iter 8
suggestion time taken 0.002449 iter 9 next_points [{'alpha': 5.004749988348909e-05, 'batch_size': 239, 'beta_1': 0.9716149501090647, 'beta_2': 0.9975611753966407, 'epsilon': 9.63691999143471e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0007354306533985226, 'tol': 0.007650516901454851, 'validation_fraction': 0.44358767441256686}]
function_evaluation time 0.897073 value 0.315870 suggestion {'alpha': 5.004749988348909e-05, 'batch_size': 239, 'beta_1': 0.9716149501090647, 'beta_2': 0.9975611753966407, 'epsilon': 9.63691999143471e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0007354306533985226, 'tol': 0.007650516901454851, 'validation_fraction': 0.44358767441256686}
observation time 0.000005, current best 0.119212 at iter 9
suggestion time taken 0.002438 iter 10 next_points [{'alpha': 0.0021844468407024057, 'batch_size': 156, 'beta_1': 0.9762942307797324, 'beta_2': 0.9999457593226879, 'epsilon': 5.597244996087148e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0023752244889767285, 'tol': 0.00012760248726506024, 'validation_fraction': 0.3439673393150804}]
function_evaluation time 0.995156 value 0.173416 suggestion {'alpha': 0.0021844468407024057, 'batch_size': 156, 'beta_1': 0.9762942307797324, 'beta_2': 0.9999457593226879, 'epsilon': 5.597244996087148e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0023752244889767285, 'tol': 0.00012760248726506024, 'validation_fraction': 0.3439673393150804}
observation time 0.000005, current best 0.119212 at iter 10
suggestion time taken 0.002399 iter 11 next_points [{'alpha': 0.06627252848945589, 'batch_size': 105, 'beta_1': 0.6649590765523495, 'beta_2': 0.998773485929283, 'epsilon': 3.3862955183761775e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.00012400958115814842, 'tol': 5.076585018590463e-05, 'validation_fraction': 0.26804567483001446}]
function_evaluation time 4.052396 value 0.387194 suggestion {'alpha': 0.06627252848945589, 'batch_size': 105, 'beta_1': 0.6649590765523495, 'beta_2': 0.998773485929283, 'epsilon': 3.3862955183761775e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.00012400958115814842, 'tol': 5.076585018590463e-05, 'validation_fraction': 0.26804567483001446}
observation time 0.000005, current best 0.119212 at iter 11
suggestion time taken 0.002403 iter 12 next_points [{'alpha': 0.00023313308814058503, 'batch_size': 238, 'beta_1': 0.9840633269468975, 'beta_2': 0.9042130709881758, 'epsilon': 1.1373663732006129e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.01936974408423804, 'tol': 0.00015693791788008528, 'validation_fraction': 0.4419843473777521}]
function_evaluation time 0.750403 value 0.822307 suggestion {'alpha': 0.00023313308814058503, 'batch_size': 238, 'beta_1': 0.9840633269468975, 'beta_2': 0.9042130709881758, 'epsilon': 1.1373663732006129e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.01936974408423804, 'tol': 0.00015693791788008528, 'validation_fraction': 0.4419843473777521}
observation time 0.000006, current best 0.119212 at iter 12
suggestion time taken 0.002613 iter 13 next_points [{'alpha': 0.05786224865613206, 'batch_size': 151, 'beta_1': 0.7042221102802866, 'beta_2': 0.9999989666920607, 'epsilon': 2.099607167978505e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0003363049187850515, 'tol': 0.000530485563270187, 'validation_fraction': 0.32560104436554593}]
function_evaluation time 2.550063 value 0.235051 suggestion {'alpha': 0.05786224865613206, 'batch_size': 151, 'beta_1': 0.7042221102802866, 'beta_2': 0.9999989666920607, 'epsilon': 2.099607167978505e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0003363049187850515, 'tol': 0.000530485563270187, 'validation_fraction': 0.32560104436554593}
observation time 0.000006, current best 0.119212 at iter 13
suggestion time taken 0.002418 iter 14 next_points [{'alpha': 8.79566172059118e-05, 'batch_size': 22, 'beta_1': 0.8268064392654154, 'beta_2': 0.9903138930553461, 'epsilon': 9.066429206257926e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.004352691127761128, 'tol': 0.005361190933192814, 'validation_fraction': 0.22789945509479484}]
function_evaluation time 1.801440 value 0.129006 suggestion {'alpha': 8.79566172059118e-05, 'batch_size': 22, 'beta_1': 0.8268064392654154, 'beta_2': 0.9903138930553461, 'epsilon': 9.066429206257926e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.004352691127761128, 'tol': 0.005361190933192814, 'validation_fraction': 0.22789945509479484}
observation time 0.000005, current best 0.119212 at iter 14
saving meta data: {'args': {'--uuid': '498825dab933535daf1ad634d2fafed5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
