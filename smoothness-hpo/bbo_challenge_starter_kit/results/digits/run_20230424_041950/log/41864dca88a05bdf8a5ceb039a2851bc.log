running: {'--uuid': '41864dca88a05bdf8a5ceb039a2851bc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 41864dca88a05bdf8a5ceb039a2851bc -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002333 iter 0 next_points [{'alpha': 0.0006577987463931718, 'batch_size': 219, 'beta_1': 0.8041089857805852, 'beta_2': 0.9945506690868382, 'epsilon': 1.4678121747230692e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 7.462380716622959e-05, 'tol': 3.253667023055912e-05, 'validation_fraction': 0.6925809972160172}]
function_evaluation time 1.124810 value -0.337161 suggestion {'alpha': 0.0006577987463931718, 'batch_size': 219, 'beta_1': 0.8041089857805852, 'beta_2': 0.9945506690868382, 'epsilon': 1.4678121747230692e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 7.462380716622959e-05, 'tol': 3.253667023055912e-05, 'validation_fraction': 0.6925809972160172}
observation time 0.000068, current best -0.337161 at iter 0
suggestion time taken 0.002636 iter 1 next_points [{'alpha': 0.12075579870625319, 'batch_size': 174, 'beta_1': 0.6060234775607237, 'beta_2': 0.9899285318438956, 'epsilon': 7.131085485860259e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0005178242816863902, 'tol': 0.06487551163975715, 'validation_fraction': 0.11559153056814353}]
function_evaluation time 0.579035 value -0.882424 suggestion {'alpha': 0.12075579870625319, 'batch_size': 174, 'beta_1': 0.6060234775607237, 'beta_2': 0.9899285318438956, 'epsilon': 7.131085485860259e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0005178242816863902, 'tol': 0.06487551163975715, 'validation_fraction': 0.11559153056814353}
observation time 0.000068, current best -0.882424 at iter 1
suggestion time taken 0.002138 iter 2 next_points [{'alpha': 8.82363931347219e-05, 'batch_size': 209, 'beta_1': 0.570210900979712, 'beta_2': 0.9413094102988157, 'epsilon': 1.7759225130477983e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 1.1124414030335141e-05, 'tol': 0.007717025636535703, 'validation_fraction': 0.14863547035323926}]
function_evaluation time 0.262400 value -0.093278 suggestion {'alpha': 8.82363931347219e-05, 'batch_size': 209, 'beta_1': 0.570210900979712, 'beta_2': 0.9413094102988157, 'epsilon': 1.7759225130477983e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 1.1124414030335141e-05, 'tol': 0.007717025636535703, 'validation_fraction': 0.14863547035323926}
observation time 0.000071, current best -0.882424 at iter 2
suggestion time taken 0.002149 iter 3 next_points [{'alpha': 0.10168405912194935, 'batch_size': 206, 'beta_1': 0.8455102092300828, 'beta_2': 0.9997870778879837, 'epsilon': 2.971044694637902e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.022678060856580487, 'tol': 0.07893959650191114, 'validation_fraction': 0.1398727460619148}]
function_evaluation time 0.293478 value -0.944340 suggestion {'alpha': 0.10168405912194935, 'batch_size': 206, 'beta_1': 0.8455102092300828, 'beta_2': 0.9997870778879837, 'epsilon': 2.971044694637902e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.022678060856580487, 'tol': 0.07893959650191114, 'validation_fraction': 0.1398727460619148}
observation time 0.000071, current best -0.944340 at iter 3
suggestion time taken 0.002385 iter 4 next_points [{'alpha': 0.1817499941820173, 'batch_size': 137, 'beta_1': 0.7152899985334755, 'beta_2': 0.9476268241730298, 'epsilon': 1.1197217321717697e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.037360478479726, 'tol': 0.002383781020619075, 'validation_fraction': 0.7018533966293137}]
function_evaluation time 0.577030 value -0.934563 suggestion {'alpha': 0.1817499941820173, 'batch_size': 137, 'beta_1': 0.7152899985334755, 'beta_2': 0.9476268241730298, 'epsilon': 1.1197217321717697e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.037360478479726, 'tol': 0.002383781020619075, 'validation_fraction': 0.7018533966293137}
observation time 0.000068, current best -0.944340 at iter 4
suggestion time taken 0.002123 iter 5 next_points [{'alpha': 0.00021208752007455774, 'batch_size': 106, 'beta_1': 0.6543265967668167, 'beta_2': 0.968552250097324, 'epsilon': 2.3131284983142123e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.001762858655726097, 'tol': 0.0031610638876859495, 'validation_fraction': 0.10404587891078022}]
function_evaluation time 0.931523 value -0.961036 suggestion {'alpha': 0.00021208752007455774, 'batch_size': 106, 'beta_1': 0.6543265967668167, 'beta_2': 0.968552250097324, 'epsilon': 2.3131284983142123e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.001762858655726097, 'tol': 0.0031610638876859495, 'validation_fraction': 0.10404587891078022}
observation time 0.000067, current best -0.961036 at iter 5
suggestion time taken 0.002113 iter 6 next_points [{'alpha': 0.05142492262790665, 'batch_size': 67, 'beta_1': 0.8892674096947145, 'beta_2': 0.920641092323933, 'epsilon': 9.926186381732828e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00019954157988416027, 'tol': 0.08869877722056688, 'validation_fraction': 0.14146361600333812}]
function_evaluation time 0.872477 value -0.926251 suggestion {'alpha': 0.05142492262790665, 'batch_size': 67, 'beta_1': 0.8892674096947145, 'beta_2': 0.920641092323933, 'epsilon': 9.926186381732828e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00019954157988416027, 'tol': 0.08869877722056688, 'validation_fraction': 0.14146361600333812}
observation time 0.000068, current best -0.961036 at iter 6
suggestion time taken 0.002213 iter 7 next_points [{'alpha': 0.6125624547285713, 'batch_size': 246, 'beta_1': 0.6620393662553504, 'beta_2': 0.9934331696862535, 'epsilon': 8.237970308936363e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0002901250118773846, 'tol': 2.2079820598352862e-05, 'validation_fraction': 0.5534066596605186}]
function_evaluation time 2.601633 value -0.910271 suggestion {'alpha': 0.6125624547285713, 'batch_size': 246, 'beta_1': 0.6620393662553504, 'beta_2': 0.9934331696862535, 'epsilon': 8.237970308936363e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0002901250118773846, 'tol': 2.2079820598352862e-05, 'validation_fraction': 0.5534066596605186}
observation time 0.000079, current best -0.961036 at iter 7
suggestion time taken 0.002111 iter 8 next_points [{'alpha': 0.01604232073766276, 'batch_size': 202, 'beta_1': 0.9143289637052154, 'beta_2': 0.9622133003305108, 'epsilon': 2.572165395387194e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.00011469212102691574, 'tol': 0.004454710584352354, 'validation_fraction': 0.24074894415906195}]
function_evaluation time 2.272627 value -0.892860 suggestion {'alpha': 0.01604232073766276, 'batch_size': 202, 'beta_1': 0.9143289637052154, 'beta_2': 0.9622133003305108, 'epsilon': 2.572165395387194e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.00011469212102691574, 'tol': 0.004454710584352354, 'validation_fraction': 0.24074894415906195}
observation time 0.000075, current best -0.961036 at iter 8
suggestion time taken 0.002308 iter 9 next_points [{'alpha': 2.3738669762607727, 'batch_size': 217, 'beta_1': 0.5308459836838838, 'beta_2': 0.9459921117483239, 'epsilon': 2.7938056642454416e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0008583874938208473, 'tol': 0.0002848933450952484, 'validation_fraction': 0.10279457455785486}]
function_evaluation time 1.267849 value -0.960337 suggestion {'alpha': 2.3738669762607727, 'batch_size': 217, 'beta_1': 0.5308459836838838, 'beta_2': 0.9459921117483239, 'epsilon': 2.7938056642454416e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0008583874938208473, 'tol': 0.0002848933450952484, 'validation_fraction': 0.10279457455785486}
observation time 0.000070, current best -0.961036 at iter 9
suggestion time taken 0.002138 iter 10 next_points [{'alpha': 0.03393852420954639, 'batch_size': 34, 'beta_1': 0.7511174484039356, 'beta_2': 0.9390898232074147, 'epsilon': 2.5404043800739593e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.08891134374691873, 'tol': 3.228555373050298e-05, 'validation_fraction': 0.23978316975765046}]
function_evaluation time 1.605201 value -0.474526 suggestion {'alpha': 0.03393852420954639, 'batch_size': 34, 'beta_1': 0.7511174484039356, 'beta_2': 0.9390898232074147, 'epsilon': 2.5404043800739593e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.08891134374691873, 'tol': 3.228555373050298e-05, 'validation_fraction': 0.23978316975765046}
observation time 0.000072, current best -0.961036 at iter 10
suggestion time taken 0.002168 iter 11 next_points [{'alpha': 6.921226850414066e-05, 'batch_size': 158, 'beta_1': 0.8523269759564833, 'beta_2': 0.9357294189181502, 'epsilon': 4.0802180329211514e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0012656177729990514, 'tol': 0.00041009949373224067, 'validation_fraction': 0.30936850146871986}]
function_evaluation time 1.337328 value -0.958256 suggestion {'alpha': 6.921226850414066e-05, 'batch_size': 158, 'beta_1': 0.8523269759564833, 'beta_2': 0.9357294189181502, 'epsilon': 4.0802180329211514e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0012656177729990514, 'tol': 0.00041009949373224067, 'validation_fraction': 0.30936850146871986}
observation time 0.000073, current best -0.961036 at iter 11
suggestion time taken 0.002121 iter 12 next_points [{'alpha': 7.789276637628765, 'batch_size': 177, 'beta_1': 0.756567371508515, 'beta_2': 0.9689147861567468, 'epsilon': 5.65984823831379e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.001643549108644706, 'tol': 0.00039015529960606115, 'validation_fraction': 0.41498050387193774}]
function_evaluation time 1.141155 value -0.955461 suggestion {'alpha': 7.789276637628765, 'batch_size': 177, 'beta_1': 0.756567371508515, 'beta_2': 0.9689147861567468, 'epsilon': 5.65984823831379e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.001643549108644706, 'tol': 0.00039015529960606115, 'validation_fraction': 0.41498050387193774}
observation time 0.000068, current best -0.961036 at iter 12
suggestion time taken 0.002176 iter 13 next_points [{'alpha': 3.4788008748543375, 'batch_size': 159, 'beta_1': 0.5476506663996406, 'beta_2': 0.9987304209865319, 'epsilon': 1.2547012726855596e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00045679576362508815, 'tol': 0.02701922719096753, 'validation_fraction': 0.2189246965789675}]
function_evaluation time 0.663522 value -0.846900 suggestion {'alpha': 3.4788008748543375, 'batch_size': 159, 'beta_1': 0.5476506663996406, 'beta_2': 0.9987304209865319, 'epsilon': 1.2547012726855596e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00045679576362508815, 'tol': 0.02701922719096753, 'validation_fraction': 0.2189246965789675}
observation time 0.000069, current best -0.961036 at iter 13
suggestion time taken 0.002140 iter 14 next_points [{'alpha': 6.6185919237344715, 'batch_size': 108, 'beta_1': 0.8050047986155977, 'beta_2': 0.9185657726760262, 'epsilon': 2.3874949127012548e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.003480406019721439, 'tol': 0.005250478424025742, 'validation_fraction': 0.2102702880681493}]
function_evaluation time 0.983054 value -0.960334 suggestion {'alpha': 6.6185919237344715, 'batch_size': 108, 'beta_1': 0.8050047986155977, 'beta_2': 0.9185657726760262, 'epsilon': 2.3874949127012548e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.003480406019721439, 'tol': 0.005250478424025742, 'validation_fraction': 0.2102702880681493}
observation time 0.000075, current best -0.961036 at iter 14
saving meta data: {'args': {'--uuid': '41864dca88a05bdf8a5ceb039a2851bc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
