running: {'--uuid': '52f23ff0262b54f89d3ef86c43502015', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 52f23ff0262b54f89d3ef86c43502015 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002122 iter 0 next_points [{'alpha': 0.0008647987022392651, 'batch_size': 193, 'beta_1': 0.725220949696593, 'beta_2': 0.9999834686305218, 'epsilon': 1.517200746371531e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0002995139419217773, 'tol': 0.0003254793194729145, 'validation_fraction': 0.22684112358292594}]
function_evaluation time 2.313774 value 0.181772 suggestion {'alpha': 0.0008647987022392651, 'batch_size': 193, 'beta_1': 0.725220949696593, 'beta_2': 0.9999834686305218, 'epsilon': 1.517200746371531e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0002995139419217773, 'tol': 0.0003254793194729145, 'validation_fraction': 0.22684112358292594}
observation time 0.001365, current best 0.181772 at iter 0
suggestion time taken 0.002058 iter 1 next_points [{'alpha': 5.972716665319574, 'batch_size': 131, 'beta_1': 0.9453243691291809, 'beta_2': 0.999993491153539, 'epsilon': 2.618731198576022e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 1.0164112871677538e-05, 'tol': 0.001638299140946022, 'validation_fraction': 0.7190948687762976}]
function_evaluation time 0.220170 value 12.455245 suggestion {'alpha': 5.972716665319574, 'batch_size': 131, 'beta_1': 0.9453243691291809, 'beta_2': 0.999993491153539, 'epsilon': 2.618731198576022e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 1.0164112871677538e-05, 'tol': 0.001638299140946022, 'validation_fraction': 0.7190948687762976}
observation time 0.001368, current best 0.181772 at iter 1
suggestion time taken 0.001724 iter 2 next_points [{'alpha': 0.0067730407337438054, 'batch_size': 107, 'beta_1': 0.9034905198099621, 'beta_2': 0.9997636303872707, 'epsilon': 4.6970165070355343e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 8.354155567941293e-05, 'tol': 0.00287507061371875, 'validation_fraction': 0.3747737864499815}]
function_evaluation time 2.819207 value 0.305983 suggestion {'alpha': 0.0067730407337438054, 'batch_size': 107, 'beta_1': 0.9034905198099621, 'beta_2': 0.9997636303872707, 'epsilon': 4.6970165070355343e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 8.354155567941293e-05, 'tol': 0.00287507061371875, 'validation_fraction': 0.3747737864499815}
observation time 0.001342, current best 0.181772 at iter 2
suggestion time taken 0.001725 iter 3 next_points [{'alpha': 1.126998056664902, 'batch_size': 92, 'beta_1': 0.9843701078229147, 'beta_2': 0.9999982273680951, 'epsilon': 6.611741646689035e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 5.953896151013897e-05, 'tol': 0.07440119253093527, 'validation_fraction': 0.48806493684601027}]
function_evaluation time 0.335842 value 5.383193 suggestion {'alpha': 1.126998056664902, 'batch_size': 92, 'beta_1': 0.9843701078229147, 'beta_2': 0.9999982273680951, 'epsilon': 6.611741646689035e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 5.953896151013897e-05, 'tol': 0.07440119253093527, 'validation_fraction': 0.48806493684601027}
observation time 0.001388, current best 0.181772 at iter 3
suggestion time taken 0.001740 iter 4 next_points [{'alpha': 0.01037183858576311, 'batch_size': 116, 'beta_1': 0.555297917807444, 'beta_2': 0.9999966336791751, 'epsilon': 5.6035685859044816e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.8122418749908704e-05, 'tol': 0.00792105245019917, 'validation_fraction': 0.1078003279524014}]
function_evaluation time 0.560108 value 10.565040 suggestion {'alpha': 0.01037183858576311, 'batch_size': 116, 'beta_1': 0.555297917807444, 'beta_2': 0.9999966336791751, 'epsilon': 5.6035685859044816e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.8122418749908704e-05, 'tol': 0.00792105245019917, 'validation_fraction': 0.1078003279524014}
observation time 0.001381, current best 0.181772 at iter 4
suggestion time taken 0.001730 iter 5 next_points [{'alpha': 0.01666721315997428, 'batch_size': 14, 'beta_1': 0.964396853192444, 'beta_2': 0.9293114360546428, 'epsilon': 2.6400738750335896e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0335710921461417, 'tol': 0.00026021435323842255, 'validation_fraction': 0.7999770089987512}]
function_evaluation time 1.458416 value 2.014996 suggestion {'alpha': 0.01666721315997428, 'batch_size': 14, 'beta_1': 0.964396853192444, 'beta_2': 0.9293114360546428, 'epsilon': 2.6400738750335896e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0335710921461417, 'tol': 0.00026021435323842255, 'validation_fraction': 0.7999770089987512}
observation time 0.001539, current best 0.181772 at iter 5
suggestion time taken 0.001809 iter 6 next_points [{'alpha': 8.96897152240691e-05, 'batch_size': 85, 'beta_1': 0.8474306431058592, 'beta_2': 0.999753978596519, 'epsilon': 7.712800409948154e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.05707922399040749, 'tol': 0.0053416334105468545, 'validation_fraction': 0.21264131046743126}]
function_evaluation time 1.278543 value 0.455775 suggestion {'alpha': 8.96897152240691e-05, 'batch_size': 85, 'beta_1': 0.8474306431058592, 'beta_2': 0.999753978596519, 'epsilon': 7.712800409948154e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.05707922399040749, 'tol': 0.0053416334105468545, 'validation_fraction': 0.21264131046743126}
observation time 0.001383, current best 0.181772 at iter 6
suggestion time taken 0.001722 iter 7 next_points [{'alpha': 1.9934541840257747, 'batch_size': 51, 'beta_1': 0.9823448391606567, 'beta_2': 0.9790605327066434, 'epsilon': 4.521115121022655e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0008041442790992906, 'tol': 0.03920796038381122, 'validation_fraction': 0.2688593132795204}]
function_evaluation time 0.916741 value 0.139677 suggestion {'alpha': 1.9934541840257747, 'batch_size': 51, 'beta_1': 0.9823448391606567, 'beta_2': 0.9790605327066434, 'epsilon': 4.521115121022655e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0008041442790992906, 'tol': 0.03920796038381122, 'validation_fraction': 0.2688593132795204}
observation time 0.001420, current best 0.139677 at iter 7
suggestion time taken 0.001750 iter 8 next_points [{'alpha': 0.06979287020784553, 'batch_size': 228, 'beta_1': 0.9276709591651271, 'beta_2': 0.9978331592305173, 'epsilon': 2.6004299838664276e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.002731490989938199, 'tol': 6.0649974693393435e-05, 'validation_fraction': 0.8992639216954927}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.757656 value 0.543358 suggestion {'alpha': 0.06979287020784553, 'batch_size': 228, 'beta_1': 0.9276709591651271, 'beta_2': 0.9978331592305173, 'epsilon': 2.6004299838664276e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.002731490989938199, 'tol': 6.0649974693393435e-05, 'validation_fraction': 0.8992639216954927}
observation time 0.001403, current best 0.139677 at iter 8
suggestion time taken 0.001695 iter 9 next_points [{'alpha': 0.05952955336863336, 'batch_size': 67, 'beta_1': 0.9695210788745126, 'beta_2': 0.9987215680924025, 'epsilon': 1.665630086129519e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0006461182715239202, 'tol': 0.03318102252582812, 'validation_fraction': 0.4593319860637058}]
function_evaluation time 0.557642 value 0.396706 suggestion {'alpha': 0.05952955336863336, 'batch_size': 67, 'beta_1': 0.9695210788745126, 'beta_2': 0.9987215680924025, 'epsilon': 1.665630086129519e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0006461182715239202, 'tol': 0.03318102252582812, 'validation_fraction': 0.4593319860637058}
observation time 0.001407, current best 0.139677 at iter 9
suggestion time taken 0.001683 iter 10 next_points [{'alpha': 3.708756427257577e-05, 'batch_size': 153, 'beta_1': 0.6688483884068004, 'beta_2': 0.9993974756725856, 'epsilon': 7.437552153059313e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.006129958813832174, 'tol': 0.0008420838024120974, 'validation_fraction': 0.8649910441823803}]
function_evaluation time 0.622226 value 0.497777 suggestion {'alpha': 3.708756427257577e-05, 'batch_size': 153, 'beta_1': 0.6688483884068004, 'beta_2': 0.9993974756725856, 'epsilon': 7.437552153059313e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.006129958813832174, 'tol': 0.0008420838024120974, 'validation_fraction': 0.8649910441823803}
observation time 0.001340, current best 0.139677 at iter 10
suggestion time taken 0.001957 iter 11 next_points [{'alpha': 2.728661443834184, 'batch_size': 211, 'beta_1': 0.8853467263705975, 'beta_2': 0.9927354967232939, 'epsilon': 1.4251444746276127e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.000187388364174473, 'tol': 0.00011092951788884957, 'validation_fraction': 0.6702615320163922}]
function_evaluation time 3.344539 value 0.262978 suggestion {'alpha': 2.728661443834184, 'batch_size': 211, 'beta_1': 0.8853467263705975, 'beta_2': 0.9927354967232939, 'epsilon': 1.4251444746276127e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.000187388364174473, 'tol': 0.00011092951788884957, 'validation_fraction': 0.6702615320163922}
observation time 0.001358, current best 0.139677 at iter 11
suggestion time taken 0.001668 iter 12 next_points [{'alpha': 0.0005094123520599927, 'batch_size': 137, 'beta_1': 0.9537695033980907, 'beta_2': 0.9998717763964101, 'epsilon': 1.0492997769015383e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.004930235227677291, 'tol': 3.267739846028528e-05, 'validation_fraction': 0.763094688990098}]
function_evaluation time 0.750869 value 0.257808 suggestion {'alpha': 0.0005094123520599927, 'batch_size': 137, 'beta_1': 0.9537695033980907, 'beta_2': 0.9998717763964101, 'epsilon': 1.0492997769015383e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.004930235227677291, 'tol': 3.267739846028528e-05, 'validation_fraction': 0.763094688990098}
observation time 0.001345, current best 0.139677 at iter 12
suggestion time taken 0.001677 iter 13 next_points [{'alpha': 0.18606022972891106, 'batch_size': 29, 'beta_1': 0.7055658437676973, 'beta_2': 0.9999783694756503, 'epsilon': 1.636020507040494e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0019408334065300738, 'tol': 0.000545136874543582, 'validation_fraction': 0.6314263222153487}]
function_evaluation time 2.128310 value 0.163694 suggestion {'alpha': 0.18606022972891106, 'batch_size': 29, 'beta_1': 0.7055658437676973, 'beta_2': 0.9999783694756503, 'epsilon': 1.636020507040494e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0019408334065300738, 'tol': 0.000545136874543582, 'validation_fraction': 0.6314263222153487}
observation time 0.001439, current best 0.139677 at iter 13
suggestion time taken 0.001894 iter 14 next_points [{'alpha': 8.177766346618114e-05, 'batch_size': 186, 'beta_1': 0.7861697916184103, 'beta_2': 0.9949701163166007, 'epsilon': 1.2074086619995547e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.009867676905797502, 'tol': 1.953081589800082e-05, 'validation_fraction': 0.14372942253190094}]
function_evaluation time 0.858097 value 0.109549 suggestion {'alpha': 8.177766346618114e-05, 'batch_size': 186, 'beta_1': 0.7861697916184103, 'beta_2': 0.9949701163166007, 'epsilon': 1.2074086619995547e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.009867676905797502, 'tol': 1.953081589800082e-05, 'validation_fraction': 0.14372942253190094}
observation time 0.001373, current best 0.109549 at iter 14
saving meta data: {'args': {'--uuid': '52f23ff0262b54f89d3ef86c43502015', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
