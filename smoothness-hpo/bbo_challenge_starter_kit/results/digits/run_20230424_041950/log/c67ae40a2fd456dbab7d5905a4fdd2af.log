running: {'--uuid': 'c67ae40a2fd456dbab7d5905a4fdd2af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u c67ae40a2fd456dbab7d5905a4fdd2af -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 11.781202 iter 0 next_points [{'alpha': 0.8814206896375589, 'batch_size': 65, 'beta_1': 0.9881248852383749, 'beta_2': 0.9890959063665491, 'epsilon': 2.71389910476537e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 6.842747319008004e-05, 'tol': 0.02197693307372854, 'validation_fraction': 0.4355416015682337}]
function_evaluation time 0.762416 value -0.439791 suggestion {'alpha': 0.8814206896375589, 'batch_size': 65, 'beta_1': 0.9881248852383749, 'beta_2': 0.9890959063665491, 'epsilon': 2.71389910476537e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 6.842747319008004e-05, 'tol': 0.02197693307372854, 'validation_fraction': 0.4355416015682337}
observation time 0.000006, current best -0.439791 at iter 0
suggestion time taken 11.962249 iter 1 next_points [{'alpha': 0.013824592155124375, 'batch_size': 80, 'beta_1': 0.8113635920721203, 'beta_2': 0.9996064524707327, 'epsilon': 3.255330653568692e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0002162562990434322, 'tol': 8.631943970871238e-05, 'validation_fraction': 0.4662221012533415}]
function_evaluation time 3.895372 value -0.926926 suggestion {'alpha': 0.013824592155124375, 'batch_size': 80, 'beta_1': 0.8113635920721203, 'beta_2': 0.9996064524707327, 'epsilon': 3.255330653568692e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0002162562990434322, 'tol': 8.631943970871238e-05, 'validation_fraction': 0.4662221012533415}
observation time 0.000006, current best -0.926926 at iter 1
suggestion time taken 12.074074 iter 2 next_points [{'alpha': 0.014315042960659052, 'batch_size': 36, 'beta_1': 0.9881788394683425, 'beta_2': 0.9984276614652329, 'epsilon': 2.5537650466088536e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.005150729674767412, 'tol': 0.01767832204802658, 'validation_fraction': 0.29856064729281334}]
function_evaluation time 0.731078 value -0.963819 suggestion {'alpha': 0.014315042960659052, 'batch_size': 36, 'beta_1': 0.9881788394683425, 'beta_2': 0.9984276614652329, 'epsilon': 2.5537650466088536e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.005150729674767412, 'tol': 0.01767832204802658, 'validation_fraction': 0.29856064729281334}
observation time 0.000006, current best -0.963819 at iter 2
suggestion time taken 11.754882 iter 3 next_points [{'alpha': 0.06189851397392173, 'batch_size': 101, 'beta_1': 0.9514201886610463, 'beta_2': 0.9902914842546392, 'epsilon': 1.6425678494615467e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 2.5807776932997282e-05, 'tol': 0.0006213455988348554, 'validation_fraction': 0.8818973923390585}]
function_evaluation time 0.172430 value -0.118941 suggestion {'alpha': 0.06189851397392173, 'batch_size': 101, 'beta_1': 0.9514201886610463, 'beta_2': 0.9902914842546392, 'epsilon': 1.6425678494615467e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 2.5807776932997282e-05, 'tol': 0.0006213455988348554, 'validation_fraction': 0.8818973923390585}
observation time 0.000005, current best -0.963819 at iter 3
suggestion time taken 11.569956 iter 4 next_points [{'alpha': 9.58356546195381, 'batch_size': 119, 'beta_1': 0.9135633015972467, 'beta_2': 0.9601567013701119, 'epsilon': 1.8745063984022962e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00037315996386182507, 'tol': 0.04565423144922661, 'validation_fraction': 0.7348928274053755}]
function_evaluation time 0.191947 value -0.208788 suggestion {'alpha': 9.58356546195381, 'batch_size': 119, 'beta_1': 0.9135633015972467, 'beta_2': 0.9601567013701119, 'epsilon': 1.8745063984022962e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00037315996386182507, 'tol': 0.04565423144922661, 'validation_fraction': 0.7348928274053755}
observation time 0.000006, current best -0.963819 at iter 4
suggestion time taken 11.604526 iter 5 next_points [{'alpha': 1.743867012411738, 'batch_size': 79, 'beta_1': 0.7917932352379544, 'beta_2': 0.9999951921232101, 'epsilon': 8.970301866058278e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.001882655119151202, 'tol': 0.009275005531807556, 'validation_fraction': 0.31860859467655955}]
function_evaluation time 0.725300 value -0.948509 suggestion {'alpha': 1.743867012411738, 'batch_size': 79, 'beta_1': 0.7917932352379544, 'beta_2': 0.9999951921232101, 'epsilon': 8.970301866058278e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.001882655119151202, 'tol': 0.009275005531807556, 'validation_fraction': 0.31860859467655955}
observation time 0.000004, current best -0.963819 at iter 5
suggestion time taken 12.217753 iter 6 next_points [{'alpha': 0.0007928699369709563, 'batch_size': 143, 'beta_1': 0.9502410389797392, 'beta_2': 0.9999986192340744, 'epsilon': 1.0123657125112065e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.02668073529242375, 'tol': 0.00015164267856538016, 'validation_fraction': 0.7682436947276648}]
function_evaluation time 0.714364 value -0.914412 suggestion {'alpha': 0.0007928699369709563, 'batch_size': 143, 'beta_1': 0.9502410389797392, 'beta_2': 0.9999986192340744, 'epsilon': 1.0123657125112065e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.02668073529242375, 'tol': 0.00015164267856538016, 'validation_fraction': 0.7682436947276648}
observation time 0.000006, current best -0.963819 at iter 6
suggestion time taken 11.709104 iter 7 next_points [{'alpha': 2.003964928681502e-05, 'batch_size': 101, 'beta_1': 0.8485899944939014, 'beta_2': 0.9999066396317843, 'epsilon': 6.693647511137017e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 7.980487625455542e-05, 'tol': 0.0004984455012717528, 'validation_fraction': 0.3458998677674049}]
function_evaluation time 4.756417 value -0.884485 suggestion {'alpha': 2.003964928681502e-05, 'batch_size': 101, 'beta_1': 0.8485899944939014, 'beta_2': 0.9999066396317843, 'epsilon': 6.693647511137017e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 7.980487625455542e-05, 'tol': 0.0004984455012717528, 'validation_fraction': 0.3458998677674049}
observation time 0.000005, current best -0.963819 at iter 7
suggestion time taken 11.894614 iter 8 next_points [{'alpha': 0.0005122451215293065, 'batch_size': 32, 'beta_1': 0.9416896742029917, 'beta_2': 0.9995657793537602, 'epsilon': 3.0851606499843856e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.009910865679557413, 'tol': 0.015614181741113493, 'validation_fraction': 0.7779850348565729}]
function_evaluation time 0.362370 value -0.920693 suggestion {'alpha': 0.0005122451215293065, 'batch_size': 32, 'beta_1': 0.9416896742029917, 'beta_2': 0.9995657793537602, 'epsilon': 3.0851606499843856e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.009910865679557413, 'tol': 0.015614181741113493, 'validation_fraction': 0.7779850348565729}
observation time 0.000005, current best -0.963819 at iter 8
suggestion time taken 11.974259 iter 9 next_points [{'alpha': 8.904333270057792, 'batch_size': 65, 'beta_1': 0.6180771343552792, 'beta_2': 0.9921529235619138, 'epsilon': 3.0175697418907316e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.5023279047336765e-05, 'tol': 1.728870163261859e-05, 'validation_fraction': 0.17158336207865424}]
function_evaluation time 4.413909 value -0.532445 suggestion {'alpha': 8.904333270057792, 'batch_size': 65, 'beta_1': 0.6180771343552792, 'beta_2': 0.9921529235619138, 'epsilon': 3.0175697418907316e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.5023279047336765e-05, 'tol': 1.728870163261859e-05, 'validation_fraction': 0.17158336207865424}
observation time 0.000006, current best -0.963819 at iter 9
suggestion time taken 11.874839 iter 10 next_points [{'alpha': 3.3197483863463816e-05, 'batch_size': 44, 'beta_1': 0.9232405001820915, 'beta_2': 0.9998384422657574, 'epsilon': 3.890820470777186e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 1.2577612492064508e-05, 'tol': 1.740284402748e-05, 'validation_fraction': 0.17882926083446388}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.683115 value -0.164995 suggestion {'alpha': 3.3197483863463816e-05, 'batch_size': 44, 'beta_1': 0.9232405001820915, 'beta_2': 0.9998384422657574, 'epsilon': 3.890820470777186e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 1.2577612492064508e-05, 'tol': 1.740284402748e-05, 'validation_fraction': 0.17882926083446388}
observation time 0.000005, current best -0.963819 at iter 10
suggestion time taken 11.484855 iter 11 next_points [{'alpha': 6.973499828706828e-05, 'batch_size': 80, 'beta_1': 0.5311958948323512, 'beta_2': 0.9999988526411513, 'epsilon': 2.3081743113143328e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.07525810037716142, 'tol': 0.029760518461488732, 'validation_fraction': 0.5130190082470162}]
function_evaluation time 0.527193 value -0.725278 suggestion {'alpha': 6.973499828706828e-05, 'batch_size': 80, 'beta_1': 0.5311958948323512, 'beta_2': 0.9999988526411513, 'epsilon': 2.3081743113143328e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.07525810037716142, 'tol': 0.029760518461488732, 'validation_fraction': 0.5130190082470162}
observation time 0.000004, current best -0.963819 at iter 11
suggestion time taken 11.919110 iter 12 next_points [{'alpha': 2.543844512034053e-05, 'batch_size': 86, 'beta_1': 0.9443745456469198, 'beta_2': 0.9970380616892228, 'epsilon': 1.9228552911593328e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0818414539805842, 'tol': 0.00016001104887481974, 'validation_fraction': 0.12486729849348148}]
function_evaluation time 1.016037 value -0.527296 suggestion {'alpha': 2.543844512034053e-05, 'batch_size': 86, 'beta_1': 0.9443745456469198, 'beta_2': 0.9970380616892228, 'epsilon': 1.9228552911593328e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0818414539805842, 'tol': 0.00016001104887481974, 'validation_fraction': 0.12486729849348148}
observation time 0.000005, current best -0.963819 at iter 12
suggestion time taken 11.634583 iter 13 next_points [{'alpha': 0.08527294507073448, 'batch_size': 44, 'beta_1': 0.9541701489577169, 'beta_2': 0.9991112514953682, 'epsilon': 7.392992995128401e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.012997982756806426, 'tol': 3.365099230226366e-05, 'validation_fraction': 0.2667042014585981}]
function_evaluation time 1.322764 value -0.963122 suggestion {'alpha': 0.08527294507073448, 'batch_size': 44, 'beta_1': 0.9541701489577169, 'beta_2': 0.9991112514953682, 'epsilon': 7.392992995128401e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.012997982756806426, 'tol': 3.365099230226366e-05, 'validation_fraction': 0.2667042014585981}
observation time 0.000005, current best -0.963819 at iter 13
suggestion time taken 11.658094 iter 14 next_points [{'alpha': 1.798689743393018e-05, 'batch_size': 101, 'beta_1': 0.8240595000754392, 'beta_2': 0.99876695989745, 'epsilon': 1.7222054961967878e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0004808165912945795, 'tol': 2.9177275301704277e-05, 'validation_fraction': 0.6840475848424723}]
function_evaluation time 2.054194 value -0.921356 suggestion {'alpha': 1.798689743393018e-05, 'batch_size': 101, 'beta_1': 0.8240595000754392, 'beta_2': 0.99876695989745, 'epsilon': 1.7222054961967878e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0004808165912945795, 'tol': 2.9177275301704277e-05, 'validation_fraction': 0.6840475848424723}
observation time 0.000006, current best -0.963819 at iter 14
saving meta data: {'args': {'--uuid': 'c67ae40a2fd456dbab7d5905a4fdd2af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
