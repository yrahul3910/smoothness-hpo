running: {'--uuid': '65df8bf66361575995de91ddde686bc9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 65df8bf66361575995de91ddde686bc9 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002656 iter 0 next_points [{'alpha': 2.4414374568448864, 'batch_size': 230, 'beta_1': 0.9583516854628942, 'beta_2': 0.9045540884719488, 'epsilon': 6.585626443996719e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.009313861489387829, 'tol': 0.06292650693733412, 'validation_fraction': 0.33323613850111844}]
function_evaluation time 0.431244 value -0.940140 suggestion {'alpha': 2.4414374568448864, 'batch_size': 230, 'beta_1': 0.9583516854628942, 'beta_2': 0.9045540884719488, 'epsilon': 6.585626443996719e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.009313861489387829, 'tol': 0.06292650693733412, 'validation_fraction': 0.33323613850111844}
observation time 0.000066, current best -0.940140 at iter 0
suggestion time taken 0.002391 iter 1 next_points [{'alpha': 1.7037812055091217e-05, 'batch_size': 93, 'beta_1': 0.6878704518037208, 'beta_2': 0.9435300115583791, 'epsilon': 9.781608910836634e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.01359551503423796, 'tol': 0.0007083365367132247, 'validation_fraction': 0.19802579397446626}]
function_evaluation time 0.886729 value -0.963824 suggestion {'alpha': 1.7037812055091217e-05, 'batch_size': 93, 'beta_1': 0.6878704518037208, 'beta_2': 0.9435300115583791, 'epsilon': 9.781608910836634e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.01359551503423796, 'tol': 0.0007083365367132247, 'validation_fraction': 0.19802579397446626}
observation time 0.000062, current best -0.963824 at iter 1
suggestion time taken 0.002129 iter 2 next_points [{'alpha': 9.663788274682968e-05, 'batch_size': 132, 'beta_1': 0.6607152452054109, 'beta_2': 0.920699901266595, 'epsilon': 2.897360392893448e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 8.08313009726771e-05, 'tol': 0.05613311576127589, 'validation_fraction': 0.39379913390767585}]
function_evaluation time 0.329550 value -0.190031 suggestion {'alpha': 9.663788274682968e-05, 'batch_size': 132, 'beta_1': 0.6607152452054109, 'beta_2': 0.920699901266595, 'epsilon': 2.897360392893448e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 8.08313009726771e-05, 'tol': 0.05613311576127589, 'validation_fraction': 0.39379913390767585}
observation time 0.000067, current best -0.963824 at iter 2
suggestion time taken 0.002165 iter 3 next_points [{'alpha': 0.004354851489422584, 'batch_size': 89, 'beta_1': 0.6026594278351439, 'beta_2': 0.9565283437665631, 'epsilon': 2.502271143449149e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.03926133503965156, 'tol': 0.0001331640465999311, 'validation_fraction': 0.3863005679658841}]
function_evaluation time 0.888811 value -0.943629 suggestion {'alpha': 0.004354851489422584, 'batch_size': 89, 'beta_1': 0.6026594278351439, 'beta_2': 0.9565283437665631, 'epsilon': 2.502271143449149e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.03926133503965156, 'tol': 0.0001331640465999311, 'validation_fraction': 0.3863005679658841}
observation time 0.000068, current best -0.963824 at iter 3
suggestion time taken 0.002113 iter 4 next_points [{'alpha': 3.7763435615581926, 'batch_size': 245, 'beta_1': 0.5485334754383222, 'beta_2': 0.9820248645501147, 'epsilon': 1.9236810196008322e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.00038846372248922364, 'tol': 1.616032933721905e-05, 'validation_fraction': 0.6057252479760094}]
function_evaluation time 2.547966 value -0.929728 suggestion {'alpha': 3.7763435615581926, 'batch_size': 245, 'beta_1': 0.5485334754383222, 'beta_2': 0.9820248645501147, 'epsilon': 1.9236810196008322e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.00038846372248922364, 'tol': 1.616032933721905e-05, 'validation_fraction': 0.6057252479760094}
observation time 0.000081, current best -0.963824 at iter 4
suggestion time taken 0.002157 iter 5 next_points [{'alpha': 0.00012405657954873495, 'batch_size': 154, 'beta_1': 0.8888475013994335, 'beta_2': 0.9235849154833543, 'epsilon': 2.0807910038157934e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0002492624554079943, 'tol': 0.0018293703951421086, 'validation_fraction': 0.11151006221148475}]
function_evaluation time 1.479617 value -0.947116 suggestion {'alpha': 0.00012405657954873495, 'batch_size': 154, 'beta_1': 0.8888475013994335, 'beta_2': 0.9235849154833543, 'epsilon': 2.0807910038157934e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0002492624554079943, 'tol': 0.0018293703951421086, 'validation_fraction': 0.11151006221148475}
observation time 0.000071, current best -0.963824 at iter 5
suggestion time taken 0.002155 iter 6 next_points [{'alpha': 0.04246716419804226, 'batch_size': 172, 'beta_1': 0.887924802880343, 'beta_2': 0.9452449133820718, 'epsilon': 3.6172510827515385e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00012254436123745966, 'tol': 0.000595297377073171, 'validation_fraction': 0.10127597127947056}]
function_evaluation time 2.230096 value -0.891401 suggestion {'alpha': 0.04246716419804226, 'batch_size': 172, 'beta_1': 0.887924802880343, 'beta_2': 0.9452449133820718, 'epsilon': 3.6172510827515385e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00012254436123745966, 'tol': 0.000595297377073171, 'validation_fraction': 0.10127597127947056}
observation time 0.000070, current best -0.963824 at iter 6
suggestion time taken 0.002210 iter 7 next_points [{'alpha': 0.006563771847237077, 'batch_size': 63, 'beta_1': 0.8738200419000745, 'beta_2': 0.9961357948184113, 'epsilon': 7.098117453155693e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00023280769873076178, 'tol': 2.5223033163082817e-05, 'validation_fraction': 0.27366589912565464}]
function_evaluation time 3.161548 value -0.947815 suggestion {'alpha': 0.006563771847237077, 'batch_size': 63, 'beta_1': 0.8738200419000745, 'beta_2': 0.9961357948184113, 'epsilon': 7.098117453155693e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00023280769873076178, 'tol': 2.5223033163082817e-05, 'validation_fraction': 0.27366589912565464}
observation time 0.000072, current best -0.963824 at iter 7
suggestion time taken 0.002175 iter 8 next_points [{'alpha': 1.300882030552549e-05, 'batch_size': 129, 'beta_1': 0.8642086825172389, 'beta_2': 0.9784861657530914, 'epsilon': 6.388717588981428e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.01893544566345553, 'tol': 0.0007688933201760213, 'validation_fraction': 0.340596619953335}]
function_evaluation time 0.934206 value -0.965902 suggestion {'alpha': 1.300882030552549e-05, 'batch_size': 129, 'beta_1': 0.8642086825172389, 'beta_2': 0.9784861657530914, 'epsilon': 6.388717588981428e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.01893544566345553, 'tol': 0.0007688933201760213, 'validation_fraction': 0.340596619953335}
observation time 0.000066, current best -0.965902 at iter 8
suggestion time taken 0.002131 iter 9 next_points [{'alpha': 0.00035390190093418386, 'batch_size': 240, 'beta_1': 0.7389109978633287, 'beta_2': 0.9557023255926662, 'epsilon': 7.432674346708325e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0022387827378698728, 'tol': 0.00011288116499145442, 'validation_fraction': 0.11111492196693588}]
function_evaluation time 0.921026 value -0.960339 suggestion {'alpha': 0.00035390190093418386, 'batch_size': 240, 'beta_1': 0.7389109978633287, 'beta_2': 0.9557023255926662, 'epsilon': 7.432674346708325e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0022387827378698728, 'tol': 0.00011288116499145442, 'validation_fraction': 0.11111492196693588}
observation time 0.000071, current best -0.965902 at iter 9
suggestion time taken 0.002165 iter 10 next_points [{'alpha': 0.0003742268077344335, 'batch_size': 183, 'beta_1': 0.7866637681694201, 'beta_2': 0.9109489973985058, 'epsilon': 1.5631530431413107e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.1528067928132197e-05, 'tol': 0.0008008912380539524, 'validation_fraction': 0.13156257449487693}]
function_evaluation time 0.343128 value -0.103008 suggestion {'alpha': 0.0003742268077344335, 'batch_size': 183, 'beta_1': 0.7866637681694201, 'beta_2': 0.9109489973985058, 'epsilon': 1.5631530431413107e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.1528067928132197e-05, 'tol': 0.0008008912380539524, 'validation_fraction': 0.13156257449487693}
observation time 0.000071, current best -0.965902 at iter 10
suggestion time taken 0.002178 iter 11 next_points [{'alpha': 0.02973858328877238, 'batch_size': 217, 'beta_1': 0.5301788300273336, 'beta_2': 0.9612465016360187, 'epsilon': 7.074917508679702e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 1.1639534321564328e-05, 'tol': 4.119284633730221e-05, 'validation_fraction': 0.11799395004637202}]
function_evaluation time 0.891627 value -0.096738 suggestion {'alpha': 0.02973858328877238, 'batch_size': 217, 'beta_1': 0.5301788300273336, 'beta_2': 0.9612465016360187, 'epsilon': 7.074917508679702e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 1.1639534321564328e-05, 'tol': 4.119284633730221e-05, 'validation_fraction': 0.11799395004637202}
observation time 0.000071, current best -0.965902 at iter 11
suggestion time taken 0.002152 iter 12 next_points [{'alpha': 0.0006613294645942952, 'batch_size': 185, 'beta_1': 0.5563185839757028, 'beta_2': 0.9497722084510635, 'epsilon': 1.6780304503566612e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00026870373755411454, 'tol': 0.0030992278516918516, 'validation_fraction': 0.1970304539414307}]
function_evaluation time 2.024355 value -0.953388 suggestion {'alpha': 0.0006613294645942952, 'batch_size': 185, 'beta_1': 0.5563185839757028, 'beta_2': 0.9497722084510635, 'epsilon': 1.6780304503566612e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00026870373755411454, 'tol': 0.0030992278516918516, 'validation_fraction': 0.1970304539414307}
observation time 0.000073, current best -0.965902 at iter 12
suggestion time taken 0.002454 iter 13 next_points [{'alpha': 0.013057619813216874, 'batch_size': 178, 'beta_1': 0.6779477239599598, 'beta_2': 0.9107452410467864, 'epsilon': 2.612673760757804e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 2.567529911782925e-05, 'tol': 0.0038650764732528907, 'validation_fraction': 0.4006530688264741}]
function_evaluation time 0.311939 value -0.096039 suggestion {'alpha': 0.013057619813216874, 'batch_size': 178, 'beta_1': 0.6779477239599598, 'beta_2': 0.9107452410467864, 'epsilon': 2.612673760757804e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 2.567529911782925e-05, 'tol': 0.0038650764732528907, 'validation_fraction': 0.4006530688264741}
observation time 0.000066, current best -0.965902 at iter 13
suggestion time taken 0.002137 iter 14 next_points [{'alpha': 0.4262871415612131, 'batch_size': 85, 'beta_1': 0.556454968887839, 'beta_2': 0.9954046322578486, 'epsilon': 5.170084532122705e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00024944270769624937, 'tol': 0.012052107957485994, 'validation_fraction': 0.5806860062641963}]
function_evaluation time 1.012843 value -0.893539 suggestion {'alpha': 0.4262871415612131, 'batch_size': 85, 'beta_1': 0.556454968887839, 'beta_2': 0.9954046322578486, 'epsilon': 5.170084532122705e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00024944270769624937, 'tol': 0.012052107957485994, 'validation_fraction': 0.5806860062641963}
observation time 0.000069, current best -0.965902 at iter 14
saving meta data: {'args': {'--uuid': '65df8bf66361575995de91ddde686bc9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
