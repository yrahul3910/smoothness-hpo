running: {'--uuid': '36ce40d091515e4c8264077f6cc738d9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 36ce40d091515e4c8264077f6cc738d9 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002347 iter 0 next_points [{'alpha': 0.0002535700551073443, 'batch_size': 109, 'beta_1': 0.8314118885459026, 'beta_2': 0.9999916690352793, 'epsilon': 3.8985238979425406e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.006271510176590195, 'tol': 1.0218029042237381e-05, 'validation_fraction': 0.4420023088989351}]
function_evaluation time 1.300459 value -0.965215 suggestion {'alpha': 0.0002535700551073443, 'batch_size': 109, 'beta_1': 0.8314118885459026, 'beta_2': 0.9999916690352793, 'epsilon': 3.8985238979425406e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.006271510176590195, 'tol': 1.0218029042237381e-05, 'validation_fraction': 0.4420023088989351}
observation time 0.001394, current best -0.965215 at iter 0
suggestion time taken 0.001790 iter 1 next_points [{'alpha': 0.2631875417353615, 'batch_size': 145, 'beta_1': 0.9663607118376791, 'beta_2': 0.9998987562613105, 'epsilon': 1.5063944174866925e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0006145573408956213, 'tol': 0.00026832672001580364, 'validation_fraction': 0.2648119622059292}]
function_evaluation time 1.637898 value -0.950598 suggestion {'alpha': 0.2631875417353615, 'batch_size': 145, 'beta_1': 0.9663607118376791, 'beta_2': 0.9998987562613105, 'epsilon': 1.5063944174866925e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0006145573408956213, 'tol': 0.00026832672001580364, 'validation_fraction': 0.2648119622059292}
observation time 0.001421, current best -0.965215 at iter 1
suggestion time taken 0.001786 iter 2 next_points [{'alpha': 0.0009615256190184746, 'batch_size': 184, 'beta_1': 0.8736503562977466, 'beta_2': 0.9999822343091987, 'epsilon': 4.891123796282077e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 3.827289696270682e-05, 'tol': 0.030776901228680868, 'validation_fraction': 0.731854505188966}]
function_evaluation time 0.281102 value -0.123860 suggestion {'alpha': 0.0009615256190184746, 'batch_size': 184, 'beta_1': 0.8736503562977466, 'beta_2': 0.9999822343091987, 'epsilon': 4.891123796282077e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 3.827289696270682e-05, 'tol': 0.030776901228680868, 'validation_fraction': 0.731854505188966}
observation time 0.001400, current best -0.965215 at iter 2
suggestion time taken 0.001776 iter 3 next_points [{'alpha': 1.013842519661627e-05, 'batch_size': 84, 'beta_1': 0.9201891096314488, 'beta_2': 0.9655421413026443, 'epsilon': 2.73276842705294e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.09899222154243865, 'tol': 0.08499145656290283, 'validation_fraction': 0.8256280791266978}]
function_evaluation time 0.227863 value -0.391860 suggestion {'alpha': 1.013842519661627e-05, 'batch_size': 84, 'beta_1': 0.9201891096314488, 'beta_2': 0.9655421413026443, 'epsilon': 2.73276842705294e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.09899222154243865, 'tol': 0.08499145656290283, 'validation_fraction': 0.8256280791266978}
observation time 0.001383, current best -0.965215 at iter 3
suggestion time taken 0.001734 iter 4 next_points [{'alpha': 0.0004753591131846464, 'batch_size': 38, 'beta_1': 0.9711283969462058, 'beta_2': 0.9835486993811297, 'epsilon': 1.611537660810459e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0033010591856725215, 'tol': 0.014434280060650236, 'validation_fraction': 0.797873669692539}]
function_evaluation time 0.447266 value -0.907438 suggestion {'alpha': 0.0004753591131846464, 'batch_size': 38, 'beta_1': 0.9711283969462058, 'beta_2': 0.9835486993811297, 'epsilon': 1.611537660810459e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0033010591856725215, 'tol': 0.014434280060650236, 'validation_fraction': 0.797873669692539}
observation time 0.001359, current best -0.965215 at iter 4
suggestion time taken 0.001776 iter 5 next_points [{'alpha': 4.655631854581946, 'batch_size': 155, 'beta_1': 0.7157141411261544, 'beta_2': 0.9999970420850975, 'epsilon': 1.1072825593144206e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.025730262844052276, 'tol': 0.008641189306512309, 'validation_fraction': 0.2222009447540718}]
function_evaluation time 0.604701 value -0.959645 suggestion {'alpha': 4.655631854581946, 'batch_size': 155, 'beta_1': 0.7157141411261544, 'beta_2': 0.9999970420850975, 'epsilon': 1.1072825593144206e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.025730262844052276, 'tol': 0.008641189306512309, 'validation_fraction': 0.2222009447540718}
observation time 0.001395, current best -0.965215 at iter 5
suggestion time taken 0.001782 iter 6 next_points [{'alpha': 5.73537062496889e-05, 'batch_size': 120, 'beta_1': 0.7962037274863899, 'beta_2': 0.9996654559209449, 'epsilon': 6.593471777820611e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.013504816802174708, 'tol': 0.0004288988485908186, 'validation_fraction': 0.8539010407717943}]
function_evaluation time 0.539171 value -0.885881 suggestion {'alpha': 5.73537062496889e-05, 'batch_size': 120, 'beta_1': 0.7962037274863899, 'beta_2': 0.9996654559209449, 'epsilon': 6.593471777820611e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.013504816802174708, 'tol': 0.0004288988485908186, 'validation_fraction': 0.8539010407717943}
observation time 0.001414, current best -0.965215 at iter 6
suggestion time taken 0.001764 iter 7 next_points [{'alpha': 7.4026240745639695, 'batch_size': 50, 'beta_1': 0.9360940017347732, 'beta_2': 0.9998453511356935, 'epsilon': 4.2034454802080365e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0014046913700348762, 'tol': 0.00015634521455702396, 'validation_fraction': 0.8808115924663049}]
function_evaluation time 1.802563 value -0.906042 suggestion {'alpha': 7.4026240745639695, 'batch_size': 50, 'beta_1': 0.9360940017347732, 'beta_2': 0.9998453511356935, 'epsilon': 4.2034454802080365e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0014046913700348762, 'tol': 0.00015634521455702396, 'validation_fraction': 0.8808115924663049}
observation time 0.001403, current best -0.965215 at iter 7
suggestion time taken 0.001752 iter 8 next_points [{'alpha': 0.002286848458991867, 'batch_size': 14, 'beta_1': 0.9751902390232479, 'beta_2': 0.9071207776889647, 'epsilon': 1.9956610412981445e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00027664989480914677, 'tol': 0.0025420669215726302, 'validation_fraction': 0.6144953833380935}]
function_evaluation time 2.418181 value -0.949202 suggestion {'alpha': 0.002286848458991867, 'batch_size': 14, 'beta_1': 0.9751902390232479, 'beta_2': 0.9071207776889647, 'epsilon': 1.9956610412981445e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00027664989480914677, 'tol': 0.0025420669215726302, 'validation_fraction': 0.6144953833380935}
observation time 0.001390, current best -0.965215 at iter 8
suggestion time taken 0.001968 iter 9 next_points [{'alpha': 1.5953840863607383, 'batch_size': 171, 'beta_1': 0.9825774747355064, 'beta_2': 0.9993041530906497, 'epsilon': 5.6444838683479235e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 1.0022188190625443e-05, 'tol': 1.8107171173252603e-05, 'validation_fraction': 0.7582199390819708}]
function_evaluation time 0.827648 value -0.138492 suggestion {'alpha': 1.5953840863607383, 'batch_size': 171, 'beta_1': 0.9825774747355064, 'beta_2': 0.9993041530906497, 'epsilon': 5.6444838683479235e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 1.0022188190625443e-05, 'tol': 1.8107171173252603e-05, 'validation_fraction': 0.7582199390819708}
observation time 0.001363, current best -0.965215 at iter 9
suggestion time taken 0.001747 iter 10 next_points [{'alpha': 0.09436009883287462, 'batch_size': 26, 'beta_1': 0.5441770406046259, 'beta_2': 0.991219370807054, 'epsilon': 8.511886328229906e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00011407746916595587, 'tol': 3.683922521596376e-05, 'validation_fraction': 0.11173373453725363}]
function_evaluation time 4.654375 value -0.956872 suggestion {'alpha': 0.09436009883287462, 'batch_size': 26, 'beta_1': 0.5441770406046259, 'beta_2': 0.991219370807054, 'epsilon': 8.511886328229906e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00011407746916595587, 'tol': 3.683922521596376e-05, 'validation_fraction': 0.11173373453725363}
observation time 0.001625, current best -0.965215 at iter 10
suggestion time taken 0.001768 iter 11 next_points [{'alpha': 0.007942475841556962, 'batch_size': 238, 'beta_1': 0.7353851677014523, 'beta_2': 0.9999567567080829, 'epsilon': 7.918171136600424e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0037421947357310303, 'tol': 9.980678677414028e-05, 'validation_fraction': 0.4876960013801321}]
function_evaluation time 0.819144 value -0.952686 suggestion {'alpha': 0.007942475841556962, 'batch_size': 238, 'beta_1': 0.7353851677014523, 'beta_2': 0.9999567567080829, 'epsilon': 7.918171136600424e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0037421947357310303, 'tol': 9.980678677414028e-05, 'validation_fraction': 0.4876960013801321}
observation time 0.001433, current best -0.965215 at iter 11
suggestion time taken 0.001728 iter 12 next_points [{'alpha': 0.6389354018588742, 'batch_size': 63, 'beta_1': 0.9047821322119948, 'beta_2': 0.9999750624675114, 'epsilon': 3.601023553069059e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 7.921860211413519e-05, 'tol': 0.05916252295891196, 'validation_fraction': 0.5854165399147897}]
function_evaluation time 0.345171 value -0.178816 suggestion {'alpha': 0.6389354018588742, 'batch_size': 63, 'beta_1': 0.9047821322119948, 'beta_2': 0.9999750624675114, 'epsilon': 3.601023553069059e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 7.921860211413519e-05, 'tol': 0.05916252295891196, 'validation_fraction': 0.5854165399147897}
observation time 0.001408, current best -0.965215 at iter 12
suggestion time taken 0.001736 iter 13 next_points [{'alpha': 0.2782098061967393, 'batch_size': 127, 'beta_1': 0.897053737955261, 'beta_2': 0.9989088895392696, 'epsilon': 1.0297099386303236e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 6.69991374671394e-05, 'tol': 0.0007704289138475395, 'validation_fraction': 0.38460183161956557}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.320756 value -0.900501 suggestion {'alpha': 0.2782098061967393, 'batch_size': 127, 'beta_1': 0.897053737955261, 'beta_2': 0.9989088895392696, 'epsilon': 1.0297099386303236e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 6.69991374671394e-05, 'tol': 0.0007704289138475395, 'validation_fraction': 0.38460183161956557}
observation time 0.001382, current best -0.965215 at iter 13
suggestion time taken 0.001693 iter 14 next_points [{'alpha': 0.003402022073280283, 'batch_size': 228, 'beta_1': 0.6730374168329547, 'beta_2': 0.9953736414345494, 'epsilon': 7.669823485583264e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.763734630067356e-05, 'tol': 6.732603400949255e-05, 'validation_fraction': 0.13033559732128386}]
function_evaluation time 1.488745 value -0.205466 suggestion {'alpha': 0.003402022073280283, 'batch_size': 228, 'beta_1': 0.6730374168329547, 'beta_2': 0.9953736414345494, 'epsilon': 7.669823485583264e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.763734630067356e-05, 'tol': 6.732603400949255e-05, 'validation_fraction': 0.13033559732128386}
observation time 0.001381, current best -0.965215 at iter 14
saving meta data: {'args': {'--uuid': '36ce40d091515e4c8264077f6cc738d9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
