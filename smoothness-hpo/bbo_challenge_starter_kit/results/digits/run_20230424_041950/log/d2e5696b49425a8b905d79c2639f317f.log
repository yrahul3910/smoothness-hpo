running: {'--uuid': 'd2e5696b49425a8b905d79c2639f317f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u d2e5696b49425a8b905d79c2639f317f -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 12.064144 iter 0 next_points [{'alpha': 2.506151661415895, 'batch_size': 51, 'beta_1': 0.9576614548449306, 'beta_2': 0.9999356926868364, 'epsilon': 7.164981006363564e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00020471426256722292, 'tol': 0.0002566796637913589, 'validation_fraction': 0.6613421057381007}]
function_evaluation time 3.454108 value -0.900486 suggestion {'alpha': 2.506151661415895, 'batch_size': 51, 'beta_1': 0.9576614548449306, 'beta_2': 0.9999356926868364, 'epsilon': 7.164981006363564e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00020471426256722292, 'tol': 0.0002566796637913589, 'validation_fraction': 0.6613421057381007}
observation time 0.000006, current best -0.900486 at iter 0
suggestion time taken 11.856493 iter 1 next_points [{'alpha': 0.006449496490603892, 'batch_size': 47, 'beta_1': 0.9843184030420935, 'beta_2': 0.9999981503473883, 'epsilon': 4.4942950142371863e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.09736509732323663, 'tol': 1.2559954200737445e-05, 'validation_fraction': 0.10729529426446177}]
function_evaluation time 0.990531 value -0.307421 suggestion {'alpha': 0.006449496490603892, 'batch_size': 47, 'beta_1': 0.9843184030420935, 'beta_2': 0.9999981503473883, 'epsilon': 4.4942950142371863e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.09736509732323663, 'tol': 1.2559954200737445e-05, 'validation_fraction': 0.10729529426446177}
observation time 0.000006, current best -0.900486 at iter 1
suggestion time taken 11.925728 iter 2 next_points [{'alpha': 0.0001525742379582073, 'batch_size': 111, 'beta_1': 0.9467127559556705, 'beta_2': 0.9061955762960721, 'epsilon': 8.71291805568392e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.07144517215116103, 'tol': 0.0018501528664896553, 'validation_fraction': 0.8687101548544907}]
function_evaluation time 0.544595 value -0.605524 suggestion {'alpha': 0.0001525742379582073, 'batch_size': 111, 'beta_1': 0.9467127559556705, 'beta_2': 0.9061955762960721, 'epsilon': 8.71291805568392e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.07144517215116103, 'tol': 0.0018501528664896553, 'validation_fraction': 0.8687101548544907}
observation time 0.000006, current best -0.900486 at iter 2
suggestion time taken 11.829662 iter 3 next_points [{'alpha': 1.9644227465732476, 'batch_size': 98, 'beta_1': 0.9844562264122609, 'beta_2': 0.9998825048484214, 'epsilon': 7.480076811174435e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0186761615742727, 'tol': 0.00012115213061695273, 'validation_fraction': 0.29400397693819985}]
function_evaluation time 0.899434 value -0.950595 suggestion {'alpha': 1.9644227465732476, 'batch_size': 98, 'beta_1': 0.9844562264122609, 'beta_2': 0.9998825048484214, 'epsilon': 7.480076811174435e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0186761615742727, 'tol': 0.00012115213061695273, 'validation_fraction': 0.29400397693819985}
observation time 0.000005, current best -0.950595 at iter 3
suggestion time taken 11.916654 iter 4 next_points [{'alpha': 3.292278435608307e-05, 'batch_size': 116, 'beta_1': 0.9852023483816683, 'beta_2': 0.9958173194856659, 'epsilon': 2.792511111977773e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.017997125643245564, 'tol': 0.016697063902597807, 'validation_fraction': 0.27985209053866394}]
function_evaluation time 0.500427 value -0.939467 suggestion {'alpha': 3.292278435608307e-05, 'batch_size': 116, 'beta_1': 0.9852023483816683, 'beta_2': 0.9958173194856659, 'epsilon': 2.792511111977773e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.017997125643245564, 'tol': 0.016697063902597807, 'validation_fraction': 0.27985209053866394}
observation time 0.000005, current best -0.950595 at iter 4
suggestion time taken 12.116143 iter 5 next_points [{'alpha': 1.4222573150458455e-05, 'batch_size': 115, 'beta_1': 0.6871740138805547, 'beta_2': 0.9996419693507109, 'epsilon': 2.9605434822572385e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0015981884809423736, 'tol': 0.00023136158687440538, 'validation_fraction': 0.6408445350311905}]
function_evaluation time 1.394890 value -0.929021 suggestion {'alpha': 1.4222573150458455e-05, 'batch_size': 115, 'beta_1': 0.6871740138805547, 'beta_2': 0.9996419693507109, 'epsilon': 2.9605434822572385e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0015981884809423736, 'tol': 0.00023136158687440538, 'validation_fraction': 0.6408445350311905}
observation time 0.000005, current best -0.950595 at iter 5
suggestion time taken 12.222248 iter 6 next_points [{'alpha': 0.14672392714948912, 'batch_size': 70, 'beta_1': 0.8770501443533539, 'beta_2': 0.9999921927164175, 'epsilon': 2.026571294418709e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.006238061274237001, 'tol': 0.024944145977610143, 'validation_fraction': 0.5113587659356184}]
function_evaluation time 0.443782 value -0.937394 suggestion {'alpha': 0.14672392714948912, 'batch_size': 70, 'beta_1': 0.8770501443533539, 'beta_2': 0.9999921927164175, 'epsilon': 2.026571294418709e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.006238061274237001, 'tol': 0.024944145977610143, 'validation_fraction': 0.5113587659356184}
observation time 0.000005, current best -0.950595 at iter 6
suggestion time taken 11.757795 iter 7 next_points [{'alpha': 0.0001949951894191249, 'batch_size': 78, 'beta_1': 0.9819072326421142, 'beta_2': 0.9999969674521052, 'epsilon': 1.1525672936993286e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 2.848429229601821e-05, 'tol': 0.0006187421713175033, 'validation_fraction': 0.474712084352862}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.168453 value -0.235376 suggestion {'alpha': 0.0001949951894191249, 'batch_size': 78, 'beta_1': 0.9819072326421142, 'beta_2': 0.9999969674521052, 'epsilon': 1.1525672936993286e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 2.848429229601821e-05, 'tol': 0.0006187421713175033, 'validation_fraction': 0.474712084352862}
observation time 0.000006, current best -0.950595 at iter 7
suggestion time taken 12.109591 iter 8 next_points [{'alpha': 0.008413980860620354, 'batch_size': 63, 'beta_1': 0.9654304966707475, 'beta_2': 0.9999472804904627, 'epsilon': 3.5090373419891174e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.07981360980893891, 'tol': 0.06311161654997037, 'validation_fraction': 0.6979913929399767}]
function_evaluation time 0.268219 value -0.421741 suggestion {'alpha': 0.008413980860620354, 'batch_size': 63, 'beta_1': 0.9654304966707475, 'beta_2': 0.9999472804904627, 'epsilon': 3.5090373419891174e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.07981360980893891, 'tol': 0.06311161654997037, 'validation_fraction': 0.6979913929399767}
observation time 0.000005, current best -0.950595 at iter 8
suggestion time taken 11.924498 iter 9 next_points [{'alpha': 0.0369465655097561, 'batch_size': 60, 'beta_1': 0.6467791464743843, 'beta_2': 0.999505518031732, 'epsilon': 7.199296066163824e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.018988780672983246, 'tol': 0.07500559164420019, 'validation_fraction': 0.7829735946085336}]
function_evaluation time 0.256358 value -0.916526 suggestion {'alpha': 0.0369465655097561, 'batch_size': 60, 'beta_1': 0.6467791464743843, 'beta_2': 0.999505518031732, 'epsilon': 7.199296066163824e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.018988780672983246, 'tol': 0.07500559164420019, 'validation_fraction': 0.7829735946085336}
observation time 0.000005, current best -0.950595 at iter 9
suggestion time taken 11.944274 iter 10 next_points [{'alpha': 0.001682569053179452, 'batch_size': 92, 'beta_1': 0.8540216940948042, 'beta_2': 0.9999844081836479, 'epsilon': 2.5625901210851314e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.015297055406485488, 'tol': 0.03674828738056241, 'validation_fraction': 0.49679300811698146}]
function_evaluation time 0.392498 value -0.953404 suggestion {'alpha': 0.001682569053179452, 'batch_size': 92, 'beta_1': 0.8540216940948042, 'beta_2': 0.9999844081836479, 'epsilon': 2.5625901210851314e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.015297055406485488, 'tol': 0.03674828738056241, 'validation_fraction': 0.49679300811698146}
observation time 0.000005, current best -0.953404 at iter 10
suggestion time taken 12.254355 iter 11 next_points [{'alpha': 0.08948081142901079, 'batch_size': 46, 'beta_1': 0.9870309225003611, 'beta_2': 0.9967206040004157, 'epsilon': 5.329258143113819e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0001869593759728237, 'tol': 0.0007242052315141729, 'validation_fraction': 0.20172937301983032}]
function_evaluation time 2.752568 value -0.931119 suggestion {'alpha': 0.08948081142901079, 'batch_size': 46, 'beta_1': 0.9870309225003611, 'beta_2': 0.9967206040004157, 'epsilon': 5.329258143113819e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0001869593759728237, 'tol': 0.0007242052315141729, 'validation_fraction': 0.20172937301983032}
observation time 0.000005, current best -0.953404 at iter 11
suggestion time taken 11.955651 iter 12 next_points [{'alpha': 2.957180141591382e-05, 'batch_size': 54, 'beta_1': 0.7776867030908324, 'beta_2': 0.9999989932970543, 'epsilon': 1.0295429767208041e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0003167945963083629, 'tol': 0.0004243207446241329, 'validation_fraction': 0.8211742348918022}]
function_evaluation time 3.160609 value -0.879612 suggestion {'alpha': 2.957180141591382e-05, 'batch_size': 54, 'beta_1': 0.7776867030908324, 'beta_2': 0.9999989932970543, 'epsilon': 1.0295429767208041e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0003167945963083629, 'tol': 0.0004243207446241329, 'validation_fraction': 0.8211742348918022}
observation time 0.000006, current best -0.953404 at iter 12
suggestion time taken 11.850534 iter 13 next_points [{'alpha': 5.726169072234688, 'batch_size': 32, 'beta_1': 0.9804659569349173, 'beta_2': 0.9999912910666002, 'epsilon': 1.5799829506514022e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.02816392190649609, 'tol': 0.010596413188299486, 'validation_fraction': 0.31970908466675074}]
function_evaluation time 0.999515 value -0.932515 suggestion {'alpha': 5.726169072234688, 'batch_size': 32, 'beta_1': 0.9804659569349173, 'beta_2': 0.9999912910666002, 'epsilon': 1.5799829506514022e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.02816392190649609, 'tol': 0.010596413188299486, 'validation_fraction': 0.31970908466675074}
observation time 0.000005, current best -0.953404 at iter 13
suggestion time taken 11.680840 iter 14 next_points [{'alpha': 1.0727482504851067, 'batch_size': 96, 'beta_1': 0.5121007657156466, 'beta_2': 0.9583054695218691, 'epsilon': 2.1143579818932624e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.9804166789655528e-05, 'tol': 0.00011257780942626816, 'validation_fraction': 0.7119800235469984}]
function_evaluation time 1.337357 value -0.185095 suggestion {'alpha': 1.0727482504851067, 'batch_size': 96, 'beta_1': 0.5121007657156466, 'beta_2': 0.9583054695218691, 'epsilon': 2.1143579818932624e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.9804166789655528e-05, 'tol': 0.00011257780942626816, 'validation_fraction': 0.7119800235469984}
observation time 0.000006, current best -0.953404 at iter 14
saving meta data: {'args': {'--uuid': 'd2e5696b49425a8b905d79c2639f317f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
