running: {'--uuid': '49787a3442e157548feed5e9aef22f04', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 49787a3442e157548feed5e9aef22f04 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 11.712160 iter 0 next_points [{'alpha': 0.0004133392438101089, 'batch_size': 90, 'beta_1': 0.9199420493882617, 'beta_2': 0.9999735225239982, 'epsilon': 4.0727668474211626e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 6.142226989705342e-05, 'tol': 1.9581569138372025e-05, 'validation_fraction': 0.8136327466608312}]
function_evaluation time 0.737821 value 8.787447 suggestion {'alpha': 0.0004133392438101089, 'batch_size': 90, 'beta_1': 0.9199420493882617, 'beta_2': 0.9999735225239982, 'epsilon': 4.0727668474211626e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 6.142226989705342e-05, 'tol': 1.9581569138372025e-05, 'validation_fraction': 0.8136327466608312}
observation time 0.000005, current best 8.787447 at iter 0
suggestion time taken 11.736807 iter 1 next_points [{'alpha': 0.951215980541297, 'batch_size': 96, 'beta_1': 0.9578426306921948, 'beta_2': 0.9998222517176165, 'epsilon': 1.8976924722700016e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.02142669037464653, 'tol': 0.004286504279182157, 'validation_fraction': 0.4740629446693945}]
function_evaluation time 0.658032 value 0.175404 suggestion {'alpha': 0.951215980541297, 'batch_size': 96, 'beta_1': 0.9578426306921948, 'beta_2': 0.9998222517176165, 'epsilon': 1.8976924722700016e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.02142669037464653, 'tol': 0.004286504279182157, 'validation_fraction': 0.4740629446693945}
observation time 0.000006, current best 0.175404 at iter 1
suggestion time taken 11.974962 iter 2 next_points [{'alpha': 1.2576087408440176e-05, 'batch_size': 118, 'beta_1': 0.9806182813087244, 'beta_2': 0.99151556963173, 'epsilon': 1.2303579357116562e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 2.1985013549096504e-05, 'tol': 0.00013188835991801654, 'validation_fraction': 0.8132743561670261}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.870291 value 11.516720 suggestion {'alpha': 1.2576087408440176e-05, 'batch_size': 118, 'beta_1': 0.9806182813087244, 'beta_2': 0.99151556963173, 'epsilon': 1.2303579357116562e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 2.1985013549096504e-05, 'tol': 0.00013188835991801654, 'validation_fraction': 0.8132743561670261}
observation time 0.000006, current best 0.175404 at iter 2
suggestion time taken 11.609936 iter 3 next_points [{'alpha': 0.16438386610042266, 'batch_size': 170, 'beta_1': 0.9783359631500621, 'beta_2': 0.9304961508260304, 'epsilon': 8.831245790608407e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00046382303328930695, 'tol': 1.3168716413650729e-05, 'validation_fraction': 0.6931082847145149}]
function_evaluation time 1.722311 value 0.235359 suggestion {'alpha': 0.16438386610042266, 'batch_size': 170, 'beta_1': 0.9783359631500621, 'beta_2': 0.9304961508260304, 'epsilon': 8.831245790608407e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00046382303328930695, 'tol': 1.3168716413650729e-05, 'validation_fraction': 0.6931082847145149}
observation time 0.000006, current best 0.175404 at iter 3
suggestion time taken 11.647569 iter 4 next_points [{'alpha': 0.002604823120376352, 'batch_size': 92, 'beta_1': 0.5315526937747678, 'beta_2': 0.999252069666446, 'epsilon': 4.59519282580472e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 2.041500664174165e-05, 'tol': 0.013490237536091512, 'validation_fraction': 0.19891701750861374}]
function_evaluation time 0.419562 value 8.490381 suggestion {'alpha': 0.002604823120376352, 'batch_size': 92, 'beta_1': 0.5315526937747678, 'beta_2': 0.999252069666446, 'epsilon': 4.59519282580472e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 2.041500664174165e-05, 'tol': 0.013490237536091512, 'validation_fraction': 0.19891701750861374}
observation time 0.000004, current best 0.175404 at iter 4
suggestion time taken 12.054431 iter 5 next_points [{'alpha': 4.685326664241739, 'batch_size': 18, 'beta_1': 0.9229679721670918, 'beta_2': 0.9999783716543261, 'epsilon': 4.0507983694088585e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0019144815004361485, 'tol': 0.010359164524415035, 'validation_fraction': 0.16759829018847447}]
function_evaluation time 1.297514 value 0.321090 suggestion {'alpha': 4.685326664241739, 'batch_size': 18, 'beta_1': 0.9229679721670918, 'beta_2': 0.9999783716543261, 'epsilon': 4.0507983694088585e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0019144815004361485, 'tol': 0.010359164524415035, 'validation_fraction': 0.16759829018847447}
observation time 0.000006, current best 0.175404 at iter 5
suggestion time taken 11.610507 iter 6 next_points [{'alpha': 2.0007235844670097, 'batch_size': 64, 'beta_1': 0.8209749726485607, 'beta_2': 0.9874702927745487, 'epsilon': 7.977479632298122e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 3.7426027546293775e-05, 'tol': 0.07959453906433944, 'validation_fraction': 0.2652842567393207}]
function_evaluation time 0.484717 value 5.823343 suggestion {'alpha': 2.0007235844670097, 'batch_size': 64, 'beta_1': 0.8209749726485607, 'beta_2': 0.9874702927745487, 'epsilon': 7.977479632298122e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 3.7426027546293775e-05, 'tol': 0.07959453906433944, 'validation_fraction': 0.2652842567393207}
observation time 0.000006, current best 0.175404 at iter 6
suggestion time taken 11.836874 iter 7 next_points [{'alpha': 0.05287951195763769, 'batch_size': 91, 'beta_1': 0.9073160268510213, 'beta_2': 0.9999960942603536, 'epsilon': 6.979332083585408e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.001602644490080393, 'tol': 1.0431353344272187e-05, 'validation_fraction': 0.31682949268916055}]
function_evaluation time 1.655679 value 0.155758 suggestion {'alpha': 0.05287951195763769, 'batch_size': 91, 'beta_1': 0.9073160268510213, 'beta_2': 0.9999960942603536, 'epsilon': 6.979332083585408e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.001602644490080393, 'tol': 1.0431353344272187e-05, 'validation_fraction': 0.31682949268916055}
observation time 0.000005, current best 0.155758 at iter 7
suggestion time taken 11.994147 iter 8 next_points [{'alpha': 0.07632153426960804, 'batch_size': 245, 'beta_1': 0.8528648157199362, 'beta_2': 0.9999951991589873, 'epsilon': 4.340721621227246e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.021666067305442155, 'tol': 0.0004659677597611002, 'validation_fraction': 0.7486491580388743}]
function_evaluation time 0.587790 value 0.235613 suggestion {'alpha': 0.07632153426960804, 'batch_size': 245, 'beta_1': 0.8528648157199362, 'beta_2': 0.9999951991589873, 'epsilon': 4.340721621227246e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.021666067305442155, 'tol': 0.0004659677597611002, 'validation_fraction': 0.7486491580388743}
observation time 0.000005, current best 0.155758 at iter 8
suggestion time taken 11.672861 iter 9 next_points [{'alpha': 1.1741259748214148e-05, 'batch_size': 68, 'beta_1': 0.7259109940375248, 'beta_2': 0.9998665967293722, 'epsilon': 1.651353351110142e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0002523207597283277, 'tol': 6.0519311363589094e-05, 'validation_fraction': 0.21533937888531832}]
function_evaluation time 2.777086 value 0.225399 suggestion {'alpha': 1.1741259748214148e-05, 'batch_size': 68, 'beta_1': 0.7259109940375248, 'beta_2': 0.9998665967293722, 'epsilon': 1.651353351110142e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0002523207597283277, 'tol': 6.0519311363589094e-05, 'validation_fraction': 0.21533937888531832}
observation time 0.000006, current best 0.155758 at iter 9
suggestion time taken 11.752478 iter 10 next_points [{'alpha': 1.5274247688672482, 'batch_size': 140, 'beta_1': 0.6507234820574717, 'beta_2': 0.9999927633213925, 'epsilon': 2.2412745891619456e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.00025921379204446224, 'tol': 0.0011116674936320293, 'validation_fraction': 0.8570959832748648}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.463716 value 4.892891 suggestion {'alpha': 1.5274247688672482, 'batch_size': 140, 'beta_1': 0.6507234820574717, 'beta_2': 0.9999927633213925, 'epsilon': 2.2412745891619456e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.00025921379204446224, 'tol': 0.0011116674936320293, 'validation_fraction': 0.8570959832748648}
observation time 0.000005, current best 0.155758 at iter 10
suggestion time taken 11.871188 iter 11 next_points [{'alpha': 0.0018467650177203412, 'batch_size': 50, 'beta_1': 0.9739553535437434, 'beta_2': 0.9937143806310713, 'epsilon': 5.482871670606633e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00941818917317638, 'tol': 0.03947409331211912, 'validation_fraction': 0.8250317311275303}]
function_evaluation time 0.330475 value 0.580136 suggestion {'alpha': 0.0018467650177203412, 'batch_size': 50, 'beta_1': 0.9739553535437434, 'beta_2': 0.9937143806310713, 'epsilon': 5.482871670606633e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00941818917317638, 'tol': 0.03947409331211912, 'validation_fraction': 0.8250317311275303}
observation time 0.000005, current best 0.155758 at iter 11
suggestion time taken 12.045866 iter 12 next_points [{'alpha': 0.0068892586783473155, 'batch_size': 55, 'beta_1': 0.9523706800215241, 'beta_2': 0.9999878133666675, 'epsilon': 2.419371787298771e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 3.142414090524354e-05, 'tol': 2.9223887233392855e-05, 'validation_fraction': 0.4457898228271387}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.984633 value 2.426549 suggestion {'alpha': 0.0068892586783473155, 'batch_size': 55, 'beta_1': 0.9523706800215241, 'beta_2': 0.9999878133666675, 'epsilon': 2.419371787298771e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 3.142414090524354e-05, 'tol': 2.9223887233392855e-05, 'validation_fraction': 0.4457898228271387}
observation time 0.000005, current best 0.155758 at iter 12
suggestion time taken 11.895525 iter 13 next_points [{'alpha': 0.0040857701377154925, 'batch_size': 86, 'beta_1': 0.9505474570082487, 'beta_2': 0.9672119500788464, 'epsilon': 1.6220276318306808e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.00814002865477418, 'tol': 8.574442756110742e-05, 'validation_fraction': 0.11102601529151532}]
function_evaluation time 0.595376 value 0.150260 suggestion {'alpha': 0.0040857701377154925, 'batch_size': 86, 'beta_1': 0.9505474570082487, 'beta_2': 0.9672119500788464, 'epsilon': 1.6220276318306808e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.00814002865477418, 'tol': 8.574442756110742e-05, 'validation_fraction': 0.11102601529151532}
observation time 0.000006, current best 0.150260 at iter 13
suggestion time taken 11.769995 iter 14 next_points [{'alpha': 0.08909748025871239, 'batch_size': 59, 'beta_1': 0.9870344838737805, 'beta_2': 0.9980964760710177, 'epsilon': 1.4912988729960874e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.006740289362197853, 'tol': 6.732698689884327e-05, 'validation_fraction': 0.8513986722192318}]
function_evaluation time 0.788435 value 0.709908 suggestion {'alpha': 0.08909748025871239, 'batch_size': 59, 'beta_1': 0.9870344838737805, 'beta_2': 0.9980964760710177, 'epsilon': 1.4912988729960874e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.006740289362197853, 'tol': 6.732698689884327e-05, 'validation_fraction': 0.8513986722192318}
observation time 0.000005, current best 0.150260 at iter 14
saving meta data: {'args': {'--uuid': '49787a3442e157548feed5e9aef22f04', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
