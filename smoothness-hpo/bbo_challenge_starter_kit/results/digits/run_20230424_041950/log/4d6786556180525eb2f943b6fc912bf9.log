running: {'--uuid': '4d6786556180525eb2f943b6fc912bf9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 4d6786556180525eb2f943b6fc912bf9 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002287 iter 0 next_points [{'alpha': 0.008411315619997469, 'batch_size': 247, 'beta_1': 0.652153918772781, 'beta_2': 0.9573916198868636, 'epsilon': 4.576866485372334e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.006751415404675526, 'tol': 1.0785777494126974e-05, 'validation_fraction': 0.23988288346372924}]
function_evaluation time 1.127705 value 0.087093 suggestion {'alpha': 0.008411315619997469, 'batch_size': 247, 'beta_1': 0.652153918772781, 'beta_2': 0.9573916198868636, 'epsilon': 4.576866485372334e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.006751415404675526, 'tol': 1.0785777494126974e-05, 'validation_fraction': 0.23988288346372924}
observation time 0.000072, current best 0.087093 at iter 0
suggestion time taken 0.002369 iter 1 next_points [{'alpha': 1.3384641796227623, 'batch_size': 104, 'beta_1': 0.7828726645313098, 'beta_2': 0.9999721410885237, 'epsilon': 1.0992150833314706e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0017525125955984875, 'tol': 0.04519753907228808, 'validation_fraction': 0.4131383391317047}]
function_evaluation time 0.536587 value 0.157220 suggestion {'alpha': 1.3384641796227623, 'batch_size': 104, 'beta_1': 0.7828726645313098, 'beta_2': 0.9999721410885237, 'epsilon': 1.0992150833314706e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0017525125955984875, 'tol': 0.04519753907228808, 'validation_fraction': 0.4131383391317047}
observation time 0.000067, current best 0.087093 at iter 1
suggestion time taken 0.002091 iter 2 next_points [{'alpha': 0.0050412688046881475, 'batch_size': 69, 'beta_1': 0.5961328224166487, 'beta_2': 0.9337588764702464, 'epsilon': 1.526863691047703e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00014914676119987387, 'tol': 3.885406687833545e-05, 'validation_fraction': 0.26177124206816926}]
function_evaluation time 3.123320 value 0.129151 suggestion {'alpha': 0.0050412688046881475, 'batch_size': 69, 'beta_1': 0.5961328224166487, 'beta_2': 0.9337588764702464, 'epsilon': 1.526863691047703e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00014914676119987387, 'tol': 3.885406687833545e-05, 'validation_fraction': 0.26177124206816926}
observation time 0.000069, current best 0.087093 at iter 2
suggestion time taken 0.002136 iter 3 next_points [{'alpha': 0.00032030455764149677, 'batch_size': 33, 'beta_1': 0.5854828583798344, 'beta_2': 0.9036767806255622, 'epsilon': 8.313949965314887e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0004546419524166166, 'tol': 0.0003623026120013494, 'validation_fraction': 0.17538211316607444}]
function_evaluation time 2.793040 value 0.101213 suggestion {'alpha': 0.00032030455764149677, 'batch_size': 33, 'beta_1': 0.5854828583798344, 'beta_2': 0.9036767806255622, 'epsilon': 8.313949965314887e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0004546419524166166, 'tol': 0.0003623026120013494, 'validation_fraction': 0.17538211316607444}
observation time 0.000070, current best 0.087093 at iter 3
suggestion time taken 0.002057 iter 4 next_points [{'alpha': 2.71987422163694, 'batch_size': 197, 'beta_1': 0.9410180378492438, 'beta_2': 0.9034797875194405, 'epsilon': 2.545006661883825e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0006655325461504515, 'tol': 0.03094565718065424, 'validation_fraction': 0.791844511135449}]
function_evaluation time 0.515944 value 0.445222 suggestion {'alpha': 2.71987422163694, 'batch_size': 197, 'beta_1': 0.9410180378492438, 'beta_2': 0.9034797875194405, 'epsilon': 2.545006661883825e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0006655325461504515, 'tol': 0.03094565718065424, 'validation_fraction': 0.791844511135449}
observation time 0.000070, current best 0.087093 at iter 4
suggestion time taken 0.002298 iter 5 next_points [{'alpha': 0.38366380282611495, 'batch_size': 226, 'beta_1': 0.8095359876921456, 'beta_2': 0.9971956002779508, 'epsilon': 1.1240000626994417e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.05389481692286916, 'tol': 1.0560043896377622e-05, 'validation_fraction': 0.1236019704561229}]
function_evaluation time 0.861069 value 0.250336 suggestion {'alpha': 0.38366380282611495, 'batch_size': 226, 'beta_1': 0.8095359876921456, 'beta_2': 0.9971956002779508, 'epsilon': 1.1240000626994417e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.05389481692286916, 'tol': 1.0560043896377622e-05, 'validation_fraction': 0.1236019704561229}
observation time 0.000067, current best 0.087093 at iter 5
suggestion time taken 0.002103 iter 6 next_points [{'alpha': 2.0967736282753602e-05, 'batch_size': 12, 'beta_1': 0.9316543993504548, 'beta_2': 0.9385573148688143, 'epsilon': 1.4098033041810895e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 2.2134558409038287e-05, 'tol': 0.06725009618607601, 'validation_fraction': 0.3779137772244912}]
function_evaluation time 1.070281 value 7.547583 suggestion {'alpha': 2.0967736282753602e-05, 'batch_size': 12, 'beta_1': 0.9316543993504548, 'beta_2': 0.9385573148688143, 'epsilon': 1.4098033041810895e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 2.2134558409038287e-05, 'tol': 0.06725009618607601, 'validation_fraction': 0.3779137772244912}
observation time 0.000066, current best 0.087093 at iter 6
suggestion time taken 0.002309 iter 7 next_points [{'alpha': 0.005516675260028378, 'batch_size': 227, 'beta_1': 0.9840155379696512, 'beta_2': 0.9464547491235377, 'epsilon': 1.2594629282938857e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.04515268573364881, 'tol': 0.009043935560038444, 'validation_fraction': 0.4280975522766124}]
function_evaluation time 0.521313 value 1.121589 suggestion {'alpha': 0.005516675260028378, 'batch_size': 227, 'beta_1': 0.9840155379696512, 'beta_2': 0.9464547491235377, 'epsilon': 1.2594629282938857e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.04515268573364881, 'tol': 0.009043935560038444, 'validation_fraction': 0.4280975522766124}
observation time 0.000071, current best 0.087093 at iter 7
suggestion time taken 0.002098 iter 8 next_points [{'alpha': 5.600319989677192, 'batch_size': 150, 'beta_1': 0.5619054601874461, 'beta_2': 0.9973228099084904, 'epsilon': 6.578782005375863e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.005572425118991964, 'tol': 3.392807809434466e-05, 'validation_fraction': 0.40409348850579413}]
function_evaluation time 0.846663 value 0.147740 suggestion {'alpha': 5.600319989677192, 'batch_size': 150, 'beta_1': 0.5619054601874461, 'beta_2': 0.9973228099084904, 'epsilon': 6.578782005375863e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.005572425118991964, 'tol': 3.392807809434466e-05, 'validation_fraction': 0.40409348850579413}
observation time 0.000066, current best 0.087093 at iter 8
suggestion time taken 0.002042 iter 9 next_points [{'alpha': 0.0037823401764017156, 'batch_size': 159, 'beta_1': 0.6179035717572878, 'beta_2': 0.9208308425342537, 'epsilon': 2.4298526993470152e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.044331607180747405, 'tol': 0.006170648007572516, 'validation_fraction': 0.2921432225335511}]
function_evaluation time 0.889743 value 0.263565 suggestion {'alpha': 0.0037823401764017156, 'batch_size': 159, 'beta_1': 0.6179035717572878, 'beta_2': 0.9208308425342537, 'epsilon': 2.4298526993470152e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.044331607180747405, 'tol': 0.006170648007572516, 'validation_fraction': 0.2921432225335511}
observation time 0.000075, current best 0.087093 at iter 9
suggestion time taken 0.002067 iter 10 next_points [{'alpha': 1.4348309325174222, 'batch_size': 247, 'beta_1': 0.5869562612468756, 'beta_2': 0.9793189522189113, 'epsilon': 2.1223253212185407e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.02687576232330294, 'tol': 4.040576685984356e-05, 'validation_fraction': 0.28575742080663646}]
function_evaluation time 0.660447 value 0.127669 suggestion {'alpha': 1.4348309325174222, 'batch_size': 247, 'beta_1': 0.5869562612468756, 'beta_2': 0.9793189522189113, 'epsilon': 2.1223253212185407e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.02687576232330294, 'tol': 4.040576685984356e-05, 'validation_fraction': 0.28575742080663646}
observation time 0.000067, current best 0.087093 at iter 10
suggestion time taken 0.002080 iter 11 next_points [{'alpha': 0.05618723572710521, 'batch_size': 133, 'beta_1': 0.8047666817029439, 'beta_2': 0.9916292255809918, 'epsilon': 2.684731947705783e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00020962939304798865, 'tol': 0.0028311511646914645, 'validation_fraction': 0.11941544199017429}]
function_evaluation time 2.093071 value 0.210741 suggestion {'alpha': 0.05618723572710521, 'batch_size': 133, 'beta_1': 0.8047666817029439, 'beta_2': 0.9916292255809918, 'epsilon': 2.684731947705783e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00020962939304798865, 'tol': 0.0028311511646914645, 'validation_fraction': 0.11941544199017429}
observation time 0.000068, current best 0.087093 at iter 11
suggestion time taken 0.002075 iter 12 next_points [{'alpha': 0.02238423394445466, 'batch_size': 76, 'beta_1': 0.8339919794041282, 'beta_2': 0.9303044598638308, 'epsilon': 1.2195761342545338e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.018639757419020127, 'tol': 0.05433261856616657, 'validation_fraction': 0.29891027095764633}]
function_evaluation time 0.446871 value 0.163307 suggestion {'alpha': 0.02238423394445466, 'batch_size': 76, 'beta_1': 0.8339919794041282, 'beta_2': 0.9303044598638308, 'epsilon': 1.2195761342545338e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.018639757419020127, 'tol': 0.05433261856616657, 'validation_fraction': 0.29891027095764633}
observation time 0.000071, current best 0.087093 at iter 12
suggestion time taken 0.002327 iter 13 next_points [{'alpha': 4.0686645675598e-05, 'batch_size': 159, 'beta_1': 0.5763806061272468, 'beta_2': 0.9556267540875203, 'epsilon': 2.2849451560982245e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 1.8912631696601628e-05, 'tol': 0.001771046167654854, 'validation_fraction': 0.11686525129659005}]
function_evaluation time 0.565603 value 8.114283 suggestion {'alpha': 4.0686645675598e-05, 'batch_size': 159, 'beta_1': 0.5763806061272468, 'beta_2': 0.9556267540875203, 'epsilon': 2.2849451560982245e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 1.8912631696601628e-05, 'tol': 0.001771046167654854, 'validation_fraction': 0.11686525129659005}
observation time 0.000066, current best 0.087093 at iter 13
suggestion time taken 0.002090 iter 14 next_points [{'alpha': 0.9947142403039484, 'batch_size': 48, 'beta_1': 0.6670122933743805, 'beta_2': 0.9363575479742733, 'epsilon': 3.8204159412413073e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0007686091914931967, 'tol': 0.0009459173816118653, 'validation_fraction': 0.28243135211041304}]
function_evaluation time 1.696365 value 0.120158 suggestion {'alpha': 0.9947142403039484, 'batch_size': 48, 'beta_1': 0.6670122933743805, 'beta_2': 0.9363575479742733, 'epsilon': 3.8204159412413073e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0007686091914931967, 'tol': 0.0009459173816118653, 'validation_fraction': 0.28243135211041304}
observation time 0.000072, current best 0.087093 at iter 14
saving meta data: {'args': {'--uuid': '4d6786556180525eb2f943b6fc912bf9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
