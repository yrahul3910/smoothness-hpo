running: {'--uuid': '4dca24ec64575cb8a273292e32644e06', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 4dca24ec64575cb8a273292e32644e06 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002125 iter 0 next_points [{'alpha': 0.11418720493657017, 'batch_size': 58, 'beta_1': 0.8055276754017522, 'beta_2': 0.9992280862162767, 'epsilon': 1.753476439414852e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.02190894837405109, 'tol': 1.1137441977268237e-05, 'validation_fraction': 0.786446434512006}]
function_evaluation time 1.183410 value 0.224515 suggestion {'alpha': 0.11418720493657017, 'batch_size': 58, 'beta_1': 0.8055276754017522, 'beta_2': 0.9992280862162767, 'epsilon': 1.753476439414852e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.02190894837405109, 'tol': 1.1137441977268237e-05, 'validation_fraction': 0.786446434512006}
observation time 0.001357, current best 0.224515 at iter 0
suggestion time taken 0.001748 iter 1 next_points [{'alpha': 1.5186253957933935, 'batch_size': 115, 'beta_1': 0.8664350367964122, 'beta_2': 0.9970719659343066, 'epsilon': 5.25752793106015e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.006907045384847157, 'tol': 0.0016834897727082915, 'validation_fraction': 0.4066769065822831}]
function_evaluation time 1.096570 value 0.130678 suggestion {'alpha': 1.5186253957933935, 'batch_size': 115, 'beta_1': 0.8664350367964122, 'beta_2': 0.9970719659343066, 'epsilon': 5.25752793106015e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.006907045384847157, 'tol': 0.0016834897727082915, 'validation_fraction': 0.4066769065822831}
observation time 0.001372, current best 0.130678 at iter 1
suggestion time taken 0.001772 iter 2 next_points [{'alpha': 0.0012794462032964633, 'batch_size': 185, 'beta_1': 0.5433332955498811, 'beta_2': 0.999617988462331, 'epsilon': 1.515075038558162e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.292856890593037e-05, 'tol': 4.4553982460003487e-05, 'validation_fraction': 0.10179657059736534}]
function_evaluation time 0.862731 value 8.874191 suggestion {'alpha': 0.0012794462032964633, 'batch_size': 185, 'beta_1': 0.5433332955498811, 'beta_2': 0.999617988462331, 'epsilon': 1.515075038558162e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.292856890593037e-05, 'tol': 4.4553982460003487e-05, 'validation_fraction': 0.10179657059736534}
observation time 0.001374, current best 0.130678 at iter 2
suggestion time taken 0.001698 iter 3 next_points [{'alpha': 0.005921682049557045, 'batch_size': 63, 'beta_1': 0.8944990082534946, 'beta_2': 0.9264272200765659, 'epsilon': 6.017078671138041e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0016230073141643457, 'tol': 0.0003197021780643309, 'validation_fraction': 0.6779794305440805}]
function_evaluation time 1.220120 value 0.193087 suggestion {'alpha': 0.005921682049557045, 'batch_size': 63, 'beta_1': 0.8944990082534946, 'beta_2': 0.9264272200765659, 'epsilon': 6.017078671138041e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0016230073141643457, 'tol': 0.0003197021780643309, 'validation_fraction': 0.6779794305440805}
observation time 0.001385, current best 0.130678 at iter 3
suggestion time taken 0.002041 iter 4 next_points [{'alpha': 1.2457124445293632e-05, 'batch_size': 135, 'beta_1': 0.5965367069708234, 'beta_2': 0.9989846529967455, 'epsilon': 1.9520003008149065e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.012126006119202719, 'tol': 0.00013204433724872637, 'validation_fraction': 0.5367667244382355}]
function_evaluation time 0.865354 value 0.171542 suggestion {'alpha': 1.2457124445293632e-05, 'batch_size': 135, 'beta_1': 0.5965367069708234, 'beta_2': 0.9989846529967455, 'epsilon': 1.9520003008149065e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.012126006119202719, 'tol': 0.00013204433724872637, 'validation_fraction': 0.5367667244382355}
observation time 0.001350, current best 0.130678 at iter 4
suggestion time taken 0.001776 iter 5 next_points [{'alpha': 0.0281514126826654, 'batch_size': 12, 'beta_1': 0.9730176446305165, 'beta_2': 0.9614148482703726, 'epsilon': 6.770406820247735e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.002668867195288988, 'tol': 0.003631555297766672, 'validation_fraction': 0.8431604691655782}]
function_evaluation time 1.098244 value 0.322777 suggestion {'alpha': 0.0281514126826654, 'batch_size': 12, 'beta_1': 0.9730176446305165, 'beta_2': 0.9614148482703726, 'epsilon': 6.770406820247735e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.002668867195288988, 'tol': 0.003631555297766672, 'validation_fraction': 0.8431604691655782}
observation time 0.001334, current best 0.130678 at iter 5
suggestion time taken 0.001713 iter 6 next_points [{'alpha': 0.00031851087253469444, 'batch_size': 29, 'beta_1': 0.9793773460800498, 'beta_2': 0.9999716443256146, 'epsilon': 3.7434263491303605e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00029893609843171143, 'tol': 8.404714533789006e-05, 'validation_fraction': 0.28138374961224905}]
function_evaluation time 3.369433 value 0.224192 suggestion {'alpha': 0.00031851087253469444, 'batch_size': 29, 'beta_1': 0.9793773460800498, 'beta_2': 0.9999716443256146, 'epsilon': 3.7434263491303605e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00029893609843171143, 'tol': 8.404714533789006e-05, 'validation_fraction': 0.28138374961224905}
observation time 0.001356, current best 0.130678 at iter 6
suggestion time taken 0.001979 iter 7 next_points [{'alpha': 0.00016765755037420035, 'batch_size': 231, 'beta_1': 0.9821859037623136, 'beta_2': 0.9999982175832041, 'epsilon': 6.974573545164178e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0008966429470790134, 'tol': 0.09315515327247971, 'validation_fraction': 0.5050508414263412}]
function_evaluation time 0.273631 value 1.576212 suggestion {'alpha': 0.00016765755037420035, 'batch_size': 231, 'beta_1': 0.9821859037623136, 'beta_2': 0.9999982175832041, 'epsilon': 6.974573545164178e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0008966429470790134, 'tol': 0.09315515327247971, 'validation_fraction': 0.5050508414263412}
observation time 0.001354, current best 0.130678 at iter 7
suggestion time taken 0.001738 iter 8 next_points [{'alpha': 6.914052338304936e-05, 'batch_size': 96, 'beta_1': 0.6913841421959795, 'beta_2': 0.9998098776381845, 'epsilon': 2.4512043627544617e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0002896738502393231, 'tol': 0.020757587419197917, 'validation_fraction': 0.20839712071568275}]
function_evaluation time 1.132550 value 0.245052 suggestion {'alpha': 6.914052338304936e-05, 'batch_size': 96, 'beta_1': 0.6913841421959795, 'beta_2': 0.9998098776381845, 'epsilon': 2.4512043627544617e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0002896738502393231, 'tol': 0.020757587419197917, 'validation_fraction': 0.20839712071568275}
observation time 0.001376, current best 0.130678 at iter 8
suggestion time taken 0.001723 iter 9 next_points [{'alpha': 0.2793444704349754, 'batch_size': 209, 'beta_1': 0.9881794801199306, 'beta_2': 0.9800854478087745, 'epsilon': 7.043868733312817e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 3.312246791811705e-05, 'tol': 0.00023797950740269796, 'validation_fraction': 0.8778476431512566}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.801416 value 7.550049 suggestion {'alpha': 0.2793444704349754, 'batch_size': 209, 'beta_1': 0.9881794801199306, 'beta_2': 0.9800854478087745, 'epsilon': 7.043868733312817e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 3.312246791811705e-05, 'tol': 0.00023797950740269796, 'validation_fraction': 0.8778476431512566}
observation time 0.001332, current best 0.130678 at iter 9
suggestion time taken 0.002017 iter 10 next_points [{'alpha': 6.899115476573546, 'batch_size': 243, 'beta_1': 0.954006136794784, 'beta_2': 0.9984532160351436, 'epsilon': 1.6289866166291768e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.09004988516511242, 'tol': 0.0004999380585566663, 'validation_fraction': 0.7301724582870439}]
function_evaluation time 0.603856 value 0.364477 suggestion {'alpha': 6.899115476573546, 'batch_size': 243, 'beta_1': 0.954006136794784, 'beta_2': 0.9984532160351436, 'epsilon': 1.6289866166291768e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.09004988516511242, 'tol': 0.0004999380585566663, 'validation_fraction': 0.7301724582870439}
observation time 0.001342, current best 0.130678 at iter 10
suggestion time taken 0.001933 iter 11 next_points [{'alpha': 0.04997041865199336, 'batch_size': 141, 'beta_1': 0.6420573128821279, 'beta_2': 0.9999949772167664, 'epsilon': 3.287506964954365e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.005425355005074903, 'tol': 0.006179125159614962, 'validation_fraction': 0.750880256732754}]
function_evaluation time 0.531102 value 0.238035 suggestion {'alpha': 0.04997041865199336, 'batch_size': 141, 'beta_1': 0.6420573128821279, 'beta_2': 0.9999949772167664, 'epsilon': 3.287506964954365e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.005425355005074903, 'tol': 0.006179125159614962, 'validation_fraction': 0.750880256732754}
observation time 0.001344, current best 0.130678 at iter 11
suggestion time taken 0.001715 iter 12 next_points [{'alpha': 0.24633939450214107, 'batch_size': 46, 'beta_1': 0.9114995353893893, 'beta_2': 0.9935099662389522, 'epsilon': 3.454330324734103e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 1.767903415625037e-05, 'tol': 3.269337030653643e-05, 'validation_fraction': 0.2596510508621315}]
function_evaluation time 8.199529 value 3.154562 suggestion {'alpha': 0.24633939450214107, 'batch_size': 46, 'beta_1': 0.9114995353893893, 'beta_2': 0.9935099662389522, 'epsilon': 3.454330324734103e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 1.767903415625037e-05, 'tol': 3.269337030653643e-05, 'validation_fraction': 0.2596510508621315}
observation time 0.001339, current best 0.130678 at iter 12
suggestion time taken 0.001721 iter 13 next_points [{'alpha': 2.2607757379748807e-05, 'batch_size': 220, 'beta_1': 0.9340473250397459, 'beta_2': 0.9999853591936314, 'epsilon': 2.2822297487679366e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0001788988368830057, 'tol': 0.0008506598036336757, 'validation_fraction': 0.16455809243978808}]
function_evaluation time 1.682213 value 2.960954 suggestion {'alpha': 2.2607757379748807e-05, 'batch_size': 220, 'beta_1': 0.9340473250397459, 'beta_2': 0.9999853591936314, 'epsilon': 2.2822297487679366e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0001788988368830057, 'tol': 0.0008506598036336757, 'validation_fraction': 0.16455809243978808}
observation time 0.001347, current best 0.130678 at iter 13
suggestion time taken 0.001738 iter 14 next_points [{'alpha': 0.007366519424602973, 'batch_size': 197, 'beta_1': 0.9452141679462711, 'beta_2': 0.9832302427957926, 'epsilon': 4.774739630577788e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 7.827318935943552e-05, 'tol': 0.012516441919610068, 'validation_fraction': 0.8694442055625322}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.168139 value 7.830452 suggestion {'alpha': 0.007366519424602973, 'batch_size': 197, 'beta_1': 0.9452141679462711, 'beta_2': 0.9832302427957926, 'epsilon': 4.774739630577788e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 7.827318935943552e-05, 'tol': 0.012516441919610068, 'validation_fraction': 0.8694442055625322}
observation time 0.001339, current best 0.130678 at iter 14
saving meta data: {'args': {'--uuid': '4dca24ec64575cb8a273292e32644e06', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
