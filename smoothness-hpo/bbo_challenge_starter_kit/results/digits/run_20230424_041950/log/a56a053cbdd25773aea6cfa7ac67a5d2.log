running: {'--uuid': 'a56a053cbdd25773aea6cfa7ac67a5d2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u a56a053cbdd25773aea6cfa7ac67a5d2 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002598 iter 0 next_points [{'alpha': 0.20303946074700582, 'batch_size': 75, 'beta_1': 0.9891081956972408, 'beta_2': 0.9263445552484096, 'epsilon': 1.4260869210696114e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.004805630749136121, 'tol': 0.007769897789663019, 'validation_fraction': 0.4471643705747102}]
function_evaluation time 0.720957 value -0.951295 suggestion {'alpha': 0.20303946074700582, 'batch_size': 75, 'beta_1': 0.9891081956972408, 'beta_2': 0.9263445552484096, 'epsilon': 1.4260869210696114e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.004805630749136121, 'tol': 0.007769897789663019, 'validation_fraction': 0.4471643705747102}
observation time 0.000006, current best -0.951295 at iter 0
suggestion time taken 0.002492 iter 1 next_points [{'alpha': 3.594211655217598e-05, 'batch_size': 50, 'beta_1': 0.9660452085031982, 'beta_2': 0.9999989610209435, 'epsilon': 7.24434655408941e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.042438894983181444, 'tol': 2.259551560461578e-05, 'validation_fraction': 0.8579245637784506}]
function_evaluation time 0.603341 value -0.607663 suggestion {'alpha': 3.594211655217598e-05, 'batch_size': 50, 'beta_1': 0.9660452085031982, 'beta_2': 0.9999989610209435, 'epsilon': 7.24434655408941e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.042438894983181444, 'tol': 2.259551560461578e-05, 'validation_fraction': 0.8579245637784506}
observation time 0.000005, current best -0.951295 at iter 1
suggestion time taken 0.002852 iter 2 next_points [{'alpha': 2.8284150938361514, 'batch_size': 146, 'beta_1': 0.9065008259980478, 'beta_2': 0.9994440002252607, 'epsilon': 1.7096369718728708e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 1.5254518618205384e-05, 'tol': 0.0011138967087475772, 'validation_fraction': 0.7623689622260293}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.077045 value -0.219851 suggestion {'alpha': 2.8284150938361514, 'batch_size': 146, 'beta_1': 0.9065008259980478, 'beta_2': 0.9994440002252607, 'epsilon': 1.7096369718728708e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 1.5254518618205384e-05, 'tol': 0.0011138967087475772, 'validation_fraction': 0.7623689622260293}
observation time 0.000004, current best -0.951295 at iter 2
suggestion time taken 0.002847 iter 3 next_points [{'alpha': 0.06854312468667505, 'batch_size': 111, 'beta_1': 0.9572793086560513, 'beta_2': 0.9998638904608937, 'epsilon': 3.197454208622044e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.001715979342773918, 'tol': 0.0001481216647688901, 'validation_fraction': 0.15522599702990808}]
function_evaluation time 1.157729 value -0.964516 suggestion {'alpha': 0.06854312468667505, 'batch_size': 111, 'beta_1': 0.9572793086560513, 'beta_2': 0.9998638904608937, 'epsilon': 3.197454208622044e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.001715979342773918, 'tol': 0.0001481216647688901, 'validation_fraction': 0.15522599702990808}
observation time 0.000005, current best -0.964516 at iter 3
suggestion time taken 0.002546 iter 4 next_points [{'alpha': 0.0834595599818482, 'batch_size': 138, 'beta_1': 0.6977737905175142, 'beta_2': 0.9992791043371778, 'epsilon': 6.602963253716171e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.029171293058074668, 'tol': 2.6469883953627438e-05, 'validation_fraction': 0.34576197584830687}]
function_evaluation time 0.832609 value -0.958249 suggestion {'alpha': 0.0834595599818482, 'batch_size': 138, 'beta_1': 0.6977737905175142, 'beta_2': 0.9992791043371778, 'epsilon': 6.602963253716171e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.029171293058074668, 'tol': 2.6469883953627438e-05, 'validation_fraction': 0.34576197584830687}
observation time 0.000005, current best -0.964516 at iter 4
suggestion time taken 0.002462 iter 5 next_points [{'alpha': 0.014169819098282377, 'batch_size': 209, 'beta_1': 0.9787698910847281, 'beta_2': 0.9999745933032359, 'epsilon': 5.490434588597736e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.002034575613805724, 'tol': 0.01151289693768954, 'validation_fraction': 0.7850315453357813}]
function_evaluation time 0.403838 value -0.876120 suggestion {'alpha': 0.014169819098282377, 'batch_size': 209, 'beta_1': 0.9787698910847281, 'beta_2': 0.9999745933032359, 'epsilon': 5.490434588597736e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.002034575613805724, 'tol': 0.01151289693768954, 'validation_fraction': 0.7850315453357813}
observation time 0.000005, current best -0.964516 at iter 5
suggestion time taken 0.002501 iter 6 next_points [{'alpha': 0.0002836814518833989, 'batch_size': 139, 'beta_1': 0.9686993648405952, 'beta_2': 0.9763923431623536, 'epsilon': 2.8590505737972335e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.015857844775968254, 'tol': 0.011726898666586348, 'validation_fraction': 0.8321468035599388}]
function_evaluation time 0.490874 value -0.893530 suggestion {'alpha': 0.0002836814518833989, 'batch_size': 139, 'beta_1': 0.9686993648405952, 'beta_2': 0.9763923431623536, 'epsilon': 2.8590505737972335e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.015857844775968254, 'tol': 0.011726898666586348, 'validation_fraction': 0.8321468035599388}
observation time 0.000004, current best -0.964516 at iter 6
suggestion time taken 0.002510 iter 7 next_points [{'alpha': 0.0005859888549504062, 'batch_size': 225, 'beta_1': 0.5029334422420689, 'beta_2': 0.9988860119935817, 'epsilon': 2.002901636477836e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0001523181911035287, 'tol': 0.0001410675315260802, 'validation_fraction': 0.619445939795175}]
function_evaluation time 2.213887 value -0.827400 suggestion {'alpha': 0.0005859888549504062, 'batch_size': 225, 'beta_1': 0.5029334422420689, 'beta_2': 0.9988860119935817, 'epsilon': 2.002901636477836e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0001523181911035287, 'tol': 0.0001410675315260802, 'validation_fraction': 0.619445939795175}
observation time 0.000005, current best -0.964516 at iter 7
suggestion time taken 0.002484 iter 8 next_points [{'alpha': 4.909754872610572e-05, 'batch_size': 20, 'beta_1': 0.9685845485575881, 'beta_2': 0.9996762296901077, 'epsilon': 6.123271159266357e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.010486628600093436, 'tol': 9.147163537823438e-05, 'validation_fraction': 0.19727462735755646}]
function_evaluation time 2.409252 value -0.961733 suggestion {'alpha': 4.909754872610572e-05, 'batch_size': 20, 'beta_1': 0.9685845485575881, 'beta_2': 0.9996762296901077, 'epsilon': 6.123271159266357e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.010486628600093436, 'tol': 9.147163537823438e-05, 'validation_fraction': 0.19727462735755646}
observation time 0.000005, current best -0.964516 at iter 8
suggestion time taken 0.002773 iter 9 next_points [{'alpha': 0.00935116524784047, 'batch_size': 93, 'beta_1': 0.8991017895786358, 'beta_2': 0.9774108423910656, 'epsilon': 1.3772891959779032e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 7.14336743322241e-05, 'tol': 0.08410322360188278, 'validation_fraction': 0.21886703655184}]
function_evaluation time 0.383080 value -0.195545 suggestion {'alpha': 0.00935116524784047, 'batch_size': 93, 'beta_1': 0.8991017895786358, 'beta_2': 0.9774108423910656, 'epsilon': 1.3772891959779032e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 7.14336743322241e-05, 'tol': 0.08410322360188278, 'validation_fraction': 0.21886703655184}
observation time 0.000004, current best -0.964516 at iter 9
suggestion time taken 0.002804 iter 10 next_points [{'alpha': 0.00010248085319125888, 'batch_size': 219, 'beta_1': 0.7831604580302463, 'beta_2': 0.999203864286644, 'epsilon': 3.281916474039485e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0017239938659875651, 'tol': 7.777153298341033e-05, 'validation_fraction': 0.2396042613207866}]
function_evaluation time 1.065789 value -0.946419 suggestion {'alpha': 0.00010248085319125888, 'batch_size': 219, 'beta_1': 0.7831604580302463, 'beta_2': 0.999203864286644, 'epsilon': 3.281916474039485e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0017239938659875651, 'tol': 7.777153298341033e-05, 'validation_fraction': 0.2396042613207866}
observation time 0.000005, current best -0.964516 at iter 10
suggestion time taken 0.002490 iter 11 next_points [{'alpha': 0.0006825005793764585, 'batch_size': 225, 'beta_1': 0.9608628186664129, 'beta_2': 0.9985787878505596, 'epsilon': 2.07535618286858e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 6.616996981607792e-05, 'tol': 0.0037203260370120843, 'validation_fraction': 0.573981558154864}]
function_evaluation time 2.670739 value -0.816988 suggestion {'alpha': 0.0006825005793764585, 'batch_size': 225, 'beta_1': 0.9608628186664129, 'beta_2': 0.9985787878505596, 'epsilon': 2.07535618286858e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 6.616996981607792e-05, 'tol': 0.0037203260370120843, 'validation_fraction': 0.573981558154864}
observation time 0.000004, current best -0.964516 at iter 11
suggestion time taken 0.002497 iter 12 next_points [{'alpha': 0.03347022726131871, 'batch_size': 245, 'beta_1': 0.7881862520453493, 'beta_2': 0.9999952506117431, 'epsilon': 6.257452383807745e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0006272031508615169, 'tol': 0.007503807618472505, 'validation_fraction': 0.8449672228158319}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.748479 value -0.823224 suggestion {'alpha': 0.03347022726131871, 'batch_size': 245, 'beta_1': 0.7881862520453493, 'beta_2': 0.9999952506117431, 'epsilon': 6.257452383807745e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0006272031508615169, 'tol': 0.007503807618472505, 'validation_fraction': 0.8449672228158319}
observation time 0.000004, current best -0.964516 at iter 12
suggestion time taken 0.002454 iter 13 next_points [{'alpha': 4.3672116951186, 'batch_size': 93, 'beta_1': 0.9515329871761784, 'beta_2': 0.9998915624462652, 'epsilon': 1.4617914170307375e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.023464593970733586, 'tol': 2.1740971478401195e-05, 'validation_fraction': 0.3597890449995037}]
function_evaluation time 1.226299 value -0.961034 suggestion {'alpha': 4.3672116951186, 'batch_size': 93, 'beta_1': 0.9515329871761784, 'beta_2': 0.9998915624462652, 'epsilon': 1.4617914170307375e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.023464593970733586, 'tol': 2.1740971478401195e-05, 'validation_fraction': 0.3597890449995037}
observation time 0.000005, current best -0.964516 at iter 13
suggestion time taken 0.002525 iter 14 next_points [{'alpha': 0.00026388930543327476, 'batch_size': 219, 'beta_1': 0.8168176971634907, 'beta_2': 0.9998489796164277, 'epsilon': 2.6170064242996493e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.02703315486837083, 'tol': 0.00030186805304457996, 'validation_fraction': 0.7051416139313562}]
function_evaluation time 0.593609 value -0.926236 suggestion {'alpha': 0.00026388930543327476, 'batch_size': 219, 'beta_1': 0.8168176971634907, 'beta_2': 0.9998489796164277, 'epsilon': 2.6170064242996493e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.02703315486837083, 'tol': 0.00030186805304457996, 'validation_fraction': 0.7051416139313562}
observation time 0.000004, current best -0.964516 at iter 14
saving meta data: {'args': {'--uuid': 'a56a053cbdd25773aea6cfa7ac67a5d2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
