running: {'--uuid': 'fac1f34813f65c7fb5144bd33bcc321b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u fac1f34813f65c7fb5144bd33bcc321b -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002398 iter 0 next_points [{'alpha': 0.014493815506466943, 'batch_size': 166, 'beta_1': 0.9541571776176839, 'beta_2': 0.9940089256976516, 'epsilon': 1.104202672781103e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.01154261747133804, 'tol': 0.002124728864545343, 'validation_fraction': 0.30187085930946433}]
function_evaluation time 0.869022 value -0.956872 suggestion {'alpha': 0.014493815506466943, 'batch_size': 166, 'beta_1': 0.9541571776176839, 'beta_2': 0.9940089256976516, 'epsilon': 1.104202672781103e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.01154261747133804, 'tol': 0.002124728864545343, 'validation_fraction': 0.30187085930946433}
observation time 0.001390, current best -0.956872 at iter 0
suggestion time taken 0.001755 iter 1 next_points [{'alpha': 0.6438050284042652, 'batch_size': 27, 'beta_1': 0.9406155473925164, 'beta_2': 0.9999939619464254, 'epsilon': 3.2251811100346646e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0001977188145240272, 'tol': 0.0006986545140438341, 'validation_fraction': 0.4425493367585102}]
function_evaluation time 3.655967 value -0.933892 suggestion {'alpha': 0.6438050284042652, 'batch_size': 27, 'beta_1': 0.9406155473925164, 'beta_2': 0.9999939619464254, 'epsilon': 3.2251811100346646e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0001977188145240272, 'tol': 0.0006986545140438341, 'validation_fraction': 0.4425493367585102}
observation time 0.001421, current best -0.956872 at iter 1
suggestion time taken 0.001759 iter 2 next_points [{'alpha': 0.00039112601236533445, 'batch_size': 191, 'beta_1': 0.8606788654116656, 'beta_2': 0.9999986193107444, 'epsilon': 2.685939176686311e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.004046881453694979, 'tol': 1.7468749768894563e-05, 'validation_fraction': 0.5071390817597581}]
function_evaluation time 0.896857 value -0.954774 suggestion {'alpha': 0.00039112601236533445, 'batch_size': 191, 'beta_1': 0.8606788654116656, 'beta_2': 0.9999986193107444, 'epsilon': 2.685939176686311e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.004046881453694979, 'tol': 1.7468749768894563e-05, 'validation_fraction': 0.5071390817597581}
observation time 0.001629, current best -0.956872 at iter 2
suggestion time taken 0.001775 iter 3 next_points [{'alpha': 0.05996336833424543, 'batch_size': 205, 'beta_1': 0.804784804054491, 'beta_2': 0.9999340164295893, 'epsilon': 2.1848413102678666e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.0004247457573118426, 'tol': 0.075973108680917, 'validation_fraction': 0.19550274948367097}]
function_evaluation time 0.553013 value -0.852495 suggestion {'alpha': 0.05996336833424543, 'batch_size': 205, 'beta_1': 0.804784804054491, 'beta_2': 0.9999340164295893, 'epsilon': 2.1848413102678666e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.0004247457573118426, 'tol': 0.075973108680917, 'validation_fraction': 0.19550274948367097}
observation time 0.001336, current best -0.956872 at iter 3
suggestion time taken 0.001737 iter 4 next_points [{'alpha': 0.08451297588958354, 'batch_size': 248, 'beta_1': 0.5135509801024578, 'beta_2': 0.9997910371100199, 'epsilon': 1.1083819613327102e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 7.610273857833162e-05, 'tol': 0.046725600219753714, 'validation_fraction': 0.8036981786700651}]
function_evaluation time 0.191319 value -0.140534 suggestion {'alpha': 0.08451297588958354, 'batch_size': 248, 'beta_1': 0.5135509801024578, 'beta_2': 0.9997910371100199, 'epsilon': 1.1083819613327102e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 7.610273857833162e-05, 'tol': 0.046725600219753714, 'validation_fraction': 0.8036981786700651}
observation time 0.001385, current best -0.956872 at iter 4
suggestion time taken 0.002016 iter 5 next_points [{'alpha': 0.005511602892819548, 'batch_size': 187, 'beta_1': 0.7038731109286807, 'beta_2': 0.9970299201964169, 'epsilon': 5.345149115424968e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.06508106575020486, 'tol': 4.050668863717753e-05, 'validation_fraction': 0.8504997615135486}]
function_evaluation time 0.734225 value -0.819086 suggestion {'alpha': 0.005511602892819548, 'batch_size': 187, 'beta_1': 0.7038731109286807, 'beta_2': 0.9970299201964169, 'epsilon': 5.345149115424968e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.06508106575020486, 'tol': 4.050668863717753e-05, 'validation_fraction': 0.8504997615135486}
observation time 0.001366, current best -0.956872 at iter 5
suggestion time taken 0.002040 iter 6 next_points [{'alpha': 4.092390355574148, 'batch_size': 84, 'beta_1': 0.9227454678052853, 'beta_2': 0.999983942470366, 'epsilon': 1.5433262427857949e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 1.1348171130329582e-05, 'tol': 7.483989692876834e-05, 'validation_fraction': 0.12305426443991005}]
function_evaluation time 4.734131 value -0.372181 suggestion {'alpha': 4.092390355574148, 'batch_size': 84, 'beta_1': 0.9227454678052853, 'beta_2': 0.999983942470366, 'epsilon': 1.5433262427857949e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 1.1348171130329582e-05, 'tol': 7.483989692876834e-05, 'validation_fraction': 0.12305426443991005}
observation time 0.001613, current best -0.956872 at iter 6
suggestion time taken 0.001768 iter 7 next_points [{'alpha': 4.244223224948627e-05, 'batch_size': 57, 'beta_1': 0.9899792252993611, 'beta_2': 0.966426786726138, 'epsilon': 1.6713858172049069e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0009186532068220419, 'tol': 0.007077243670918944, 'validation_fraction': 0.8818985950112821}]
function_evaluation time 0.560031 value -0.781485 suggestion {'alpha': 4.244223224948627e-05, 'batch_size': 57, 'beta_1': 0.9899792252993611, 'beta_2': 0.966426786726138, 'epsilon': 1.6713858172049069e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0009186532068220419, 'tol': 0.007077243670918944, 'validation_fraction': 0.8818985950112821}
observation time 0.001340, current best -0.956872 at iter 7
suggestion time taken 0.001780 iter 8 next_points [{'alpha': 1.8343642136043767e-05, 'batch_size': 155, 'beta_1': 0.9763194555888445, 'beta_2': 0.9719530477719441, 'epsilon': 5.508616330476479e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.029217140237374782, 'tol': 0.00020298950089326853, 'validation_fraction': 0.35552434578002834}]
function_evaluation time 0.819807 value -0.936017 suggestion {'alpha': 1.8343642136043767e-05, 'batch_size': 155, 'beta_1': 0.9763194555888445, 'beta_2': 0.9719530477719441, 'epsilon': 5.508616330476479e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.029217140237374782, 'tol': 0.00020298950089326853, 'validation_fraction': 0.35552434578002834}
observation time 0.001352, current best -0.956872 at iter 8
suggestion time taken 0.001736 iter 9 next_points [{'alpha': 8.560216051122143, 'batch_size': 131, 'beta_1': 0.9647786144554631, 'beta_2': 0.9999637924460105, 'epsilon': 3.516568214453682e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 4.661232101630295e-05, 'tol': 0.000989020059669291, 'validation_fraction': 0.5756752599601943}]
function_evaluation time 5.010158 value -0.858735 suggestion {'alpha': 8.560216051122143, 'batch_size': 131, 'beta_1': 0.9647786144554631, 'beta_2': 0.9999637924460105, 'epsilon': 3.516568214453682e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 4.661232101630295e-05, 'tol': 0.000989020059669291, 'validation_fraction': 0.5756752599601943}
observation time 0.001329, current best -0.956872 at iter 9
suggestion time taken 0.001725 iter 10 next_points [{'alpha': 1.5993502182966497, 'batch_size': 87, 'beta_1': 0.8934236280618987, 'beta_2': 0.9997074364658949, 'epsilon': 6.957228956346781e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.008741459918688601, 'tol': 0.0003639216302555302, 'validation_fraction': 0.3926819872500605}]
function_evaluation time 0.767635 value -0.952688 suggestion {'alpha': 1.5993502182966497, 'batch_size': 87, 'beta_1': 0.8934236280618987, 'beta_2': 0.9997074364658949, 'epsilon': 6.957228956346781e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.008741459918688601, 'tol': 0.0003639216302555302, 'validation_fraction': 0.3926819872500605}
observation time 0.001384, current best -0.956872 at iter 10
suggestion time taken 0.001707 iter 11 next_points [{'alpha': 6.571393630948226e-05, 'batch_size': 14, 'beta_1': 0.6041802900871074, 'beta_2': 0.9980632169469279, 'epsilon': 1.9992746009120064e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0014082042895206806, 'tol': 0.004412455861782768, 'validation_fraction': 0.5925936591318633}]
function_evaluation time 1.733636 value -0.956168 suggestion {'alpha': 6.571393630948226e-05, 'batch_size': 14, 'beta_1': 0.6041802900871074, 'beta_2': 0.9980632169469279, 'epsilon': 1.9992746009120064e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0014082042895206806, 'tol': 0.004412455861782768, 'validation_fraction': 0.5925936591318633}
observation time 0.001388, current best -0.956872 at iter 11
suggestion time taken 0.001695 iter 12 next_points [{'alpha': 0.0017924160324287615, 'batch_size': 226, 'beta_1': 0.9839425610388474, 'beta_2': 0.9998672199922757, 'epsilon': 1.2707878063485866e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.021952395315893644, 'tol': 1.1095681947734925e-05, 'validation_fraction': 0.829315119136016}]
function_evaluation time 0.583469 value -0.817637 suggestion {'alpha': 0.0017924160324287615, 'batch_size': 226, 'beta_1': 0.9839425610388474, 'beta_2': 0.9998672199922757, 'epsilon': 1.2707878063485866e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.021952395315893644, 'tol': 1.1095681947734925e-05, 'validation_fraction': 0.829315119136016}
observation time 0.001410, current best -0.956872 at iter 12
suggestion time taken 0.001665 iter 13 next_points [{'alpha': 0.23215989727215075, 'batch_size': 221, 'beta_1': 0.9174403425462967, 'beta_2': 0.9999922163182584, 'epsilon': 3.8214321924791115e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 2.079346838637204e-05, 'tol': 0.00017713854615758132, 'validation_fraction': 0.2365886897579247}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.713332 value -0.176815 suggestion {'alpha': 0.23215989727215075, 'batch_size': 221, 'beta_1': 0.9174403425462967, 'beta_2': 0.9999922163182584, 'epsilon': 3.8214321924791115e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 2.079346838637204e-05, 'tol': 0.00017713854615758132, 'validation_fraction': 0.2365886897579247}
observation time 0.001370, current best -0.956872 at iter 13
suggestion time taken 0.001683 iter 14 next_points [{'alpha': 0.00013167869273470292, 'batch_size': 113, 'beta_1': 0.972534577512489, 'beta_2': 0.929887492796026, 'epsilon': 3.47177965842363e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.00333145212991571, 'tol': 0.02128839303318852, 'validation_fraction': 0.7051055303881957}]
function_evaluation time 0.351666 value -0.917889 suggestion {'alpha': 0.00013167869273470292, 'batch_size': 113, 'beta_1': 0.972534577512489, 'beta_2': 0.929887492796026, 'epsilon': 3.47177965842363e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.00333145212991571, 'tol': 0.02128839303318852, 'validation_fraction': 0.7051055303881957}
observation time 0.001348, current best -0.956872 at iter 14
saving meta data: {'args': {'--uuid': 'fac1f34813f65c7fb5144bd33bcc321b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
