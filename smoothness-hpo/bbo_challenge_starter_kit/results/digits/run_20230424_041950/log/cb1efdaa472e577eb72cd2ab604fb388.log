running: {'--uuid': 'cb1efdaa472e577eb72cd2ab604fb388', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u cb1efdaa472e577eb72cd2ab604fb388 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002182 iter 0 next_points [{'alpha': 0.009770342773507431, 'batch_size': 126, 'beta_1': 0.9147272994795216, 'beta_2': 0.9994598259553814, 'epsilon': 4.207133267799302e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006550450510642073, 'tol': 0.0004997696129614238, 'validation_fraction': 0.41219652004722424}]
function_evaluation time 0.849699 value 0.172600 suggestion {'alpha': 0.009770342773507431, 'batch_size': 126, 'beta_1': 0.9147272994795216, 'beta_2': 0.9994598259553814, 'epsilon': 4.207133267799302e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006550450510642073, 'tol': 0.0004997696129614238, 'validation_fraction': 0.41219652004722424}
observation time 0.001405, current best 0.172600 at iter 0
suggestion time taken 0.001793 iter 1 next_points [{'alpha': 0.2914873998041566, 'batch_size': 230, 'beta_1': 0.9217879293599275, 'beta_2': 0.9999989171747837, 'epsilon': 1.7419725092266948e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.04276704122934775, 'tol': 0.06899329284177033, 'validation_fraction': 0.8031766317284612}]
function_evaluation time 0.188775 value 1.436863 suggestion {'alpha': 0.2914873998041566, 'batch_size': 230, 'beta_1': 0.9217879293599275, 'beta_2': 0.9999989171747837, 'epsilon': 1.7419725092266948e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.04276704122934775, 'tol': 0.06899329284177033, 'validation_fraction': 0.8031766317284612}
observation time 0.001403, current best 0.172600 at iter 1
suggestion time taken 0.001814 iter 2 next_points [{'alpha': 1.7500670869050083e-05, 'batch_size': 183, 'beta_1': 0.9864242463846498, 'beta_2': 0.9999877289623729, 'epsilon': 7.868861934843314e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.015997575000012282, 'tol': 0.001744762098982351, 'validation_fraction': 0.8885389350400411}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.530128 value 0.570987 suggestion {'alpha': 1.7500670869050083e-05, 'batch_size': 183, 'beta_1': 0.9864242463846498, 'beta_2': 0.9999877289623729, 'epsilon': 7.868861934843314e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.015997575000012282, 'tol': 0.001744762098982351, 'validation_fraction': 0.8885389350400411}
observation time 0.001502, current best 0.172600 at iter 2
suggestion time taken 0.001737 iter 3 next_points [{'alpha': 0.0002797280785479967, 'batch_size': 70, 'beta_1': 0.7438114177836904, 'beta_2': 0.9999959767461495, 'epsilon': 6.688713597069552e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.014377789086061596, 'tol': 0.005894446608526543, 'validation_fraction': 0.21029050112258316}]
function_evaluation time 0.838851 value 0.111677 suggestion {'alpha': 0.0002797280785479967, 'batch_size': 70, 'beta_1': 0.7438114177836904, 'beta_2': 0.9999959767461495, 'epsilon': 6.688713597069552e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.014377789086061596, 'tol': 0.005894446608526543, 'validation_fraction': 0.21029050112258316}
observation time 0.001403, current best 0.111677 at iter 3
suggestion time taken 0.001757 iter 4 next_points [{'alpha': 5.971783727821347e-05, 'batch_size': 49, 'beta_1': 0.5380689629551652, 'beta_2': 0.9893303393353974, 'epsilon': 1.1849500333396049e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00046495863856962124, 'tol': 0.00038839993524713656, 'validation_fraction': 0.840716250941789}]
function_evaluation time 2.390384 value 0.382123 suggestion {'alpha': 5.971783727821347e-05, 'batch_size': 49, 'beta_1': 0.5380689629551652, 'beta_2': 0.9893303393353974, 'epsilon': 1.1849500333396049e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00046495863856962124, 'tol': 0.00038839993524713656, 'validation_fraction': 0.840716250941789}
observation time 0.001385, current best 0.111677 at iter 4
suggestion time taken 0.001778 iter 5 next_points [{'alpha': 0.049669369728046565, 'batch_size': 20, 'beta_1': 0.6552383760542134, 'beta_2': 0.9775991976060171, 'epsilon': 1.3632304600511786e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 2.711640277810816e-05, 'tol': 0.0045925412033957416, 'validation_fraction': 0.8683892846783602}]
function_evaluation time 2.060151 value 3.422552 suggestion {'alpha': 0.049669369728046565, 'batch_size': 20, 'beta_1': 0.6552383760542134, 'beta_2': 0.9775991976060171, 'epsilon': 1.3632304600511786e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 2.711640277810816e-05, 'tol': 0.0045925412033957416, 'validation_fraction': 0.8683892846783602}
observation time 0.001374, current best 0.111677 at iter 5
suggestion time taken 0.001745 iter 6 next_points [{'alpha': 2.016513431274579, 'batch_size': 100, 'beta_1': 0.9427873798703891, 'beta_2': 0.9999782190881676, 'epsilon': 4.093151238925859e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 1.497875189452927e-05, 'tol': 0.0002446558218434841, 'validation_fraction': 0.4646624642775999}]
function_evaluation time 1.773864 value 9.911647 suggestion {'alpha': 2.016513431274579, 'batch_size': 100, 'beta_1': 0.9427873798703891, 'beta_2': 0.9999782190881676, 'epsilon': 4.093151238925859e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 1.497875189452927e-05, 'tol': 0.0002446558218434841, 'validation_fraction': 0.4646624642775999}
observation time 0.001410, current best 0.111677 at iter 6
suggestion time taken 0.002058 iter 7 next_points [{'alpha': 0.2038540643144714, 'batch_size': 197, 'beta_1': 0.9673674885162103, 'beta_2': 0.9007702921706212, 'epsilon': 1.5679281001554442e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0006132675570454236, 'tol': 0.002139499881536276, 'validation_fraction': 0.6098735666999583}]
function_evaluation time 1.313907 value 0.214438 suggestion {'alpha': 0.2038540643144714, 'batch_size': 197, 'beta_1': 0.9673674885162103, 'beta_2': 0.9007702921706212, 'epsilon': 1.5679281001554442e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0006132675570454236, 'tol': 0.002139499881536276, 'validation_fraction': 0.6098735666999583}
observation time 0.001375, current best 0.111677 at iter 7
suggestion time taken 0.001792 iter 8 next_points [{'alpha': 0.8325993666892941, 'batch_size': 43, 'beta_1': 0.9802594180984856, 'beta_2': 0.9999928135533194, 'epsilon': 3.6979054576910925e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0018435464386131215, 'tol': 0.05875649243651429, 'validation_fraction': 0.7692865827484335}]
function_evaluation time 0.349343 value 0.380095 suggestion {'alpha': 0.8325993666892941, 'batch_size': 43, 'beta_1': 0.9802594180984856, 'beta_2': 0.9999928135533194, 'epsilon': 3.6979054576910925e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0018435464386131215, 'tol': 0.05875649243651429, 'validation_fraction': 0.7692865827484335}
observation time 0.001457, current best 0.111677 at iter 8
suggestion time taken 0.001721 iter 9 next_points [{'alpha': 0.003541565958330423, 'batch_size': 78, 'beta_1': 0.9747218814366196, 'beta_2': 0.9913575175645469, 'epsilon': 2.0133129645934626e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.00015088354053465085, 'tol': 0.01579105440251453, 'validation_fraction': 0.11624892412479815}]
function_evaluation time 1.694269 value 0.337527 suggestion {'alpha': 0.003541565958330423, 'batch_size': 78, 'beta_1': 0.9747218814366196, 'beta_2': 0.9913575175645469, 'epsilon': 2.0133129645934626e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.00015088354053465085, 'tol': 0.01579105440251453, 'validation_fraction': 0.11624892412479815}
observation time 0.001364, current best 0.111677 at iter 9
suggestion time taken 0.001761 iter 10 next_points [{'alpha': 0.022907090253406096, 'batch_size': 223, 'beta_1': 0.9875145908852668, 'beta_2': 0.9998200852119122, 'epsilon': 3.421107661386575e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.005225559460890337, 'tol': 1.8024498941524434e-05, 'validation_fraction': 0.7015693637221251}]
function_evaluation time 0.806362 value 0.314783 suggestion {'alpha': 0.022907090253406096, 'batch_size': 223, 'beta_1': 0.9875145908852668, 'beta_2': 0.9998200852119122, 'epsilon': 3.421107661386575e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.005225559460890337, 'tol': 1.8024498941524434e-05, 'validation_fraction': 0.7015693637221251}
observation time 0.001405, current best 0.111677 at iter 10
suggestion time taken 0.001728 iter 11 next_points [{'alpha': 0.0007101679102315167, 'batch_size': 98, 'beta_1': 0.6095605488609637, 'beta_2': 0.9979965872096208, 'epsilon': 6.051231728540398e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00028680161435530767, 'tol': 4.417961089215802e-05, 'validation_fraction': 0.3207470623336616}]
function_evaluation time 2.361171 value 0.231246 suggestion {'alpha': 0.0007101679102315167, 'batch_size': 98, 'beta_1': 0.6095605488609637, 'beta_2': 0.9979965872096208, 'epsilon': 6.051231728540398e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00028680161435530767, 'tol': 4.417961089215802e-05, 'validation_fraction': 0.3207470623336616}
observation time 0.001363, current best 0.111677 at iter 11
suggestion time taken 0.001751 iter 12 next_points [{'alpha': 0.06495709411057378, 'batch_size': 155, 'beta_1': 0.948043579181343, 'beta_2': 0.9964410968020726, 'epsilon': 1.2458480743215812e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.003353881326044708, 'tol': 0.00015136116560365406, 'validation_fraction': 0.6419996323370519}]
function_evaluation time 0.922652 value 0.186418 suggestion {'alpha': 0.06495709411057378, 'batch_size': 155, 'beta_1': 0.948043579181343, 'beta_2': 0.9964410968020726, 'epsilon': 1.2458480743215812e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.003353881326044708, 'tol': 0.00015136116560365406, 'validation_fraction': 0.6419996323370519}
observation time 0.001355, current best 0.111677 at iter 12
suggestion time taken 0.001737 iter 13 next_points [{'alpha': 6.227060569415688, 'batch_size': 116, 'beta_1': 0.9656830895704724, 'beta_2': 0.9990595641531088, 'epsilon': 2.5560699062007536e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 5.3226506366758326e-05, 'tol': 0.035414207977452275, 'validation_fraction': 0.287348434831583}]
function_evaluation time 0.354595 value 7.375742 suggestion {'alpha': 6.227060569415688, 'batch_size': 116, 'beta_1': 0.9656830895704724, 'beta_2': 0.9990595641531088, 'epsilon': 2.5560699062007536e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 5.3226506366758326e-05, 'tol': 0.035414207977452275, 'validation_fraction': 0.287348434831583}
observation time 0.001359, current best 0.111677 at iter 13
suggestion time taken 0.001765 iter 14 next_points [{'alpha': 2.5064296894066158e-05, 'batch_size': 162, 'beta_1': 0.7877723788713195, 'beta_2': 0.9999968992508274, 'epsilon': 4.546893473556086e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0837644313597884, 'tol': 8.84379561630177e-05, 'validation_fraction': 0.2495328790756913}]
function_evaluation time 0.892581 value 1.529392 suggestion {'alpha': 2.5064296894066158e-05, 'batch_size': 162, 'beta_1': 0.7877723788713195, 'beta_2': 0.9999968992508274, 'epsilon': 4.546893473556086e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0837644313597884, 'tol': 8.84379561630177e-05, 'validation_fraction': 0.2495328790756913}
observation time 0.001365, current best 0.111677 at iter 14
saving meta data: {'args': {'--uuid': 'cb1efdaa472e577eb72cd2ab604fb388', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
