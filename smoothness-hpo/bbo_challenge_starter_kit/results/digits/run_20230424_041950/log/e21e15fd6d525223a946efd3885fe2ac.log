running: {'--uuid': 'e21e15fd6d525223a946efd3885fe2ac', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u e21e15fd6d525223a946efd3885fe2ac -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_041950
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002100 iter 0 next_points [{'alpha': 6.027453155327518, 'batch_size': 126, 'beta_1': 0.6752680871575893, 'beta_2': 0.9999877437621723, 'epsilon': 4.325690540828484e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00012240390266119496, 'tol': 1.2334504525019228e-05, 'validation_fraction': 0.5397392473665056}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.367413 value 2.278543 suggestion {'alpha': 6.027453155327518, 'batch_size': 126, 'beta_1': 0.6752680871575893, 'beta_2': 0.9999877437621723, 'epsilon': 4.325690540828484e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00012240390266119496, 'tol': 1.2334504525019228e-05, 'validation_fraction': 0.5397392473665056}
observation time 0.001409, current best 2.278543 at iter 0
suggestion time taken 0.001784 iter 1 next_points [{'alpha': 3.311961556991468, 'batch_size': 84, 'beta_1': 0.5579724071029472, 'beta_2': 0.9997514339822032, 'epsilon': 1.240899200133713e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.003932169999429311, 'tol': 8.770718989677278e-05, 'validation_fraction': 0.6977537050920672}]
function_evaluation time 0.976100 value 0.207728 suggestion {'alpha': 3.311961556991468, 'batch_size': 84, 'beta_1': 0.5579724071029472, 'beta_2': 0.9997514339822032, 'epsilon': 1.240899200133713e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.003932169999429311, 'tol': 8.770718989677278e-05, 'validation_fraction': 0.6977537050920672}
observation time 0.001387, current best 0.207728 at iter 1
suggestion time taken 0.001722 iter 2 next_points [{'alpha': 0.007537264515718685, 'batch_size': 197, 'beta_1': 0.9654748697064214, 'beta_2': 0.9999000570807949, 'epsilon': 8.642663609381243e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0020569647619004773, 'tol': 5.519699493350896e-05, 'validation_fraction': 0.60062295332533}]
function_evaluation time 1.237971 value 0.212327 suggestion {'alpha': 0.007537264515718685, 'batch_size': 197, 'beta_1': 0.9654748697064214, 'beta_2': 0.9999000570807949, 'epsilon': 8.642663609381243e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0020569647619004773, 'tol': 5.519699493350896e-05, 'validation_fraction': 0.60062295332533}
observation time 0.001635, current best 0.207728 at iter 2
suggestion time taken 0.001757 iter 3 next_points [{'alpha': 0.17294933867340723, 'batch_size': 217, 'beta_1': 0.987117887095805, 'beta_2': 0.9725995690103786, 'epsilon': 5.559337013154985e-08, 'hidden_layer_sizes': 197, 'learning_rate_init': 4.5710704072681336e-05, 'tol': 0.0004313863415225113, 'validation_fraction': 0.3731734602854858}]
function_evaluation time 4.100525 value 1.286935 suggestion {'alpha': 0.17294933867340723, 'batch_size': 217, 'beta_1': 0.987117887095805, 'beta_2': 0.9725995690103786, 'epsilon': 5.559337013154985e-08, 'hidden_layer_sizes': 197, 'learning_rate_init': 4.5710704072681336e-05, 'tol': 0.0004313863415225113, 'validation_fraction': 0.3731734602854858}
observation time 0.001394, current best 0.207728 at iter 3
suggestion time taken 0.001736 iter 4 next_points [{'alpha': 1.6974347308671772e-05, 'batch_size': 94, 'beta_1': 0.8040887482687458, 'beta_2': 0.9999952442230172, 'epsilon': 2.1888857093231466e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.878168982404594e-05, 'tol': 0.08894599030302726, 'validation_fraction': 0.6675658346668315}]
function_evaluation time 0.236338 value 10.041847 suggestion {'alpha': 1.6974347308671772e-05, 'batch_size': 94, 'beta_1': 0.8040887482687458, 'beta_2': 0.9999952442230172, 'epsilon': 2.1888857093231466e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.878168982404594e-05, 'tol': 0.08894599030302726, 'validation_fraction': 0.6675658346668315}
observation time 0.001371, current best 0.207728 at iter 4
suggestion time taken 0.001770 iter 5 next_points [{'alpha': 0.9839711844855977, 'batch_size': 176, 'beta_1': 0.843847978554305, 'beta_2': 0.9999987169898962, 'epsilon': 6.725905426006364e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 3.149806080291994e-05, 'tol': 0.028945671208842477, 'validation_fraction': 0.15728327491812516}]
function_evaluation time 0.430367 value 8.954408 suggestion {'alpha': 0.9839711844855977, 'batch_size': 176, 'beta_1': 0.843847978554305, 'beta_2': 0.9999987169898962, 'epsilon': 6.725905426006364e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 3.149806080291994e-05, 'tol': 0.028945671208842477, 'validation_fraction': 0.15728327491812516}
observation time 0.001408, current best 0.207728 at iter 5
suggestion time taken 0.001705 iter 6 next_points [{'alpha': 0.07059995127457475, 'batch_size': 64, 'beta_1': 0.9683441713971842, 'beta_2': 0.9911105557982125, 'epsilon': 1.832171529683457e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0006460120533319089, 'tol': 0.009459294569310215, 'validation_fraction': 0.2248426149290853}]
function_evaluation time 1.079988 value 0.153846 suggestion {'alpha': 0.07059995127457475, 'batch_size': 64, 'beta_1': 0.9683441713971842, 'beta_2': 0.9911105557982125, 'epsilon': 1.832171529683457e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0006460120533319089, 'tol': 0.009459294569310215, 'validation_fraction': 0.2248426149290853}
observation time 0.001343, current best 0.153846 at iter 6
suggestion time taken 0.001770 iter 7 next_points [{'alpha': 0.002763747238619229, 'batch_size': 173, 'beta_1': 0.9572291271613673, 'beta_2': 0.9999733656819917, 'epsilon': 2.5323366957520384e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.026620151725697212, 'tol': 0.003945280166909241, 'validation_fraction': 0.28687374406052835}]
function_evaluation time 0.721718 value 0.234459 suggestion {'alpha': 0.002763747238619229, 'batch_size': 173, 'beta_1': 0.9572291271613673, 'beta_2': 0.9999733656819917, 'epsilon': 2.5323366957520384e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.026620151725697212, 'tol': 0.003945280166909241, 'validation_fraction': 0.28687374406052835}
observation time 0.001358, current best 0.153846 at iter 7
suggestion time taken 0.001770 iter 8 next_points [{'alpha': 0.03839777494956072, 'batch_size': 107, 'beta_1': 0.6313107862785383, 'beta_2': 0.9998554484374046, 'epsilon': 3.3194988764372995e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00615308346228075, 'tol': 0.0009285050975042066, 'validation_fraction': 0.33310362604237254}]
function_evaluation time 0.781610 value 0.157979 suggestion {'alpha': 0.03839777494956072, 'batch_size': 107, 'beta_1': 0.6313107862785383, 'beta_2': 0.9998554484374046, 'epsilon': 3.3194988764372995e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00615308346228075, 'tol': 0.0009285050975042066, 'validation_fraction': 0.33310362604237254}
observation time 0.001405, current best 0.153846 at iter 8
suggestion time taken 0.001720 iter 9 next_points [{'alpha': 0.000713023702298266, 'batch_size': 48, 'beta_1': 0.932758905947278, 'beta_2': 0.9999971926312446, 'epsilon': 2.8310722894190387e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00333937946106528, 'tol': 0.0001834146696892169, 'validation_fraction': 0.8480078448940387}]
function_evaluation time 0.835958 value 0.391686 suggestion {'alpha': 0.000713023702298266, 'batch_size': 48, 'beta_1': 0.932758905947278, 'beta_2': 0.9999971926312446, 'epsilon': 2.8310722894190387e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00333937946106528, 'tol': 0.0001834146696892169, 'validation_fraction': 0.8480078448940387}
observation time 0.001364, current best 0.153846 at iter 9
suggestion time taken 0.001722 iter 10 next_points [{'alpha': 0.0012948744361131706, 'batch_size': 156, 'beta_1': 0.618050965472671, 'beta_2': 0.9032384181415818, 'epsilon': 6.4274107102020615e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00026746907252059125, 'tol': 0.0006370184481977165, 'validation_fraction': 0.44791285639381634}]
function_evaluation time 2.245972 value 0.149220 suggestion {'alpha': 0.0012948744361131706, 'batch_size': 156, 'beta_1': 0.618050965472671, 'beta_2': 0.9032384181415818, 'epsilon': 6.4274107102020615e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00026746907252059125, 'tol': 0.0006370184481977165, 'validation_fraction': 0.44791285639381634}
observation time 0.001387, current best 0.149220 at iter 10
suggestion time taken 0.001699 iter 11 next_points [{'alpha': 0.00013787895733967037, 'batch_size': 13, 'beta_1': 0.903105309939547, 'beta_2': 0.9999299639162367, 'epsilon': 4.6227282351322815e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.011231369132739451, 'tol': 1.902163974519938e-05, 'validation_fraction': 0.13870564703139737}]
function_evaluation time 3.654290 value 0.200388 suggestion {'alpha': 0.00013787895733967037, 'batch_size': 13, 'beta_1': 0.903105309939547, 'beta_2': 0.9999299639162367, 'epsilon': 4.6227282351322815e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.011231369132739451, 'tol': 1.902163974519938e-05, 'validation_fraction': 0.13870564703139737}
observation time 0.001338, current best 0.149220 at iter 11
suggestion time taken 0.001673 iter 12 next_points [{'alpha': 0.00022075228678102707, 'batch_size': 235, 'beta_1': 0.9362747960141521, 'beta_2': 0.9963872545705222, 'epsilon': 9.497811479773551e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.05635648895235728, 'tol': 0.0015449768078316228, 'validation_fraction': 0.8941311186697088}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.363487 value 2.230340 suggestion {'alpha': 0.00022075228678102707, 'batch_size': 235, 'beta_1': 0.9362747960141521, 'beta_2': 0.9963872545705222, 'epsilon': 9.497811479773551e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.05635648895235728, 'tol': 0.0015449768078316228, 'validation_fraction': 0.8941311186697088}
observation time 0.001400, current best 0.149220 at iter 12
suggestion time taken 0.001725 iter 13 next_points [{'alpha': 8.331812091888418e-05, 'batch_size': 147, 'beta_1': 0.976333976618493, 'beta_2': 0.998752471165809, 'epsilon': 8.931915745131219e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0003693920336519915, 'tol': 0.002795683070909508, 'validation_fraction': 0.7455961584779796}]
function_evaluation time 1.345247 value 0.321377 suggestion {'alpha': 8.331812091888418e-05, 'batch_size': 147, 'beta_1': 0.976333976618493, 'beta_2': 0.998752471165809, 'epsilon': 8.931915745131219e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0003693920336519915, 'tol': 0.002795683070909508, 'validation_fraction': 0.7455961584779796}
observation time 0.001339, current best 0.149220 at iter 13
suggestion time taken 0.001734 iter 14 next_points [{'alpha': 0.015839250899761174, 'batch_size': 199, 'beta_1': 0.9817377484300742, 'beta_2': 0.9840482360460306, 'epsilon': 1.4188151945265835e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0008668742845659871, 'tol': 0.03823282072419989, 'validation_fraction': 0.8662969626231081}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.183915 value 3.346704 suggestion {'alpha': 0.015839250899761174, 'batch_size': 199, 'beta_1': 0.9817377484300742, 'beta_2': 0.9840482360460306, 'epsilon': 1.4188151945265835e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0008668742845659871, 'tol': 0.03823282072419989, 'validation_fraction': 0.8662969626231081}
observation time 0.001394, current best 0.149220 at iter 14
saving meta data: {'args': {'--uuid': 'e21e15fd6d525223a946efd3885fe2ac', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_041950', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done
