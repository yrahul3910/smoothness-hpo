running: {'--uuid': 'ea7f4dea6e4959958bb8f1dd93f589b2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_015942', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d iris -o smoothness -u ea7f4dea6e4959958bb8f1dd93f589b2 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_015942
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_acc betwen [-0.52290909 -0.27918182 -0.34166667 -0.725      -0.91715152] and [-0.41666667 -0.275      -0.26133333 -0.68915152 -0.875     ]
  warnings.warn(

Signature errors:
                          0         1         2         3         4       max
MLP-adam_iris_acc  0.106242  0.004182  0.080333  0.035848  0.042152  0.106242
max                0.106242  0.004182  0.080333  0.035848  0.042152  0.106242
starting sklearn study smoothness MLP-adam iris acc 15 1
with data root: None
suggestion time taken 12.195007 iter 0 next_points [{'alpha': 0.003075192557311203, 'batch_size': 44, 'beta_1': 0.9594153056147458, 'beta_2': 0.9999684589866222, 'epsilon': 1.9251284099542216e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0010839158866082933, 'tol': 0.01745479248897928, 'validation_fraction': 0.661672613750234}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.062844 value -0.566667 suggestion {'alpha': 0.003075192557311203, 'batch_size': 44, 'beta_1': 0.9594153056147458, 'beta_2': 0.9999684589866222, 'epsilon': 1.9251284099542216e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0010839158866082933, 'tol': 0.01745479248897928, 'validation_fraction': 0.661672613750234}
observation time 0.000006, current best -0.566667 at iter 0
suggestion time taken 12.355716 iter 1 next_points [{'alpha': 0.22870325914851042, 'batch_size': 59, 'beta_1': 0.7498770390394845, 'beta_2': 0.9976692845125518, 'epsilon': 2.9295870109506867e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.710225240118063e-05, 'tol': 0.007437730825339302, 'validation_fraction': 0.15043789226285273}]
function_evaluation time 0.054390 value -0.341667 suggestion {'alpha': 0.22870325914851042, 'batch_size': 59, 'beta_1': 0.7498770390394845, 'beta_2': 0.9976692845125518, 'epsilon': 2.9295870109506867e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.710225240118063e-05, 'tol': 0.007437730825339302, 'validation_fraction': 0.15043789226285273}
observation time 0.000006, current best -0.566667 at iter 1
suggestion time taken 12.246090 iter 2 next_points [{'alpha': 6.166833896994247e-05, 'batch_size': 98, 'beta_1': 0.9880363191402033, 'beta_2': 0.9999960325633576, 'epsilon': 1.0069969516101565e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 6.90644361144025e-05, 'tol': 0.0065343985769012415, 'validation_fraction': 0.35052938907945413}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.045421 value -0.400000 suggestion {'alpha': 6.166833896994247e-05, 'batch_size': 98, 'beta_1': 0.9880363191402033, 'beta_2': 0.9999960325633576, 'epsilon': 1.0069969516101565e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 6.90644361144025e-05, 'tol': 0.0065343985769012415, 'validation_fraction': 0.35052938907945413}
observation time 0.000006, current best -0.566667 at iter 2
suggestion time taken 12.383586 iter 3 next_points [{'alpha': 0.9189220914991678, 'batch_size': 48, 'beta_1': 0.9761747073500415, 'beta_2': 0.9992354295790088, 'epsilon': 9.129015531701181e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.00019051889246632375, 'tol': 8.498152037776944e-05, 'validation_fraction': 0.8560179250562625}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.045825 value -0.300000 suggestion {'alpha': 0.9189220914991678, 'batch_size': 48, 'beta_1': 0.9761747073500415, 'beta_2': 0.9992354295790088, 'epsilon': 9.129015531701181e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.00019051889246632375, 'tol': 8.498152037776944e-05, 'validation_fraction': 0.8560179250562625}
observation time 0.000006, current best -0.566667 at iter 3
suggestion time taken 12.101411 iter 4 next_points [{'alpha': 0.09766885583930546, 'batch_size': 28, 'beta_1': 0.9470412393320283, 'beta_2': 0.9998691109898139, 'epsilon': 8.012404293738144e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0001037424921706293, 'tol': 0.008466291459872956, 'validation_fraction': 0.8721034012888791}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.041248 value -0.325000 suggestion {'alpha': 0.09766885583930546, 'batch_size': 28, 'beta_1': 0.9470412393320283, 'beta_2': 0.9998691109898139, 'epsilon': 8.012404293738144e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0001037424921706293, 'tol': 0.008466291459872956, 'validation_fraction': 0.8721034012888791}
observation time 0.000006, current best -0.566667 at iter 4
suggestion time taken 12.518446 iter 5 next_points [{'alpha': 0.05668882042007092, 'batch_size': 77, 'beta_1': 0.7801137631792432, 'beta_2': 0.9966979241201609, 'epsilon': 6.745854249051497e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.003244531732312825, 'tol': 0.01926377847992471, 'validation_fraction': 0.525584905336127}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053490 value -0.633333 suggestion {'alpha': 0.05668882042007092, 'batch_size': 77, 'beta_1': 0.7801137631792432, 'beta_2': 0.9966979241201609, 'epsilon': 6.745854249051497e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.003244531732312825, 'tol': 0.01926377847992471, 'validation_fraction': 0.525584905336127}
observation time 0.000006, current best -0.633333 at iter 5
suggestion time taken 12.116952 iter 6 next_points [{'alpha': 0.23924173792976364, 'batch_size': 104, 'beta_1': 0.9141122895610143, 'beta_2': 0.9972219781655804, 'epsilon': 4.934759846402629e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0005997169600143954, 'tol': 0.0353425266950161, 'validation_fraction': 0.36666289898565185}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.041736 value -0.325000 suggestion {'alpha': 0.23924173792976364, 'batch_size': 104, 'beta_1': 0.9141122895610143, 'beta_2': 0.9972219781655804, 'epsilon': 4.934759846402629e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0005997169600143954, 'tol': 0.0353425266950161, 'validation_fraction': 0.36666289898565185}
observation time 0.000006, current best -0.633333 at iter 6
suggestion time taken 12.347081 iter 7 next_points [{'alpha': 4.573364372466298, 'batch_size': 135, 'beta_1': 0.7435469444205199, 'beta_2': 0.9929229941352815, 'epsilon': 4.0925073783367335e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0005209617546625554, 'tol': 0.0031268053603332345, 'validation_fraction': 0.17606545169906432}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.049571 value -0.366667 suggestion {'alpha': 4.573364372466298, 'batch_size': 135, 'beta_1': 0.7435469444205199, 'beta_2': 0.9929229941352815, 'epsilon': 4.0925073783367335e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0005209617546625554, 'tol': 0.0031268053603332345, 'validation_fraction': 0.17606545169906432}
observation time 0.000005, current best -0.633333 at iter 7
suggestion time taken 12.207710 iter 8 next_points [{'alpha': 0.0032546844917878443, 'batch_size': 85, 'beta_1': 0.9376434129792803, 'beta_2': 0.9999987215955429, 'epsilon': 3.392686872338003e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 1.9737797053296636e-05, 'tol': 0.0002802181249979316, 'validation_fraction': 0.8779795175389689}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.040938 value -0.341667 suggestion {'alpha': 0.0032546844917878443, 'batch_size': 85, 'beta_1': 0.9376434129792803, 'beta_2': 0.9999987215955429, 'epsilon': 3.392686872338003e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 1.9737797053296636e-05, 'tol': 0.0002802181249979316, 'validation_fraction': 0.8779795175389689}
observation time 0.000006, current best -0.633333 at iter 8
suggestion time taken 12.343256 iter 9 next_points [{'alpha': 0.1260112195565586, 'batch_size': 82, 'beta_1': 0.8428853771869621, 'beta_2': 0.9994914244302373, 'epsilon': 6.917254630247001e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.005695493798182745, 'tol': 0.0013483924422235272, 'validation_fraction': 0.20722558732376792}]
function_evaluation time 0.084437 value -0.933333 suggestion {'alpha': 0.1260112195565586, 'batch_size': 82, 'beta_1': 0.8428853771869621, 'beta_2': 0.9994914244302373, 'epsilon': 6.917254630247001e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.005695493798182745, 'tol': 0.0013483924422235272, 'validation_fraction': 0.20722558732376792}
observation time 0.000006, current best -0.933333 at iter 9
suggestion time taken 12.100267 iter 10 next_points [{'alpha': 1.8215297783217387e-05, 'batch_size': 41, 'beta_1': 0.5978224425263635, 'beta_2': 0.9011857717476285, 'epsilon': 9.510629826680938e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0004912840657729811, 'tol': 0.00020401353955829958, 'validation_fraction': 0.1852403611388334}]
function_evaluation time 0.068632 value -0.383333 suggestion {'alpha': 1.8215297783217387e-05, 'batch_size': 41, 'beta_1': 0.5978224425263635, 'beta_2': 0.9011857717476285, 'epsilon': 9.510629826680938e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0004912840657729811, 'tol': 0.00020401353955829958, 'validation_fraction': 0.1852403611388334}
observation time 0.000006, current best -0.933333 at iter 10
suggestion time taken 12.166649 iter 11 next_points [{'alpha': 7.694752559748729, 'batch_size': 80, 'beta_1': 0.9460467456312498, 'beta_2': 0.9998452073184304, 'epsilon': 3.8009921210215865e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.025328283327786708, 'tol': 0.0006682550346076475, 'validation_fraction': 0.846479160795387}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.065771 value -0.766667 suggestion {'alpha': 7.694752559748729, 'batch_size': 80, 'beta_1': 0.9460467456312498, 'beta_2': 0.9998452073184304, 'epsilon': 3.8009921210215865e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.025328283327786708, 'tol': 0.0006682550346076475, 'validation_fraction': 0.846479160795387}
observation time 0.000006, current best -0.933333 at iter 11
suggestion time taken 12.408575 iter 12 next_points [{'alpha': 0.010783438595386122, 'batch_size': 43, 'beta_1': 0.811208216753113, 'beta_2': 0.9987407927680697, 'epsilon': 1.5221671758075662e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.03401158134292098, 'tol': 0.001970199890066599, 'validation_fraction': 0.3984764411207001}]
function_evaluation time 0.096563 value -0.941667 suggestion {'alpha': 0.010783438595386122, 'batch_size': 43, 'beta_1': 0.811208216753113, 'beta_2': 0.9987407927680697, 'epsilon': 1.5221671758075662e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.03401158134292098, 'tol': 0.001970199890066599, 'validation_fraction': 0.3984764411207001}
observation time 0.000006, current best -0.941667 at iter 12
suggestion time taken 12.222650 iter 13 next_points [{'alpha': 0.0005338339186059298, 'batch_size': 66, 'beta_1': 0.9740845950065486, 'beta_2': 0.9991664214184044, 'epsilon': 9.530376080313921e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 3.612852369239306e-05, 'tol': 0.0009754925715050382, 'validation_fraction': 0.1743024261807949}]
function_evaluation time 0.052897 value -0.383333 suggestion {'alpha': 0.0005338339186059298, 'batch_size': 66, 'beta_1': 0.9740845950065486, 'beta_2': 0.9991664214184044, 'epsilon': 9.530376080313921e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 3.612852369239306e-05, 'tol': 0.0009754925715050382, 'validation_fraction': 0.1743024261807949}
observation time 0.000006, current best -0.941667 at iter 13
suggestion time taken 12.305457 iter 14 next_points [{'alpha': 0.00010626694737737637, 'batch_size': 84, 'beta_1': 0.8997027986532897, 'beta_2': 0.956473623352015, 'epsilon': 2.649278786896457e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.008655658409157886, 'tol': 0.0004472939499729241, 'validation_fraction': 0.23077632465347972}]
function_evaluation time 0.103747 value -0.858333 suggestion {'alpha': 0.00010626694737737637, 'batch_size': 84, 'beta_1': 0.8997027986532897, 'beta_2': 0.956473623352015, 'epsilon': 2.649278786896457e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.008655658409157886, 'tol': 0.0004472939499729241, 'validation_fraction': 0.23077632465347972}
observation time 0.000005, current best -0.941667 at iter 14
saving meta data: {'args': {'--uuid': 'ea7f4dea6e4959958bb8f1dd93f589b2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_015942', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])}
saving results
saving timing
saving suggest log
done
