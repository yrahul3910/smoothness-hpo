running: {'--uuid': 'fc8eb1a25afb556e88be9a2f5893c9bc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_015942', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d iris -o smoothness -u fc8eb1a25afb556e88be9a2f5893c9bc -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_015942
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_acc betwen [-0.52290909 -0.27918182 -0.34166667 -0.725      -0.91715152] and [-0.41666667 -0.275      -0.26133333 -0.68915152 -0.875     ]
  warnings.warn(

Signature errors:
                          0         1         2         3         4       max
MLP-adam_iris_acc  0.106242  0.004182  0.080333  0.035848  0.042152  0.106242
max                0.106242  0.004182  0.080333  0.035848  0.042152  0.106242
starting sklearn study smoothness MLP-adam iris acc 15 1
with data root: None
suggestion time taken 12.170158 iter 0 next_points [{'alpha': 0.00080109485859168, 'batch_size': 37, 'beta_1': 0.8600982949839336, 'beta_2': 0.990791086146052, 'epsilon': 9.282284136946545e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00019729961729124344, 'tol': 4.730029108147684e-05, 'validation_fraction': 0.5829378662291115}]
function_evaluation time 0.050607 value -0.358333 suggestion {'alpha': 0.00080109485859168, 'batch_size': 37, 'beta_1': 0.8600982949839336, 'beta_2': 0.990791086146052, 'epsilon': 9.282284136946545e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00019729961729124344, 'tol': 4.730029108147684e-05, 'validation_fraction': 0.5829378662291115}
observation time 0.000007, current best -0.358333 at iter 0
suggestion time taken 11.816492 iter 1 next_points [{'alpha': 6.054112351543193, 'batch_size': 38, 'beta_1': 0.969289020705917, 'beta_2': 0.9900473157520606, 'epsilon': 8.985288735768177e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00033410906115666575, 'tol': 0.004206409364604457, 'validation_fraction': 0.8431020278364495}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046658 value -0.358333 suggestion {'alpha': 6.054112351543193, 'batch_size': 38, 'beta_1': 0.969289020705917, 'beta_2': 0.9900473157520606, 'epsilon': 8.985288735768177e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00033410906115666575, 'tol': 0.004206409364604457, 'validation_fraction': 0.8431020278364495}
observation time 0.000006, current best -0.358333 at iter 1
suggestion time taken 11.675257 iter 2 next_points [{'alpha': 0.00043156042557662607, 'batch_size': 107, 'beta_1': 0.895186921609357, 'beta_2': 0.999200277743114, 'epsilon': 6.721369150785206e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.006518054417306564, 'tol': 0.0008160161668714659, 'validation_fraction': 0.17723755978291914}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.083159 value -0.900000 suggestion {'alpha': 0.00043156042557662607, 'batch_size': 107, 'beta_1': 0.895186921609357, 'beta_2': 0.999200277743114, 'epsilon': 6.721369150785206e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.006518054417306564, 'tol': 0.0008160161668714659, 'validation_fraction': 0.17723755978291914}
observation time 0.000006, current best -0.900000 at iter 2
suggestion time taken 11.942664 iter 3 next_points [{'alpha': 0.005704431953633013, 'batch_size': 101, 'beta_1': 0.9665099694024645, 'beta_2': 0.9949383613645535, 'epsilon': 6.144349204805154e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.3097860755198885e-05, 'tol': 0.00017740569580573456, 'validation_fraction': 0.8646349333260231}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.040097 value -0.350000 suggestion {'alpha': 0.005704431953633013, 'batch_size': 101, 'beta_1': 0.9665099694024645, 'beta_2': 0.9949383613645535, 'epsilon': 6.144349204805154e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.3097860755198885e-05, 'tol': 0.00017740569580573456, 'validation_fraction': 0.8646349333260231}
observation time 0.000027, current best -0.900000 at iter 3
suggestion time taken 11.736798 iter 4 next_points [{'alpha': 0.012840513677861294, 'batch_size': 62, 'beta_1': 0.95617805938688, 'beta_2': 0.99802980698616, 'epsilon': 9.804746995672914e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0013493309826614578, 'tol': 8.172047036740381e-05, 'validation_fraction': 0.3162387831168819}]
function_evaluation time 0.088770 value -0.675000 suggestion {'alpha': 0.012840513677861294, 'batch_size': 62, 'beta_1': 0.95617805938688, 'beta_2': 0.99802980698616, 'epsilon': 9.804746995672914e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0013493309826614578, 'tol': 8.172047036740381e-05, 'validation_fraction': 0.3162387831168819}
observation time 0.000005, current best -0.900000 at iter 4
suggestion time taken 12.326352 iter 5 next_points [{'alpha': 0.026070535372827875, 'batch_size': 83, 'beta_1': 0.8656647043319209, 'beta_2': 0.9993124063106152, 'epsilon': 1.0854826727328122e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.000600158409999531, 'tol': 0.0006950257911679463, 'validation_fraction': 0.14446487962569227}]
function_evaluation time 0.063486 value -0.458333 suggestion {'alpha': 0.026070535372827875, 'batch_size': 83, 'beta_1': 0.8656647043319209, 'beta_2': 0.9993124063106152, 'epsilon': 1.0854826727328122e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.000600158409999531, 'tol': 0.0006950257911679463, 'validation_fraction': 0.14446487962569227}
observation time 0.000005, current best -0.900000 at iter 5
suggestion time taken 11.754238 iter 6 next_points [{'alpha': 2.402755399585235, 'batch_size': 66, 'beta_1': 0.8894056015903468, 'beta_2': 0.9989779412507483, 'epsilon': 2.3182477907556954e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.000919881096189772, 'tol': 0.06729102708343142, 'validation_fraction': 0.8771839257288517}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048807 value -0.416667 suggestion {'alpha': 2.402755399585235, 'batch_size': 66, 'beta_1': 0.8894056015903468, 'beta_2': 0.9989779412507483, 'epsilon': 2.3182477907556954e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.000919881096189772, 'tol': 0.06729102708343142, 'validation_fraction': 0.8771839257288517}
observation time 0.000006, current best -0.900000 at iter 6
suggestion time taken 11.708680 iter 7 next_points [{'alpha': 0.005610168541020664, 'batch_size': 44, 'beta_1': 0.7710613637007933, 'beta_2': 0.9610553999098546, 'epsilon': 2.5276983799853675e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 3.7656106578398023e-05, 'tol': 8.717865252387033e-05, 'validation_fraction': 0.10894041734026085}]
function_evaluation time 0.062565 value -0.358333 suggestion {'alpha': 0.005610168541020664, 'batch_size': 44, 'beta_1': 0.7710613637007933, 'beta_2': 0.9610553999098546, 'epsilon': 2.5276983799853675e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 3.7656106578398023e-05, 'tol': 8.717865252387033e-05, 'validation_fraction': 0.10894041734026085}
observation time 0.000006, current best -0.900000 at iter 7
suggestion time taken 11.992447 iter 8 next_points [{'alpha': 4.948871473272582, 'batch_size': 97, 'beta_1': 0.8922699933311078, 'beta_2': 0.9975411865700794, 'epsilon': 3.5429886263245916e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00949150351214902, 'tol': 1.1112052808561634e-05, 'validation_fraction': 0.1753262673754669}]
function_evaluation time 0.068420 value -0.883333 suggestion {'alpha': 4.948871473272582, 'batch_size': 97, 'beta_1': 0.8922699933311078, 'beta_2': 0.9975411865700794, 'epsilon': 3.5429886263245916e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00949150351214902, 'tol': 1.1112052808561634e-05, 'validation_fraction': 0.1753262673754669}
observation time 0.000005, current best -0.900000 at iter 8
suggestion time taken 12.160924 iter 9 next_points [{'alpha': 0.006617194437922746, 'batch_size': 85, 'beta_1': 0.7848785102559913, 'beta_2': 0.9999975558098231, 'epsilon': 2.82494151652334e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00013149826667231348, 'tol': 7.893298574532736e-05, 'validation_fraction': 0.2160155010424538}]
function_evaluation time 0.042755 value -0.391667 suggestion {'alpha': 0.006617194437922746, 'batch_size': 85, 'beta_1': 0.7848785102559913, 'beta_2': 0.9999975558098231, 'epsilon': 2.82494151652334e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00013149826667231348, 'tol': 7.893298574532736e-05, 'validation_fraction': 0.2160155010424538}
observation time 0.000005, current best -0.900000 at iter 9
suggestion time taken 11.730053 iter 10 next_points [{'alpha': 8.74345547145313e-05, 'batch_size': 72, 'beta_1': 0.9594134435814944, 'beta_2': 0.9810515046228819, 'epsilon': 2.11645990563643e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 9.781163576499003e-05, 'tol': 9.444773595626701e-05, 'validation_fraction': 0.1953261341202009}]
function_evaluation time 0.051783 value -0.341667 suggestion {'alpha': 8.74345547145313e-05, 'batch_size': 72, 'beta_1': 0.9594134435814944, 'beta_2': 0.9810515046228819, 'epsilon': 2.11645990563643e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 9.781163576499003e-05, 'tol': 9.444773595626701e-05, 'validation_fraction': 0.1953261341202009}
observation time 0.000006, current best -0.900000 at iter 10
suggestion time taken 11.952899 iter 11 next_points [{'alpha': 0.43867227634298644, 'batch_size': 38, 'beta_1': 0.9751637917177884, 'beta_2': 0.9998917879227072, 'epsilon': 4.023786167272469e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0033573321642480945, 'tol': 0.04002998030687527, 'validation_fraction': 0.11658779620460964}]
function_evaluation time 0.101009 value -0.808333 suggestion {'alpha': 0.43867227634298644, 'batch_size': 38, 'beta_1': 0.9751637917177884, 'beta_2': 0.9998917879227072, 'epsilon': 4.023786167272469e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0033573321642480945, 'tol': 0.04002998030687527, 'validation_fraction': 0.11658779620460964}
observation time 0.000005, current best -0.900000 at iter 11
suggestion time taken 11.717973 iter 12 next_points [{'alpha': 0.00010266081602440768, 'batch_size': 56, 'beta_1': 0.9666635851232253, 'beta_2': 0.9998329236378203, 'epsilon': 4.762512627994069e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.004537294363548876, 'tol': 0.01536428657541599, 'validation_fraction': 0.4986397285219154}]
function_evaluation time 0.112287 value -0.958333 suggestion {'alpha': 0.00010266081602440768, 'batch_size': 56, 'beta_1': 0.9666635851232253, 'beta_2': 0.9998329236378203, 'epsilon': 4.762512627994069e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.004537294363548876, 'tol': 0.01536428657541599, 'validation_fraction': 0.4986397285219154}
observation time 0.000006, current best -0.958333 at iter 12
suggestion time taken 11.998089 iter 13 next_points [{'alpha': 2.330150719704897, 'batch_size': 201, 'beta_1': 0.9520563632379363, 'beta_2': 0.9999918264243841, 'epsilon': 8.769484972224e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004961403995157313, 'tol': 0.01692280400404413, 'validation_fraction': 0.484860025556245}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.066435 value -0.783333 suggestion {'alpha': 2.330150719704897, 'batch_size': 201, 'beta_1': 0.9520563632379363, 'beta_2': 0.9999918264243841, 'epsilon': 8.769484972224e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004961403995157313, 'tol': 0.01692280400404413, 'validation_fraction': 0.484860025556245}
observation time 0.000005, current best -0.958333 at iter 13
suggestion time taken 11.626931 iter 14 next_points [{'alpha': 0.09693795816110766, 'batch_size': 107, 'beta_1': 0.9542338344540565, 'beta_2': 0.9891578626387307, 'epsilon': 1.8963378729481465e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0028611440799107407, 'tol': 0.0009367011643171985, 'validation_fraction': 0.7326291211972917}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.061841 value -0.783333 suggestion {'alpha': 0.09693795816110766, 'batch_size': 107, 'beta_1': 0.9542338344540565, 'beta_2': 0.9891578626387307, 'epsilon': 1.8963378729481465e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0028611440799107407, 'tol': 0.0009367011643171985, 'validation_fraction': 0.7326291211972917}
observation time 0.000006, current best -0.958333 at iter 14
saving meta data: {'args': {'--uuid': 'fc8eb1a25afb556e88be9a2f5893c9bc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_015942', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])}
saving results
saving timing
saving suggest log
done
