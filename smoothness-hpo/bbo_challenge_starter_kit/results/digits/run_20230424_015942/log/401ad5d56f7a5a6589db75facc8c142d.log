running: {'--uuid': '401ad5d56f7a5a6589db75facc8c142d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_015942', '--opt': 'opentuner', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d iris -o opentuner -u 401ad5d56f7a5a6589db75facc8c142d -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_015942
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_nll betwen [1.31057198 1.56976556 1.25224472 0.90978049 0.39813052] and [1.32439241 1.77609477 1.43221076 0.9966468  0.57459871]
  warnings.warn(

Signature errors:
                         0         1         2         3         4       max
MLP-adam_iris_nll  0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
max                0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
starting sklearn study opentuner MLP-adam iris nll 15 1
with data root: None
suggestion time taken 0.018381 iter 0 next_points [{'hidden_layer_sizes': 176, 'alpha': 8.894878056386137, 'batch_size': 120, 'learning_rate_init': 0.05972037728343287, 'tol': 0.010594269861738437, 'validation_fraction': 0.7045095668349407, 'beta_1': 0.6449833524198858, 'beta_2': 0.9125160913109021, 'epsilon': 8.118435511910983e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.066759 value 0.985771 suggestion {'hidden_layer_sizes': 176, 'alpha': 8.894878056386137, 'batch_size': 120, 'learning_rate_init': 0.05972037728343287, 'tol': 0.010594269861738437, 'validation_fraction': 0.7045095668349407, 'beta_1': 0.6449833524198858, 'beta_2': 0.9125160913109021, 'epsilon': 8.118435511910983e-07}
observation time 0.004321, current best 0.985771 at iter 0
suggestion time taken 0.047277 iter 1 next_points [{'beta_2': 0.9816609058934659, 'alpha': 0.6776686734584986, 'epsilon': 4.855820997800842e-07, 'tol': 0.0014968295079339955, 'learning_rate_init': 0.046609357800584776, 'hidden_layer_sizes': 198, 'validation_fraction': 0.17850169184252007, 'batch_size': 231, 'beta_1': 0.9066545374746718}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.094154 value 0.354453 suggestion {'beta_2': 0.9816609058934659, 'alpha': 0.6776686734584986, 'epsilon': 4.855820997800842e-07, 'tol': 0.0014968295079339955, 'learning_rate_init': 0.046609357800584776, 'hidden_layer_sizes': 198, 'validation_fraction': 0.17850169184252007, 'batch_size': 231, 'beta_1': 0.9066545374746718}
observation time 0.001877, current best 0.354453 at iter 1
suggestion time taken 0.021797 iter 2 next_points [{'beta_2': 0.9451665767811457, 'alpha': 0.07465523045816573, 'epsilon': 2.1308723310905952e-07, 'tol': 0.050451491975700584, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 87, 'validation_fraction': 0.17902838380383504, 'batch_size': 43, 'beta_1': 0.6072698725780717}]
function_evaluation time 0.083887 value 0.309315 suggestion {'beta_2': 0.9451665767811457, 'alpha': 0.07465523045816573, 'epsilon': 2.1308723310905952e-07, 'tol': 0.050451491975700584, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 87, 'validation_fraction': 0.17902838380383504, 'batch_size': 43, 'beta_1': 0.6072698725780717}
observation time 0.001882, current best 0.309315 at iter 2
suggestion time taken 0.007126 iter 3 next_points [{'beta_2': 0.9451665767811457, 'alpha': 0.07465523045816573, 'epsilon': 2.1308723310905952e-07, 'tol': 0.04938367932696235, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 87, 'validation_fraction': 0.17902838380383504, 'batch_size': 23, 'beta_1': 0.6072698725780717}]
function_evaluation time 0.099924 value 0.324376 suggestion {'beta_2': 0.9451665767811457, 'alpha': 0.07465523045816573, 'epsilon': 2.1308723310905952e-07, 'tol': 0.04938367932696235, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 87, 'validation_fraction': 0.17902838380383504, 'batch_size': 23, 'beta_1': 0.6072698725780717}
observation time 0.001878, current best 0.309315 at iter 3
suggestion time taken 0.005176 iter 4 next_points [{'beta_2': 0.9187004668063213, 'alpha': 2.712512407415023, 'epsilon': 3.3318276351831835e-07, 'tol': 0.0049627192476923605, 'learning_rate_init': 0.006126983096456252, 'hidden_layer_sizes': 135, 'validation_fraction': 0.412738421614938, 'batch_size': 198, 'beta_1': 0.7696780952979216}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070872 value 0.650528 suggestion {'beta_2': 0.9187004668063213, 'alpha': 2.712512407415023, 'epsilon': 3.3318276351831835e-07, 'tol': 0.0049627192476923605, 'learning_rate_init': 0.006126983096456252, 'hidden_layer_sizes': 135, 'validation_fraction': 0.412738421614938, 'batch_size': 198, 'beta_1': 0.7696780952979216}
observation time 0.001930, current best 0.309315 at iter 4
suggestion time taken 0.006079 iter 5 next_points [{'beta_2': 0.9382631632131184, 'alpha': 2.8674684681914235, 'epsilon': 2.631790538004376e-07, 'tol': 0.06940043688134982, 'learning_rate_init': 0.003963867711094627, 'hidden_layer_sizes': 137, 'validation_fraction': 0.5367381233889744, 'batch_size': 232, 'beta_1': 0.8231948288851821}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.061363 value 0.658894 suggestion {'beta_2': 0.9382631632131184, 'alpha': 2.8674684681914235, 'epsilon': 2.631790538004376e-07, 'tol': 0.06940043688134982, 'learning_rate_init': 0.003963867711094627, 'hidden_layer_sizes': 137, 'validation_fraction': 0.5367381233889744, 'batch_size': 232, 'beta_1': 0.8231948288851821}
observation time 0.002026, current best 0.309315 at iter 5
suggestion time taken 0.007149 iter 6 next_points [{'beta_2': 0.9451665767811457, 'alpha': 0.06829720780017527, 'epsilon': 2.1308723310905952e-07, 'tol': 0.050451491975700584, 'learning_rate_init': 0.045232067930517976, 'hidden_layer_sizes': 94, 'validation_fraction': 0.17902838380383504, 'batch_size': 43, 'beta_1': 0.6931618281271401}]
function_evaluation time 0.072969 value 0.385244 suggestion {'beta_2': 0.9451665767811457, 'alpha': 0.06829720780017527, 'epsilon': 2.1308723310905952e-07, 'tol': 0.050451491975700584, 'learning_rate_init': 0.045232067930517976, 'hidden_layer_sizes': 94, 'validation_fraction': 0.17902838380383504, 'batch_size': 43, 'beta_1': 0.6931618281271401}
observation time 0.001849, current best 0.309315 at iter 6
suggestion time taken 0.006047 iter 7 next_points [{'beta_2': 0.9178778596231504, 'alpha': 2.461672735291839, 'epsilon': 1.0354661275688192e-07, 'tol': 0.07547138192598905, 'learning_rate_init': 0.041313711320819894, 'hidden_layer_sizes': 89, 'validation_fraction': 0.15204723038527695, 'batch_size': 107, 'beta_1': 0.9092914584947565}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.067946 value 0.423322 suggestion {'beta_2': 0.9178778596231504, 'alpha': 2.461672735291839, 'epsilon': 1.0354661275688192e-07, 'tol': 0.07547138192598905, 'learning_rate_init': 0.041313711320819894, 'hidden_layer_sizes': 89, 'validation_fraction': 0.15204723038527695, 'batch_size': 107, 'beta_1': 0.9092914584947565}
observation time 0.002064, current best 0.309315 at iter 7
suggestion time taken 0.005211 iter 8 next_points [{'beta_2': 0.9827125973908786, 'alpha': 1.46905849526854, 'epsilon': 2.4301858872530126e-07, 'tol': 0.0731929918224196, 'learning_rate_init': 0.08490855476108032, 'hidden_layer_sizes': 155, 'validation_fraction': 0.3074257496166424, 'batch_size': 247, 'beta_1': 0.6585866626269451}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.075474 value 0.371508 suggestion {'beta_2': 0.9827125973908786, 'alpha': 1.46905849526854, 'epsilon': 2.4301858872530126e-07, 'tol': 0.0731929918224196, 'learning_rate_init': 0.08490855476108032, 'hidden_layer_sizes': 155, 'validation_fraction': 0.3074257496166424, 'batch_size': 247, 'beta_1': 0.6585866626269451}
observation time 0.001787, current best 0.309315 at iter 8
suggestion time taken 0.007092 iter 9 next_points [{'beta_2': 0.9451665767811457, 'alpha': 0.07465523045816573, 'epsilon': 2.1308723310905952e-07, 'tol': 0.044438434119041074, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 30, 'beta_1': 0.6072698725780717}]
function_evaluation time 0.088634 value 0.277417 suggestion {'beta_2': 0.9451665767811457, 'alpha': 0.07465523045816573, 'epsilon': 2.1308723310905952e-07, 'tol': 0.044438434119041074, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 30, 'beta_1': 0.6072698725780717}
observation time 0.001872, current best 0.277417 at iter 9
suggestion time taken 0.008284 iter 10 next_points [{'beta_2': 0.9378490978520396, 'alpha': 0.07465523045816573, 'epsilon': 2.8646619246228035e-07, 'tol': 0.04855240431327428, 'learning_rate_init': 0.08055787649374928, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 50, 'beta_1': 0.6072698725780717}]
function_evaluation time 0.078897 value 0.373503 suggestion {'beta_2': 0.9378490978520396, 'alpha': 0.07465523045816573, 'epsilon': 2.8646619246228035e-07, 'tol': 0.04855240431327428, 'learning_rate_init': 0.08055787649374928, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 50, 'beta_1': 0.6072698725780717}
observation time 0.001786, current best 0.277417 at iter 10
suggestion time taken 0.007208 iter 11 next_points [{'beta_2': 0.9451665767811457, 'alpha': 0.05702344812397458, 'epsilon': 1.3259019274233685e-07, 'tol': 0.05656687169395241, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 24, 'beta_1': 0.6573171154899914}]
function_evaluation time 0.097482 value 0.248556 suggestion {'beta_2': 0.9451665767811457, 'alpha': 0.05702344812397458, 'epsilon': 1.3259019274233685e-07, 'tol': 0.05656687169395241, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 24, 'beta_1': 0.6573171154899914}
observation time 0.001877, current best 0.248556 at iter 11
suggestion time taken 0.007101 iter 12 next_points [{'beta_2': 0.9451665767811457, 'alpha': 0.05702344812397458, 'epsilon': 1.9876733628518172e-07, 'tol': 0.05656687169395241, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 62, 'validation_fraction': 0.17980502352059513, 'batch_size': 24, 'beta_1': 0.5345325036341213}]
function_evaluation time 0.093252 value 0.401472 suggestion {'beta_2': 0.9451665767811457, 'alpha': 0.05702344812397458, 'epsilon': 1.9876733628518172e-07, 'tol': 0.05656687169395241, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 62, 'validation_fraction': 0.17980502352059513, 'batch_size': 24, 'beta_1': 0.5345325036341213}
observation time 0.001851, current best 0.248556 at iter 12
suggestion time taken 0.006809 iter 13 next_points [{'beta_2': 0.9451665767811457, 'alpha': 0.05702344812397458, 'epsilon': 1.3259019274233685e-07, 'tol': 0.05656687169395241, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 50, 'validation_fraction': 0.23012872465632472, 'batch_size': 24, 'beta_1': 0.6573171154899914}]
function_evaluation time 0.104513 value 0.374524 suggestion {'beta_2': 0.9451665767811457, 'alpha': 0.05702344812397458, 'epsilon': 1.3259019274233685e-07, 'tol': 0.05656687169395241, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 50, 'validation_fraction': 0.23012872465632472, 'batch_size': 24, 'beta_1': 0.6573171154899914}
observation time 0.001833, current best 0.248556 at iter 13
suggestion time taken 0.007137 iter 14 next_points [{'beta_2': 0.9349806433299922, 'alpha': 0.05702344812397458, 'epsilon': 1.5436465453152925e-07, 'tol': 0.07796009176131206, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 24, 'beta_1': 0.6573171154899914}]
function_evaluation time 0.091031 value 0.322810 suggestion {'beta_2': 0.9349806433299922, 'alpha': 0.05702344812397458, 'epsilon': 1.5436465453152925e-07, 'tol': 0.07796009176131206, 'learning_rate_init': 0.06496143230604161, 'hidden_layer_sizes': 64, 'validation_fraction': 0.17980502352059513, 'batch_size': 24, 'beta_1': 0.6573171154899914}
observation time 0.002001, current best 0.248556 at iter 14
saving meta data: {'args': {'--uuid': '401ad5d56f7a5a6589db75facc8c142d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_015942', '--opt': 'opentuner', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])}
saving results
saving timing
saving suggest log
done
