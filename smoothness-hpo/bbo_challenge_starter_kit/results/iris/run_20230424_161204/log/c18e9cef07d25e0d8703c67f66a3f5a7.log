running: {'--uuid': 'c18e9cef07d25e0d8703c67f66a3f5a7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_161204', '--opt': 'turbo', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d iris -o turbo -u c18e9cef07d25e0d8703c67f66a3f5a7 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230424_161204
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_nll betwen [1.31057198 1.56976556 1.25224472 0.90978049 0.39813052] and [1.32439241 1.77609477 1.43221076 0.9966468  0.57459871]
  warnings.warn(

Signature errors:
                         0         1         2         3         4       max
MLP-adam_iris_nll  0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
max                0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
starting sklearn study turbo MLP-adam iris nll 15 1
with data root: None
suggestion time taken 0.002162 iter 0 next_points [{'alpha': 0.00022244053543189884, 'batch_size': 199, 'beta_1': 0.9823971190573975, 'beta_2': 0.9999971016015524, 'epsilon': 2.7766010030265726e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 3.394168889875944e-05, 'tol': 0.018729320251301893, 'validation_fraction': 0.41525726256662226}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.047844 value 1.163292 suggestion {'alpha': 0.00022244053543189884, 'batch_size': 199, 'beta_1': 0.9823971190573975, 'beta_2': 0.9999971016015524, 'epsilon': 2.7766010030265726e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 3.394168889875944e-05, 'tol': 0.018729320251301893, 'validation_fraction': 0.41525726256662226}
observation time 0.001421, current best 1.163292 at iter 0
suggestion time taken 0.001755 iter 1 next_points [{'alpha': 3.641915581188345, 'batch_size': 201, 'beta_1': 0.9383173915302124, 'beta_2': 0.9238336640780265, 'epsilon': 1.443564429237799e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 9.69410627181939e-05, 'tol': 0.0031082045515754613, 'validation_fraction': 0.4084686179633436}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.058296 value 1.247470 suggestion {'alpha': 3.641915581188345, 'batch_size': 201, 'beta_1': 0.9383173915302124, 'beta_2': 0.9238336640780265, 'epsilon': 1.443564429237799e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 9.69410627181939e-05, 'tol': 0.0031082045515754613, 'validation_fraction': 0.4084686179633436}
observation time 0.001405, current best 1.163292 at iter 1
suggestion time taken 0.001799 iter 2 next_points [{'alpha': 2.1785642968279844e-05, 'batch_size': 235, 'beta_1': 0.8742859162852256, 'beta_2': 0.9999982256121612, 'epsilon': 7.471037609989332e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.03821955649845162, 'tol': 0.001086089558607772, 'validation_fraction': 0.8476439667026099}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.068832 value 1.212273 suggestion {'alpha': 2.1785642968279844e-05, 'batch_size': 235, 'beta_1': 0.8742859162852256, 'beta_2': 0.9999982256121612, 'epsilon': 7.471037609989332e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.03821955649845162, 'tol': 0.001086089558607772, 'validation_fraction': 0.8476439667026099}
observation time 0.001407, current best 1.163292 at iter 2
suggestion time taken 0.001992 iter 3 next_points [{'alpha': 0.032738378416758564, 'batch_size': 93, 'beta_1': 0.8984389049849892, 'beta_2': 0.998239448765988, 'epsilon': 1.2443414552195726e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.062275793937115395, 'tol': 7.389625968884687e-05, 'validation_fraction': 0.27954910174815184}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.071580 value 0.387249 suggestion {'alpha': 0.032738378416758564, 'batch_size': 93, 'beta_1': 0.8984389049849892, 'beta_2': 0.998239448765988, 'epsilon': 1.2443414552195726e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.062275793937115395, 'tol': 7.389625968884687e-05, 'validation_fraction': 0.27954910174815184}
observation time 0.001361, current best 0.387249 at iter 3
suggestion time taken 0.001674 iter 4 next_points [{'alpha': 1.04081517607069, 'batch_size': 161, 'beta_1': 0.9851569150891731, 'beta_2': 0.9939051098381043, 'epsilon': 4.320963452955395e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0013857366802073467, 'tol': 0.07774475003234614, 'validation_fraction': 0.16201211669719953}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.062876 value 1.092715 suggestion {'alpha': 1.04081517607069, 'batch_size': 161, 'beta_1': 0.9851569150891731, 'beta_2': 0.9939051098381043, 'epsilon': 4.320963452955395e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0013857366802073467, 'tol': 0.07774475003234614, 'validation_fraction': 0.16201211669719953}
observation time 0.001446, current best 0.387249 at iter 4
suggestion time taken 0.001697 iter 5 next_points [{'alpha': 5.179180152330659e-05, 'batch_size': 25, 'beta_1': 0.9247703385946415, 'beta_2': 0.9999090651399949, 'epsilon': 5.285845034362152e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0011071458043792456, 'tol': 4.630447240310273e-05, 'validation_fraction': 0.73118824010734}]
function_evaluation time 0.082349 value 0.817314 suggestion {'alpha': 5.179180152330659e-05, 'batch_size': 25, 'beta_1': 0.9247703385946415, 'beta_2': 0.9999090651399949, 'epsilon': 5.285845034362152e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0011071458043792456, 'tol': 4.630447240310273e-05, 'validation_fraction': 0.73118824010734}
observation time 0.001382, current best 0.387249 at iter 5
suggestion time taken 0.001692 iter 6 next_points [{'alpha': 0.00010841289807090977, 'batch_size': 11, 'beta_1': 0.959206119219038, 'beta_2': 0.9999958815422183, 'epsilon': 1.2903843728995598e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0006453751782448443, 'tol': 0.02935019977464438, 'validation_fraction': 0.8652806287784799}]
function_evaluation time 0.060782 value 1.101918 suggestion {'alpha': 0.00010841289807090977, 'batch_size': 11, 'beta_1': 0.959206119219038, 'beta_2': 0.9999958815422183, 'epsilon': 1.2903843728995598e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0006453751782448443, 'tol': 0.02935019977464438, 'validation_fraction': 0.8652806287784799}
observation time 0.001388, current best 0.387249 at iter 6
suggestion time taken 0.001750 iter 7 next_points [{'alpha': 0.0004208376900408626, 'batch_size': 52, 'beta_1': 0.7073682907277946, 'beta_2': 0.9999690172200709, 'epsilon': 4.334627184079485e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.01401532440958577, 'tol': 3.903964272202461e-05, 'validation_fraction': 0.1926871639340527}]
function_evaluation time 0.085456 value 0.363402 suggestion {'alpha': 0.0004208376900408626, 'batch_size': 52, 'beta_1': 0.7073682907277946, 'beta_2': 0.9999690172200709, 'epsilon': 4.334627184079485e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.01401532440958577, 'tol': 3.903964272202461e-05, 'validation_fraction': 0.1926871639340527}
observation time 0.001434, current best 0.363402 at iter 7
suggestion time taken 0.001720 iter 8 next_points [{'alpha': 0.072901243761738, 'batch_size': 138, 'beta_1': 0.9708276227274779, 'beta_2': 0.9990213944310751, 'epsilon': 1.1662416832085328e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00025412545419464203, 'tol': 0.012082623204447238, 'validation_fraction': 0.1353176354330111}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.056929 value 1.485277 suggestion {'alpha': 0.072901243761738, 'batch_size': 138, 'beta_1': 0.9708276227274779, 'beta_2': 0.9990213944310751, 'epsilon': 1.1662416832085328e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00025412545419464203, 'tol': 0.012082623204447238, 'validation_fraction': 0.1353176354330111}
observation time 0.001416, current best 0.363402 at iter 8
suggestion time taken 0.001711 iter 9 next_points [{'alpha': 0.5126453785392119, 'batch_size': 47, 'beta_1': 0.5453862640322825, 'beta_2': 0.999986342372693, 'epsilon': 2.4743144159932735e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.006952614641512877, 'tol': 0.0005630714163407548, 'validation_fraction': 0.32932721953692756}]
function_evaluation time 0.095667 value 0.406313 suggestion {'alpha': 0.5126453785392119, 'batch_size': 47, 'beta_1': 0.5453862640322825, 'beta_2': 0.999986342372693, 'epsilon': 2.4743144159932735e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.006952614641512877, 'tol': 0.0005630714163407548, 'validation_fraction': 0.32932721953692756}
observation time 0.001384, current best 0.363402 at iter 9
suggestion time taken 0.002009 iter 10 next_points [{'alpha': 0.02572641487124106, 'batch_size': 166, 'beta_1': 0.9567989953619773, 'beta_2': 0.9672178244905763, 'epsilon': 5.364047550459407e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.03277333621875153, 'tol': 0.00012074043584092455, 'validation_fraction': 0.7951853782238165}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.090005 value 0.361095 suggestion {'alpha': 0.02572641487124106, 'batch_size': 166, 'beta_1': 0.9567989953619773, 'beta_2': 0.9672178244905763, 'epsilon': 5.364047550459407e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.03277333621875153, 'tol': 0.00012074043584092455, 'validation_fraction': 0.7951853782238165}
observation time 0.001322, current best 0.361095 at iter 10
suggestion time taken 0.001947 iter 11 next_points [{'alpha': 7.651533636220486, 'batch_size': 180, 'beta_1': 0.6668553223428968, 'beta_2': 0.9998028438445027, 'epsilon': 2.0747534014141584e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0003651053676499762, 'tol': 0.0002213431562865782, 'validation_fraction': 0.8872629067396274}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051504 value 1.335588 suggestion {'alpha': 7.651533636220486, 'batch_size': 180, 'beta_1': 0.6668553223428968, 'beta_2': 0.9998028438445027, 'epsilon': 2.0747534014141584e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0003651053676499762, 'tol': 0.0002213431562865782, 'validation_fraction': 0.8872629067396274}
observation time 0.001419, current best 0.361095 at iter 11
suggestion time taken 0.001741 iter 12 next_points [{'alpha': 0.002717515785536526, 'batch_size': 216, 'beta_1': 0.8475876314554727, 'beta_2': 0.9772765755133487, 'epsilon': 3.2627836551635924e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 1.7763231735900735e-05, 'tol': 0.0003225866268418384, 'validation_fraction': 0.10440032301162054}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.045131 value 1.336195 suggestion {'alpha': 0.002717515785536526, 'batch_size': 216, 'beta_1': 0.8475876314554727, 'beta_2': 0.9772765755133487, 'epsilon': 3.2627836551635924e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 1.7763231735900735e-05, 'tol': 0.0003225866268418384, 'validation_fraction': 0.10440032301162054}
observation time 0.001635, current best 0.361095 at iter 12
suggestion time taken 0.001763 iter 13 next_points [{'alpha': 0.16620543478791827, 'batch_size': 247, 'beta_1': 0.5854357351936396, 'beta_2': 0.9999343797169277, 'epsilon': 8.209197203559683e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.1393049008717734e-05, 'tol': 0.006863079953288897, 'validation_fraction': 0.24547217810095986}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.047803 value 1.235228 suggestion {'alpha': 0.16620543478791827, 'batch_size': 247, 'beta_1': 0.5854357351936396, 'beta_2': 0.9999343797169277, 'epsilon': 8.209197203559683e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.1393049008717734e-05, 'tol': 0.006863079953288897, 'validation_fraction': 0.24547217810095986}
observation time 0.001431, current best 0.361095 at iter 13
suggestion time taken 0.001721 iter 14 next_points [{'alpha': 0.007206040813744404, 'batch_size': 68, 'beta_1': 0.8155377587508682, 'beta_2': 0.9892087092084096, 'epsilon': 2.874936702170897e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00017427365191934952, 'tol': 1.0424400055935972e-05, 'validation_fraction': 0.541725176319687}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.041919 value 1.810937 suggestion {'alpha': 0.007206040813744404, 'batch_size': 68, 'beta_1': 0.8155377587508682, 'beta_2': 0.9892087092084096, 'epsilon': 2.874936702170897e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00017427365191934952, 'tol': 1.0424400055935972e-05, 'validation_fraction': 0.541725176319687}
observation time 0.001388, current best 0.361095 at iter 14
saving meta data: {'args': {'--uuid': 'c18e9cef07d25e0d8703c67f66a3f5a7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230424_161204', '--opt': 'turbo', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])}
saving results
saving timing
saving suggest log
done
